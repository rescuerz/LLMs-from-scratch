{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2e65c03-36d4-413f-9b23-5cdd816729ab",
   "metadata": {
    "id": "e2e65c03-36d4-413f-9b23-5cdd816729ab"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f678e62-7bcb-4405-86ae-dce94f494303",
   "metadata": {
    "id": "6f678e62-7bcb-4405-86ae-dce94f494303"
   },
   "source": [
    "# Comparing Efficient Multi-Head Attention Implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742938a-4bfc-4527-a1f1-d5963508967d",
   "metadata": {
    "id": "b742938a-4bfc-4527-a1f1-d5963508967d"
   },
   "source": [
    "This code notebook compares different ways to implement causal multi-head attention used in decoder-style LLMs like GPT, Llama, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7898551e-f582-48ac-9f66-3632abe2a93f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7898551e-f582-48ac-9f66-3632abe2a93f",
    "outputId": "1a7d22c1-96d8-4a42-e3ec-ce78abaf18eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu121\n",
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "batch_size = 8\n",
    "context_len = 1024\n",
    "embed_dim = 768\n",
    "embeddings = torch.randn((batch_size, context_len, embed_dim), device=device)\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LYLcq3403Yq6",
   "metadata": {
    "id": "LYLcq3403Yq6"
   },
   "source": [
    "- To run all the code in this notebook, please ensure you update to at least PyTorch 2.5 (FlexAttention is not included in earlier PyTorch releases)\n",
    "- If the code cell above shows a PyTorch version lower than 2.5, you can upgrade your PyTorch installation by uncommenting and running the following code cell (Please note that PyTorch 2.5 requires Python 3.9 or later)\n",
    "- For more specific instructions and CUDA versions, please refer to the official installation guide at https://pytorch.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db27f43-86f4-478f-89df-fbc2182a129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9bb1b6-a1e5-4e0a-884d-0f31b374a8d6",
   "metadata": {
    "id": "2f9bb1b6-a1e5-4e0a-884d-0f31b374a8d6"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 1) CausalAttention MHA wrapper class from chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297c93ed-aec0-4896-bb89-42c4b294d3d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "297c93ed-aec0-4896-bb89-42c4b294d3d1",
    "outputId": "b6f596e4-b778-496c-bea8-3fe83d873c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n",
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CausalAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout)  # New\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))  # New\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape  # New batch dimension b\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(1, 2)  # Changed transpose\n",
    "        attn_scores.masked_fill_(  # New, _ ops are in-place\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)  # New\n",
    "\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "# class Ch03_MHA_Wrapper(nn.Module):\n",
    "\n",
    "#     def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "#         super().__init__()\n",
    "#         self.heads = nn.ModuleList(\n",
    "#             [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
    "#              for _ in range(num_heads)]\n",
    "#         )\n",
    "#         self.out_proj = nn.Linear(d_out*num_heads, d_out*num_heads)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         context_vec = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "#         return self.out_proj(context_vec)\n",
    "\n",
    "class Ch03_MHA_Wrapper(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [CausalAttention(d_in, d_out, context_length, dropout, qkv_bias)\n",
    "            for _ in range(num_heads)]\n",
    "        )\n",
    "        self.out_proj = nn.Linear(d_out*num_heads, d_out*num_heads)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        context_vec = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        return self.out_proj(context_vec)\n",
    "\n",
    "mha_ch03_wrapper = Ch03_MHA_Wrapper(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim//12,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_ch03_wrapper(embeddings)\n",
    "print(embeddings.shape)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21930804-b327-40b1-8e63-94dcad39ce7b",
   "metadata": {
    "id": "21930804-b327-40b1-8e63-94dcad39ce7b"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 2) The multi-head attention class from chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ee6a61b-d25c-4a0c-8a59-f285544e3710",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ee6a61b-d25c-4a0c-8a59-f285544e3710",
    "outputId": "4d9ade55-4710-4ae6-9f00-aa87811bfb04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "class Ch03_MHA(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "mha_ch03 = Ch03_MHA(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_ch03(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cd11da-ea3b-4081-b483-c4965dfefbc4",
   "metadata": {
    "id": "73cd11da-ea3b-4081-b483-c4965dfefbc4"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 3) An alternative multi-head attention with combined weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa1a5ea-eaff-4d2d-aaf0-b34cdb6fd4dd",
   "metadata": {
    "id": "1fa1a5ea-eaff-4d2d-aaf0-b34cdb6fd4dd"
   },
   "source": [
    "- The code for the `MultiHeadAttentionCombinedQKV` class below is based on code that was kindly shared by [Rayed Bin Wahed](https://github.com/rasbt/LLMs-from-scratch/discussions/51)\n",
    "- The main difference between the `MultiHeadAttentionCombinedQKV` class and the `MultiHeadAttention` class used in chapter 3 is that `MultiHeadAttentionCombinedQKV` uses a single weight matrix, `self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)` instead of separate weight matrices:\n",
    "\n",
    "  - `self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)`\n",
    "  - `self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)`\n",
    "  - `self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)`\n",
    "\n",
    "- Here, `self.qkv` combines all three weight matrices `self.W_query`, `self.W_key`, and `self.W_value` to carry out the query, key, and value computation in a single step\n",
    "- Using `q, k, v = qkv.unbind(0)`, we obtain the individual query, key, and value tensors, which are then used similarly to the query, key, and value tensors in the `MultiHeadAttention` class in chapter 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6bd0a2-f27c-4602-afa0-c96cd295c1a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a6bd0a2-f27c-4602-afa0-c96cd295c1a6",
    "outputId": "a0a023ee-3bc7-4a89-cdba-7c97921160ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MultiHeadAttentionCombinedQKV(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_out % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.context_length = context_length\n",
    "        self.head_dim = d_out // num_heads\n",
    "        \"\"\"\n",
    "        使用单个线性层替代之前的三个独立线性层\n",
    "        输出维度是原来的3倍，包含Q、K、V三个矩阵的信息\n",
    "        \"\"\"\n",
    "        self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, embed_dim = x.shape\n",
    "\n",
    "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        \"\"\"\n",
    "        多头分割: (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
    "        \"\"\"\n",
    "        qkv = qkv.view(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
    "\n",
    "        \"\"\"\n",
    "        维度重排：(b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
    "        \"\"\"\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        \"\"\"\n",
    "        使用unbind沿着第0维分解张量\n",
    "        得到独立的Q、K、V矩阵\n",
    "        每个矩阵形状为(b, num_heads, num_tokens, head_dim)\n",
    "        (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_head, num_tokens, head_dim)\n",
    "        \"\"\"\n",
    "        queries, keys, values = qkv.unbind(0)\n",
    "\n",
    "        # (b, num_heads, num_tokens, head_dim) --> (b, num_heads, num_tokens, num_tokens)\n",
    "        attn_scores = queries @ keys.transpose(-2, -1)\n",
    "        attn_scores = attn_scores.masked_fill(\n",
    "            self.mask.bool()[:num_tokens, :num_tokens], -torch.inf\n",
    "        )\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**-0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # (b, num_heads, num_tokens, num_tokens) --> (b, num_heads, num_tokens, head_dim)\n",
    "        context_vec = attn_weights @ values\n",
    "\n",
    "        # (b, num_heads, num_tokens, head_dim) --> (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = context_vec.transpose(1, 2)\n",
    "\n",
    "        # (b, num_tokens, num_heads, head_dim) --> (b, num_tokens, embed_dim)\n",
    "        context_vec = context_vec.contiguous().view(batch_size, num_tokens, embed_dim)\n",
    "\n",
    "        context_vec = self.proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "mha_combined_qkv = MultiHeadAttentionCombinedQKV(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_combined_qkv(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b14390d-3e21-43fd-87be-43e7029163ee",
   "metadata": {
    "id": "9b14390d-3e21-43fd-87be-43e7029163ee"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 4) Multi-head attention with Einsum\n",
    "\n",
    "- Implementing multi-head attention using Einstein summation via [`torch.einsum`](https://pytorch.org/docs/stable/generated/torch.einsum.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92481814-068d-439b-a65c-b1310ebbe0aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92481814-068d-439b-a65c-b1310ebbe0aa",
    "outputId": "59a75f6e-ef06-418f-8e54-d3b368fbed13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class MHAEinsum(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads\n",
    "\n",
    "        # Initialize parameters for Q, K, V\n",
    "        self.W_query = nn.Parameter(torch.randn(d_out, d_in))\n",
    "        self.W_key = nn.Parameter(torch.randn(d_out, d_in))\n",
    "        self.W_value = nn.Parameter(torch.randn(d_out, d_in))\n",
    "\n",
    "        if qkv_bias:\n",
    "            self.bias_q = nn.Parameter(torch.zeros(d_out))\n",
    "            self.bias_k = nn.Parameter(torch.zeros(d_out))\n",
    "            self.bias_v = nn.Parameter(torch.zeros(d_out))\n",
    "        else:\n",
    "            self.register_parameter(\"bias_q\", None)\n",
    "            self.register_parameter(\"bias_k\", None)\n",
    "            self.register_parameter(\"bias_v\", None)\n",
    "\n",
    "        self.out_proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "        # Initialize parameters\n",
    "        self.reset_parameters()\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.W_query, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_key, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_value, a=math.sqrt(5))\n",
    "        if self.bias_q is not None:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.W_query)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias_q, -bound, bound)\n",
    "            nn.init.uniform_(self.bias_k, -bound, bound)\n",
    "            nn.init.uniform_(self.bias_v, -bound, bound)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        \"\"\"\n",
    "        x的shape是 batch_num, num_tokens, embed_dim\n",
    "        W_query的shape是d_in, d_out\n",
    "        \"\"\"\n",
    "        # Calculate Q, K, V using einsum, first perform linear transformations\n",
    "        Q = torch.einsum(\"bnd,di->bni\", x, self.W_query)\n",
    "        K = torch.einsum(\"bnd,di->bni\", x, self.W_key)\n",
    "        V = torch.einsum(\"bnd,di->bni\", x, self.W_value)\n",
    "\n",
    "        # print(\"x.shape:\", x.shape)\n",
    "        # print(\"W_query.shape:\", self.W_query.shape)\n",
    "        # print(\"Q.shape:\", Q.shape)\n",
    "        # Add biases if they are used\n",
    "        if self.bias_q is not None:\n",
    "            Q += self.bias_q\n",
    "            K += self.bias_k\n",
    "            V += self.bias_v\n",
    "\n",
    "        # Reshape for multi-head attention\n",
    "        Q = Q.view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(b, n, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        # 等价于：Q @ K.transpose(-2, -1)\n",
    "        scores = torch.einsum(\"bhnd,bhmd->bhnm\", Q, K) / (self.head_dim ** 0.5)\n",
    "\n",
    "        # Apply mask\n",
    "        mask = self.mask[:n, :n].unsqueeze(0).unsqueeze(1).expand(b, self.num_heads, n, n)\n",
    "        scores = scores.masked_fill(mask.bool(), -torch.inf)\n",
    "\n",
    "        # Softmax and dropout\n",
    "        attn_weights = torch.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Aggregate the attended context vectors\n",
    "        context_vec = torch.einsum(\"bhnm,bhmd->bhnd\", attn_weights, V)\n",
    "\n",
    "        # Combine heads and project the output\n",
    "        context_vec = context_vec.transpose(1, 2).reshape(b, n, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)\n",
    "\n",
    "        return context_vec\n",
    "\n",
    "\n",
    "mha_einsum = MHAEinsum(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_einsum(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a042d3-ee78-4c29-bf63-d92fe6706632",
   "metadata": {
    "id": "48a042d3-ee78-4c29-bf63-d92fe6706632"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 5) Multi-head attention with PyTorch's scaled dot product attention and FlashAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e346f-3b85-44e6-9feb-f01131381148",
   "metadata": {
    "id": "f78e346f-3b85-44e6-9feb-f01131381148"
   },
   "source": [
    "- The implementation below uses PyTorch's [`scaled_dot_product_attention`](https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html) function, which implements a memory-optimized version of self-attention called [FlashAttention](https://arxiv.org/abs/2205.14135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b8e5a0d-1f65-4a03-bf6e-723f0cc428f5",
   "metadata": {
    "id": "1b8e5a0d-1f65-4a03-bf6e-723f0cc428f5"
   },
   "outputs": [],
   "source": [
    "class MHAPyTorchScaledDotProduct(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_out % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.context_length = context_length\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.d_out = d_out\n",
    "\n",
    "        self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, embed_dim = x.shape\n",
    "\n",
    "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        # (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
    "        qkv = qkv.view(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
    "\n",
    "        # (b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        # (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_heads, num_tokens, head_dim)\n",
    "        queries, keys, values = qkv\n",
    "\n",
    "        use_dropout = 0. if not self.training else self.dropout\n",
    "\n",
    "        \"\"\"\n",
    "        # 相比传统实现\n",
    "        attn_scores = queries @ keys.transpose(-2, -1)\n",
    "        attn_scores = attn_scores.masked_fill(mask, -float('inf'))\n",
    "        attn_weights = F.softmax(attn_scores / math.sqrt(d_k), dim=-1)\n",
    "        attn_weights = F.dropout(attn_weights, p=dropout_p)\n",
    "        context_vec = attn_weights @ values\n",
    "\n",
    "        减少中间结果的内存占用, 优化GPU显存使用\n",
    "        \"\"\"\n",
    "        context_vec = nn.functional.scaled_dot_product_attention(\n",
    "            queries, keys, values, attn_mask=None, dropout_p=use_dropout, is_causal=True)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.transpose(1, 2).contiguous().view(batch_size, num_tokens, self.d_out)\n",
    "\n",
    "        context_vec = self.proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc8ba92-3471-41cb-b1b2-4c0ef5be392b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbc8ba92-3471-41cb-b1b2-4c0ef5be392b",
    "outputId": "087a53e7-86d8-48dc-bf2e-023f0f2104cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "mha_pytorch_scaled = MHAPyTorchScaledDotProduct(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_pytorch_scaled(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51492724-6018-49f6-8bf6-ae9e585229c3",
   "metadata": {
    "id": "51492724-6018-49f6-8bf6-ae9e585229c3"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 6) PyTorch's scaled dot product attention without FlashAttention\n",
    "\n",
    "- This is similar to above, except that we disable FlashAttention by passing an explicit causal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bad53538-e905-4065-ba0c-caacdfec5a0b",
   "metadata": {
    "id": "bad53538-e905-4065-ba0c-caacdfec5a0b"
   },
   "outputs": [],
   "source": [
    "class MHAPyTorchSDPAWithoutFlash(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_out % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.context_length = context_length\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.d_out = d_out\n",
    "\n",
    "        self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = dropout\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, embed_dim = x.shape\n",
    "\n",
    "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        # (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
    "        qkv = qkv.view(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
    "\n",
    "        # (b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        # (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_heads, num_tokens, head_dim)\n",
    "        queries, keys, values = qkv\n",
    "\n",
    "        use_dropout = 0. if not self.training else self.dropout\n",
    "\n",
    "        # Ensure attn_mask is compatible with expected shape and `batch_first=True`\n",
    "        # No need to manually adjust for num_heads; ensure it's right for the sequence\n",
    "        if self.context_length >= num_tokens:\n",
    "            attn_mask = self.mask[:num_tokens, :num_tokens]\n",
    "        else:\n",
    "            attn_mask = self.mask[:self.context_length, :self.context_length]\n",
    "\n",
    "        \"\"\"\n",
    "        MHAPyTorchScaledDotProduct不显式定义掩码，而是通过is_causal=True参数让PyTorch自动处理。\n",
    "\n",
    "        # MHAPyTorchScaledDotProduct\n",
    "        scaled_dot_product_attention(\n",
    "            queries, keys, values,\n",
    "            attn_mask=None,  # 不传入掩码\n",
    "            dropout_p=use_dropout,\n",
    "            is_causal=True   # 使用内置因果掩码\n",
    "        )\n",
    "        MHAPyTorchSDPAWithoutFlash显式定义和管理掩码：\n",
    "\n",
    "        # MHAPyTorchSDPAWithoutFlash\n",
    "        scaled_dot_product_attention(\n",
    "            queries, keys, values, \n",
    "            attn_mask=attn_mask,  # 显式传入掩码\n",
    "            dropout_p=use_dropout, \n",
    "            is_causal=False\n",
    "        )\n",
    "        \"\"\"\n",
    "        context_vec = nn.functional.scaled_dot_product_attention(\n",
    "            queries, keys, values, attn_mask=attn_mask, dropout_p=use_dropout, is_causal=False)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.transpose(1, 2).contiguous().view(batch_size, num_tokens, self.d_out)\n",
    "\n",
    "        context_vec = self.proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3da7850-e772-47d3-bd51-22d077b01412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3da7850-e772-47d3-bd51-22d077b01412",
    "outputId": "cc8fc837-8e06-42fc-bad5-b17816f47fcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "mha_pytorch_sdpa_no_flash = MHAPyTorchSDPAWithoutFlash(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_pytorch_sdpa_no_flash(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c318f-4835-4d74-8d58-a070222447c4",
   "metadata": {
    "id": "351c318f-4835-4d74-8d58-a070222447c4"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 7) Using PyTorch's torch.nn.MultiheadAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a6d060-6324-48fa-a35c-cb09f2a48965",
   "metadata": {
    "id": "74a6d060-6324-48fa-a35c-cb09f2a48965"
   },
   "source": [
    "- Below, we use PyTorch's [torch.nn.MultiheadAttention](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html) implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3799c7ef-3155-42c6-a829-f95656453ae0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3799c7ef-3155-42c6-a829-f95656453ae0",
    "outputId": "78236eea-a0f4-47e4-c846-606e7f8f8768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MHAPyTorchClass(nn.Module):\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout=0.0, qkv_bias=False, need_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.context_length = context_length\n",
    "        self.multihead_attn = nn.MultiheadAttention(\n",
    "            embed_dim=d_out,        # 输入/输出的特征维度\n",
    "            num_heads=num_heads,    # 注意力头数\n",
    "            dropout=dropout,        # dropout率\n",
    "            bias=qkv_bias,          # 是否使用偏置\n",
    "            add_bias_kv=qkv_bias,   # 是否为k/v添加偏置\n",
    "            batch_first=True,       # 输入格式为(batch, num_tokens, embed_dim)\n",
    "        )\n",
    "\n",
    "        self.need_weights = need_weights\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1).bool())\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, _ = x.shape\n",
    "\n",
    "        # Ensure attn_mask is compatible with expected shape and `batch_first=True`\n",
    "        # No need to manually adjust for num_heads; ensure it's right for the sequence\n",
    "        if self.context_length >= num_tokens:\n",
    "            attn_mask = self.mask[:num_tokens, :num_tokens]\n",
    "        else:\n",
    "            attn_mask = self.mask[:self.context_length, :self.context_length]\n",
    "\n",
    "        # attn_mask broadcasting will handle batch_size dimension implicitly\n",
    "        # x的形状: (batch_size, num_tokens, embed_dim)\n",
    "        attn_output, _ = self.multihead_attn(\n",
    "            x, x, x, attn_mask=attn_mask, need_weights=self.need_weights\n",
    "        )\n",
    "\n",
    "        output = self.proj(attn_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "mha_pytorch_class_default = MHAPyTorchClass(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False\n",
    ").to(device)\n",
    "\n",
    "out = mha_pytorch_class_default(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3953bff-1056-4de2-bfd1-dfccf659eee4",
   "metadata": {
    "id": "a3953bff-1056-4de2-bfd1-dfccf659eee4"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 8) Using PyTorch's torch.nn.MultiheadAttention with `scaled_dot_product_attention`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2164859-31a0-4537-b4fb-27d57675ba77",
   "metadata": {
    "id": "d2164859-31a0-4537-b4fb-27d57675ba77"
   },
   "source": [
    "- Set `need_weights` (default `True`) to `False` so that `MultiheadAttention` uses `scaled_dot_product_attention` [according to the documentation](https://github.com/pytorch/pytorch/blob/71d020262793542974cf13b30f2a9099773f015c/torch/nn/modules/activation.py#L1096)\n",
    "\n",
    "```markdown\n",
    "need_weights: If specified, returns `attn_output_weights` in addition to `attn_outputs`.\n",
    "           Set `need_weights=False` to use the optimized `scaled_dot_product_attention`\n",
    "           and achieve the best performance for MHA.\n",
    "           Default: `True`\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a4c2afe-5e1f-4bd7-a118-67031176f147",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4a4c2afe-5e1f-4bd7-a118-67031176f147",
    "outputId": "6359dcff-ddcf-4cf9-eada-c3f0685cced2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "mha_pytorch_class_noweights = MHAPyTorchClass(\n",
    "    d_in=embed_dim,\n",
    "    d_out=embed_dim,\n",
    "    context_length=context_len,\n",
    "    dropout=0.0,\n",
    "    num_heads=12,\n",
    "    qkv_bias=False,\n",
    "    need_weights=False # NEW!\n",
    ").to(device)\n",
    "\n",
    "out = mha_pytorch_class_noweights(embeddings)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4ff35-651c-4e47-bfa1-016f3de01ecc",
   "metadata": {
    "id": "21f4ff35-651c-4e47-bfa1-016f3de01ecc"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## 9) Using PyTorch's FlexAttention\n",
    "\n",
    "- See [FlexAttention: The Flexibility of PyTorch with the Performance of FlashAttention](https://pytorch.org/blog/flexattention/) to learn more about FlexAttention\n",
    "- FlexAttention caveat: It currently doesn't support dropout\n",
    "- This is supported starting from PyTorch 2.5, which you can install on a CPU machine via\n",
    "\n",
    "    ```bash\n",
    "    pip install torch torchvision torchaudio\n",
    "    ```\n",
    "\n",
    "- To install PyTorch on a GPU machine, use the following (for more information, also see the installation menu on [pytorch.org](https://pytorch.org/))\n",
    "\n",
    "    ```bash\n",
    "    pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834318c8-4748-4902-99f0-70ee02bef63e",
   "metadata": {
    "id": "834318c8-4748-4902-99f0-70ee02bef63e"
   },
   "outputs": [],
   "source": [
    "from packaging.version import parse as parse_version\n",
    "\n",
    "def normalize_version(version):\n",
    "    parsed_version = parse_version(version)\n",
    "    return parse_version(f\"{parsed_version.major}.{parsed_version.minor}.{parsed_version.micro}\")\n",
    "\n",
    "current_version = normalize_version(torch.__version__)\n",
    "MIN_TORCH_VERSION = \"2.5.0\"\n",
    "required_version = parse_version(MIN_TORCH_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "WYyFRCXndVH9",
   "metadata": {
    "id": "WYyFRCXndVH9"
   },
   "outputs": [],
   "source": [
    "if current_version >= required_version:\n",
    "    from torch.nn.attention.flex_attention import flex_attention, create_block_mask\n",
    "\n",
    "\n",
    "def causal(b, h, q_idx, kv_idx):\n",
    "    # 确保当前位置只能看到之前的位置\n",
    "    return q_idx >= kv_idx\n",
    "\n",
    "\n",
    "class MHAPyTorchFlexAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, d_in, d_out, num_heads, context_length, dropout=0.0, qkv_bias=False):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_out % num_heads == 0, \"embed_dim is indivisible by num_heads\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.context_length = context_length\n",
    "        self.head_dim = d_out // num_heads\n",
    "        self.d_out = d_out\n",
    "\n",
    "        self.qkv = nn.Linear(d_in, 3 * d_out, bias=qkv_bias)\n",
    "        self.proj = nn.Linear(d_out, d_out)\n",
    "        self.dropout = dropout\n",
    "        # self.register_buffer(\"block_mask\", create_block_mask(causal, B=None, H=None, Q_LEN=context_length, KV_LEN=context_length))\n",
    "        # `create_block_mask` function does not support buffers, yet\n",
    "        # 创建block_mask用于因果注意力\n",
    "        self.block_mask = create_block_mask(\n",
    "            causal,  # 使用上面定义的causal函数\n",
    "            B=None,  # batch size动态确定\n",
    "            H=None,  # heads动态确定\n",
    "            Q_LEN=context_length, \n",
    "            KV_LEN=context_length\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, num_tokens, embed_dim = x.shape\n",
    "\n",
    "        # (b, num_tokens, embed_dim) --> (b, num_tokens, 3 * embed_dim)\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        # (b, num_tokens, 3 * embed_dim) --> (b, num_tokens, 3, num_heads, head_dim)\n",
    "        qkv = qkv.view(batch_size, num_tokens, 3, self.num_heads, self.head_dim)\n",
    "\n",
    "        # (b, num_tokens, 3, num_heads, head_dim) --> (3, b, num_heads, num_tokens, head_dim)\n",
    "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
    "\n",
    "        # (3, b, num_heads, num_tokens, head_dim) -> 3 times (b, num_heads, num_tokens, head_dim)\n",
    "        queries, keys, values = qkv\n",
    "\n",
    "        # use_dropout = 0. if not self.training else self.dropout\n",
    "\n",
    "        # Ensure attn_mask is compatible with expected shape and `batch_first=True`\n",
    "        # No need to manually adjust for num_heads; ensure it's right for the sequence\n",
    "        if self.context_length >= num_tokens:\n",
    "            attn_mask = self.block_mask[:num_tokens, :num_tokens]\n",
    "        else:\n",
    "            attn_mask = self.block_mask[:self.context_length, :self.context_length]\n",
    "\n",
    "        # 使用flex_attention计算注意力\n",
    "        context_vec = flex_attention(\n",
    "            queries,     # (b, num_heads, num_tokens, head_dim)\n",
    "            keys,        # (b, num_heads, num_tokens, head_dim)\n",
    "            values,      # (b, num_heads, num_tokens, head_dim)\n",
    "            block_mask=attn_mask  # 因果掩码\n",
    "        )\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.transpose(1, 2).contiguous().view(batch_size, num_tokens, self.d_out)\n",
    "\n",
    "        context_vec = self.proj(context_vec)\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cdaaf8a-f956-44bc-932f-4d33448e8aaf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cdaaf8a-f956-44bc-932f-4d33448e8aaf",
    "outputId": "a88a7398-159e-401f-d96c-2fc928908e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "if current_version >= required_version and torch.cuda.is_available():\n",
    "\n",
    "    mha_pytorch_flex = MHAPyTorchFlexAttention(\n",
    "        d_in=embed_dim,\n",
    "        d_out=embed_dim,\n",
    "        context_length=context_len,\n",
    "        dropout=0.0,\n",
    "        num_heads=12,\n",
    "        qkv_bias=False\n",
    "    ).to(device)\n",
    "\n",
    "    out = mha_pytorch_flex(embeddings)\n",
    "    print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8877de71-f84f-4f6d-bc87-7552013b6301",
   "metadata": {
    "id": "8877de71-f84f-4f6d-bc87-7552013b6301"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## Quick speed comparison (M3 Macbook Air CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "219cf93a-078f-434d-888c-2458d0731285",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "219cf93a-078f-434d-888c-2458d0731285",
    "outputId": "a10b52d4-b4e6-43c2-9677-113c41edd3b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu121\n",
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a97c0b2e-6593-49d8-98bc-2267b3aa610f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a97c0b2e-6593-49d8-98bc-2267b3aa610f",
    "outputId": "7bcd7da4-d115-4ba6-efba-377a0bd7d3a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.3 ms ± 668 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 1) CausalAttention MHA wrapper class from chapter 3\n",
    "%timeit mha_ch03_wrapper(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19db9c2c-8e75-431a-8eef-0b4d8284e6e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19db9c2c-8e75-431a-8eef-0b4d8284e6e6",
    "outputId": "b04b4d0d-71aa-4944-f02b-131bf5a50202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 ms ± 1.1 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 2) The multi-head attention class from chapter 3\n",
    "%timeit mha_ch03(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa526ee0-7a88-4f34-a49a-f8f97da83779",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa526ee0-7a88-4f34-a49a-f8f97da83779",
    "outputId": "5436928a-7b98-4c40-bf51-97973f13327e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.3 ms ± 2.8 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 3) An alternative multi-head attention with combined weights\n",
    "%timeit mha_combined_qkv(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "131ca826-35bf-47e5-b497-540aba439ef9",
   "metadata": {
    "id": "131ca826-35bf-47e5-b497-540aba439ef9",
    "outputId": "f5848852-f81b-4e5f-a7ff-e37a8445ad91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45.6 ms ± 1.51 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 4) Multi-head attention using Einstein summation\n",
    "%timeit mha_einsum(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc2b4256-16d8-4c34-9fd0-d4b4af0e60fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cc2b4256-16d8-4c34-9fd0-d4b4af0e60fa",
    "outputId": "9e07ce73-a2de-4e2c-8276-64626df9450e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.6 ms ± 2.93 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 5) Multi-head attention with PyTorch's scaled dot product attention\n",
    "%timeit mha_pytorch_scaled(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c44305ce-9f61-451a-b9ef-30caba222357",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c44305ce-9f61-451a-b9ef-30caba222357",
    "outputId": "6bab4a24-5bb4-4ad6-b260-3b442f598950"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.8 ms ± 863 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 6) PyTorch's scaled dot product attention without FlashAttention\n",
    "%timeit mha_pytorch_sdpa_no_flash(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f209e70-ebb6-4a1a-b608-1ff42e41c01d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f209e70-ebb6-4a1a-b608-1ff42e41c01d",
    "outputId": "630c49d1-8a06-4148-cd96-a7b2467310a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.8 ms ± 11.5 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 7) Using PyTorch's torch.nn.MultiheadAttention\n",
    "%timeit mha_pytorch_class_default(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f4968c2-8d40-4ab9-8dba-052b4f77d756",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f4968c2-8d40-4ab9-8dba-052b4f77d756",
    "outputId": "10f6a268-f9cf-446c-aa83-e87b6a0b4f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.4 ms ± 825 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 8) Using PyTorch's torch.nn.MultiheadAttention disabling `need_weights`\n",
    "%timeit mha_pytorch_class_noweights(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdd8e0fc-ef24-424c-bccf-c381e73da228",
   "metadata": {
    "id": "bdd8e0fc-ef24-424c-bccf-c381e73da228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.8 ms ± 780 μs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "## 9) Using PyTorch's FlexAttention\n",
    "\n",
    "# Requires PyTorch 2.5.0 or newer and currently only supports CUDA PyTorch\n",
    "%timeit mha_pytorch_flex(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ff594-6cc2-496d-a302-789fa104c3c9",
   "metadata": {
    "id": "a78ff594-6cc2-496d-a302-789fa104c3c9"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "## Quick speed comparison (Nvidia A100 GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "RStnI1pEi6Eo",
   "metadata": {
    "id": "RStnI1pEi6Eo"
   },
   "outputs": [],
   "source": [
    "# Enable tensor cores\n",
    "torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8431d75-e1c9-4d9a-b7da-9a1ff391f2bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8431d75-e1c9-4d9a-b7da-9a1ff391f2bf",
    "outputId": "f6356d4c-7a3f-47f5-cf51-5507db3f5748"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu121\n",
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "707a2a14-a089-48a8-88aa-d328e1e0a9d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "707a2a14-a089-48a8-88aa-d328e1e0a9d0",
    "outputId": "4ea5798b-a590-401b-d049-3fed0716db34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.9 ms ± 341 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 1) CausalAttention MHA wrapper class from chapter 3\n",
    "%timeit mha_ch03_wrapper(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8686dd69-3655-40e4-a57b-a2c55532a010",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8686dd69-3655-40e4-a57b-a2c55532a010",
    "outputId": "88094b61-4d87-47bd-8c8b-c9344ab57062"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.3 ms ± 515 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 2) The multi-head attention class from chapter 3\n",
    "%timeit mha_ch03(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2209d7df-e54b-4910-ae2b-c78cf684d9bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2209d7df-e54b-4910-ae2b-c78cf684d9bf",
    "outputId": "e3d82c53-f75b-425a-ed3e-5e48ea9ef768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.6 ms ± 1.17 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 3) An alternative multi-head attention with combined weights\n",
    "%timeit mha_combined_qkv(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abee5edf-2585-4f0e-846c-b1c7ca88f545",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abee5edf-2585-4f0e-846c-b1c7ca88f545",
    "outputId": "c9bf17f5-de62-4c39-a328-fe430812b156"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.9 ms ± 1.08 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 4) Multi-head attention using Einstein summation\n",
    "%timeit mha_einsum(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1075abe2-4839-4fd6-af3e-c09bb3651e26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1075abe2-4839-4fd6-af3e-c09bb3651e26",
    "outputId": "b63f4769-3be5-44df-b8f2-2ac379be1ff4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.5 ms ± 3.33 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 5) Multi-head attention with PyTorch's scaled dot product attention\n",
    "%timeit mha_pytorch_scaled(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "218adbaf-f17f-47d9-81d5-41c758218df7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "218adbaf-f17f-47d9-81d5-41c758218df7",
    "outputId": "a30ab365-865d-4175-f148-dc15abc4e07a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.7 ms ± 530 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 6) PyTorch's scaled dot product attention without FlashAttention\n",
    "%timeit mha_pytorch_sdpa_no_flash(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "868e3670-8edc-47bc-9e06-eb505e44dc9d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "868e3670-8edc-47bc-9e06-eb505e44dc9d",
    "outputId": "e20e77ac-6573-4830-82c7-795bd139af4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.6 ms ± 16.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 7) Using PyTorch's torch.nn.MultiheadAttention\n",
    "%timeit mha_pytorch_class_default(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "944870e6-de54-4e3b-a455-b8f21f6f92c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "944870e6-de54-4e3b-a455-b8f21f6f92c8",
    "outputId": "26df6295-fa5c-4b3f-89be-c7183f079fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.8 ms ± 612 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "## 8) Using PyTorch's torch.nn.MultiheadAttention disabling `need_weights`\n",
    "%timeit mha_pytorch_class_noweights(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "evKtpb5QN_2A",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evKtpb5QN_2A",
    "outputId": "23bf5398-c8ec-4463-8af9-17de8f920a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.4 ms ± 1.78 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "## 9) Using PyTorch's FlexAttention\n",
    "\n",
    "# Requires PyTorch 2.5.0 or newer\n",
    "%timeit mha_pytorch_flex(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc6575-0316-4640-a729-e616d5c17b73",
   "metadata": {
    "id": "dabc6575-0316-4640-a729-e616d5c17b73"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbb2f729-d3d8-46d0-b249-9249197ea574",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bbb2f729-d3d8-46d0-b249-9249197ea574",
    "outputId": "a45fe256-6416-4f43-87d2-27bbf97239e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.0+cu121\n",
      "Running on cuda\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Running on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0620bf5",
   "metadata": {
    "id": "b0620bf5"
   },
   "outputs": [],
   "source": [
    "functions = {\n",
    "    \"1) MHA wrapper class\": mha_ch03_wrapper,\n",
    "    \"2) MHA Ch03\": mha_ch03,\n",
    "    \"3) MHA with combined QKV weights\": mha_combined_qkv,\n",
    "    \"4) MHA with Einsum\": mha_einsum,\n",
    "    \"5) MHA with PyTorch scaled_dot_product_attention\": mha_pytorch_scaled,\n",
    "    \"6) PyTorch's SDPA, no FlashAttention\": mha_pytorch_sdpa_no_flash,\n",
    "    \"7) PyTorch MHA class defaults\": mha_pytorch_class_default,\n",
    "    \"8) PyTorch MHA with need_weights=False\": mha_pytorch_class_noweights\n",
    "    }\n",
    "\n",
    "if current_version >= required_version:\n",
    "    functions[\"8) PyTorch's FlexAttention\"] =  mha_pytorch_flex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "CDJAPZaszaqx",
   "metadata": {
    "id": "CDJAPZaszaqx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Customize further for dark mode aesthetics\n",
    "plt.rcParams[\"figure.facecolor\"] = \"#121212\"\n",
    "plt.rcParams[\"axes.facecolor\"] = \"#121212\"\n",
    "plt.rcParams[\"axes.edgecolor\"] = \"white\"\n",
    "plt.rcParams[\"axes.labelcolor\"] = \"white\"\n",
    "plt.rcParams[\"text.color\"] = \"white\"\n",
    "plt.rcParams[\"xtick.color\"] = \"white\"\n",
    "plt.rcParams[\"ytick.color\"] = \"white\"\n",
    "plt.rcParams[\"grid.color\"] = \"#444444\"\n",
    "plt.rcParams[\"lines.linewidth\"] = 2\n",
    "plt.rcParams[\"lines.markersize\"] = 8\n",
    "\n",
    "def plot_execution_times(functions, execution_means, execution_stds, filename):\n",
    "\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots()\n",
    "    bars = ax.bar(functions.keys(), execution_means, yerr=execution_stds, capsize=5, error_kw={'ecolor': 'grey'})\n",
    "\n",
    "    plt.ylabel(\"Execution time (ms)\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "\n",
    "    # Calculate new ylim with a margin\n",
    "    max_execution_time = max(execution_means)\n",
    "    upper_ylim = max_execution_time + 0.4 * max_execution_time  # Adding a 40% margin\n",
    "    plt.ylim(0, upper_ylim)\n",
    "\n",
    "    # Annotate bars with execution times\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval + (0.05 * upper_ylim), round(yval, 2), ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df834dc",
   "metadata": {
    "id": "4df834dc"
   },
   "source": [
    "## Speed comparison (Nvidia A100 GPU) with warmup (forward pass only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29b63d3d-6d0b-43bb-9c68-d5514dc81000",
   "metadata": {
    "id": "29b63d3d-6d0b-43bb-9c68-d5514dc81000"
   },
   "outputs": [],
   "source": [
    "# CUDA benchmark code shared by Andrei Aksionov\n",
    "# and based on code from\n",
    "# https://github.com/cuda-mode/lectures/blob/main/lecture1/pytorch_square.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def time_pytorch_function(func, *input, num_repeats=1_000):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        func(*input)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    times = []\n",
    "    for _ in range(num_repeats):\n",
    "        start.record()\n",
    "        func(*input)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        times.append(start.elapsed_time(end))\n",
    "\n",
    "    return np.mean(times), np.std(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9dd07a09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "9dd07a09",
    "outputId": "491d06f4-a6bc-431a-a1ca-4db38df57e0c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnIAAAHWCAYAAADzS2TwAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAyNJJREFUeJzt3QeUZUXV/v8iZ5UhZwQTWUFykgwSBEEwgREQEJAkWeQlSpIgOQko8gICAoJIkhwkB0kKkiSLApKR//rU+6v+n7l0z/Qw4da5vb9r9erp201zq885VU/t/exd4w0bNuz9FARBEARBELSO8bv9BoIgCIIgCIIPRwi5IAiCIAiClhJCLgiCIAiCoKWEkAuCIAiCIGgpIeSCIAiCIAhaSgi5IAiCIAiClhJCLgiCIAiCoKWEkAuCIAiCIGgpE3b7DbSdmWaaKb322mvdfhtBEARBEPQYU045ZXrmmWdG+DMh5EZTxN13333dfhtBEARBEPQo888//wjFXAi50aBE4vyRIyoXBEEQBMGYjMYJFo1MX4SQGwP4I7/66qvdfhtBEARBEAwxotghCIIgCIKgpYSQC4IgCIIgaCkh5IIgCIIgCFpKCLkgCIIgCIKWEkIuCIIgCIKgpYSQC4IgCIIgaCkh5IIgCIIgCFpKzwq58ccfP+26667pjjvuSE899VS67bbb0g477PCBn9tll13S/fffn3/mvPPOS3PNNVdX3m8QBEEQBMGo0rNCbtttt03f+c530s4775yWXHLJtPfee6dtttkmbbbZZn0/U77ecccd06qrrppef/31dM4556RJJpmkq+89CIIgCIJgMPTsyQ6LLrpouvTSS9Pll1+ev37yySfT+uuvnxZeeOG+n9l8883ToYcemn8OW2yxRXrwwQfTF7/4xXT++ed37b0HQRAEQRAM6Yjcn//857TccsulueeeO38933zzpcUXXzxdccUV+es55pgjzTjjjOmaa67p+28cs3X77bdnEdgfE088cZpqqqn6PpyDFgRBEARB0C16NiJ3+OGHZ7F18803p/feey9NMMEEab/99kvnnntu/v7000+fP7/wwgvD/Xe+Lt/r5Ec/+lFO1QZBEARBENRAzwq5ddddN22wwQbZAyddusACC2Qh9+yzz6azzjrrQ4vDY489tu9rEbn77rtvDL7rIAiCIAiCwdOzQk5xwxFHHNHndXvggQfSbLPNlqNqhNzzzz+fX59uuunSc8891/ff+Xogcfb222/njyAIgiAIghroWY/cZJNNlv773/8O95oU63jjjZf//fjjj+foHB9dQSp2kUUWyf66IAiCIAiC2unZiNxll12Wtt9++9wfTmp1wQUXzFWpZ555Zt/PHH/88bm33KOPPpqF3W677ZbF3SWXXNLV9x4EQRAEQTCkhZxGvxoCH3zwwWnaaafNAu20007LXxeOPPLINPnkk6fDDjssffSjH0233HJL2nDDDdNbb73V1fceBEEQBEEwGMYbNmzY+4P6yeADSMX+/e9/T3POOWduXRIEQRAEQTAuNUbPeuSCIAiCIAh6nRByQRAEQRAELaU6j9zss8+ez0adddZZs3/txRdfTPfee2+uJA3vWhAEQRAEQYVCTvNeZ59+9rOfzT3eFCe8+eabaeqpp875YSLOqQx6w6lEDYIgCIIgGOpUIeSuvvrq9M4776Tf/OY36Vvf+lb6xz/+8YEzTp1/ut5666Urr7wy7bTTTunCCy/s2vsNgiAIgiCogSqqVldYYYUs5gaDCJ3069133526TVStBkEQBEHQTY1RTURusLz88sv5IwiCIAiCYKhTXdWqExjmmWeevq/XWGONdMYZZ6Q99tgjTTTRRF19b0EQBEEQBDVRnZBzysInPvGJ/O855pgjnXjiien1119P66yzTvrpT3/a7bcXBEEQBEFQDdUJubnnnju3G8GXvvSldNNNN+Vq1h/+8Idp7bXX7vbbC4IgCIJgHDDTTDOl4447Lj3yyCO5W8V1112XO1sU1lprrdzNwvdfeumlNP/884/0d0444YRpxx13TLfddlt6+umn0zXXXJNWXHHF4X5myimnTPvtt1+666678v/30ksvTZ/73OdSrVQn5MYbb7w0/vj/97aWX375dPnll+d/+4MPGzasy+8uCIIgCIKxjfPPL7nkktzRYqONNkpLLbVU2nPPPdO//vWvvp/Ra/bmm29Oe++996B/7+67756+/e1v5/PY/c5f/vKX6fTTT08LLLBA388cfvjh6Qtf+ELaYost0rLLLpt9/Oedd14WljVSRbFDEwp4hx12yCrZH5lyLmnWF154odtvLwiCIAiCscy2226bAzhbb71132tPPPHEcD9z9tln58+zzTbboH/vhhtumC1cV1xxRf761FNPzUGjrbbaKv3gBz9Ik046ac7+ffOb38wZQRx00EFptdVWS9/5znfS/vvvn2qjuojcbrvtlgsefvazn+U/9mOPPZZf55G79dZbu/32giAIgiAYy6y++uo5sHPKKaekBx98MEfFNt5449H+vRNPPHE+bKCJrxdffPG+1KuPzpOkmj9TG9VF5P7yl7/kUGYne+21V3rvvfe68p6CIAiCIBh3yMKJgB177LHp5z//efaoHXDAATnVetZZZ33o33vVVVelLbfcMkfbBIpE49Zcc800wQQT5O+/9tprOWgkM/jwww/nk6bWX3/9fChBCSzVRnURuSZTTDFFbojng4qebLLJuv2WgiAIgiAYy/DK33PPPWnffffNBZB8bFqR8beNbtbv0Ucfzd46R4HK/jlV6r///W/fz/DG8evff//96ZlnnkmbbbZZ9sg1f6YmqhNyTm3wR5ULp37/9re/5Q9/eJ+DIAiCIOhtnnvuufTQQw8N95oI2ayzzjpav/ell17KKVq+OhWw0qX/+c9/0uOPP973M05TYOfyM6xeq6yySk63er1GqkutKjWmhLfZZptc3PD++10/QSwIgiAIgnHILbfc0tdTttme7Mknnxwjv/+tt97K0TYCTRuT3/3udx/4GT1sfaig1aKk1l621Qm5+eabL6200krpr3/9a7ffShAEQRAEXQrq6N+23XbbpQsuuCAtvPDCaZNNNknbb79938987GMfyxG6GWecMX9dhB9fmw8cc8wxWbDts88++etFFlkktxGRrvV55513zmncI488crjz3wWU6JC55porCzi96s4888xUI9UJuTvvvDPNMsssIeSCIAiCYIhCCxBuesdpQ8ZupQecBsDNIzx/8Ytf9H198skn5898b1qGgJ5oetsmmWSS7JNTTCGlqg0JT9wrr7zS9zMf+chH8v935plnzme7X3zxxdmr9+6776YaGW/YsGFV5S7nnHPOdOihh6ZzzjknPfDAA7lCpbOqtRYUYciZe8+vvvpqt99OEARBEAQ9wmA1RnURuWmnnTa/6aOOOqrvNT45YU6fp59++q6+vyAIgiAIglqoTsjJU8tdK/eV445ihyAIgiAIgpYIOcbFb3zjG9U23guCIAiCIKiF6vrIXXfddWn++efv9tsIgiAIgiConuoicpdddlmuDplnnnn6LXb4wx/+0LX3FgRBEARBfUw++eT5NKhRReWqXnFtprqqVU2AB6K2YoeoWg2CIAiC7rP44ot/qEPtNR72USOtrVqdbrrpuv0WgiAIgiBoEffee28+yrOTL33pSzlaJ+rW3+kNInJtpzohFwRBEARBMCq8/v+O0+qkNAP2eUQZvzZTRbHDeuutN+if1Wl5scUWG6vvJwiCIAiCoA1UIeS+853vpJtuuiltvfXW6VOf+lS/eeKVV145HX/88enqq69Ow4YN68r7DIIgCIIgqIkqUqvrrLNOWn311dOmm26azzcTHtUM+K233sqH4ipweOmll9JZZ52VlllmmZ4NjwZBEARBELROyJW2Ij5E25ZYYoncGHiyySbLAo6J8Z577hnlUx5mmmmmtNdee6WVVlop/y5NhkX97rrrrr6f2WWXXdLGG2+cPvrRj6Zbb701H87bn2EyCIIgCIKxx1Sbnj7Gf+d4k96dUnonjTfF1GP897964iapBqoRcoV//vOf6ZJLLhnt30OY+T3XX3992mijjdKLL76Y5pprrvSvf/2r72e22WabfBTYVlttlR5//PG02267pXPOOScttdRSORoYBEEQBEFQM9UJuTHFtttum55++ukcgSs88cQTw/3M5ptvng499NB06aWX5q+32GKL9OCDD6YvfvGL6fzzzx/n7zkIgiAIgqB1xQ5jA547KdRTTjklizNFElKohTnmmCPNOOOM6Zprrul7TcO922+/PS266KL9/s6JJ544F16UjymnnHKcjCUIgiAIgmBICTlCTTUsv9tXvvKVdOqpp6YDDjggffWrX83fLydEdBZO+Hqg0yN+9KMf5S7L5eO+++4bByMJgiAIgiAYYqnV8ccfP0fknNsKBRPOb/32t7+dq18/DIcffng69thj+74WkQsxFwRBEATdZbL0dpp8vOHPZsf46f2+z9OM98FTHF5/f6L0Rpo4tZlqhdxEE02Uo2oqTd97771R/u+fe+659NBDDw332sMPP5zWXnvt/G/tTcqRYH624OuBxNnbb7+dP4IgCIIgqIdPT/hC+txEzwz4/cnGezetM+kDH3j9zndmSne9O0tqM9UJOW1CDjzwwL4UqFMcVJR67ZlnnklHHHHEoH6PQ3A/8YlPDPfa3HPPnZ588sn8b7/z2WefTcstt1yfcON7W2SRRXIaNgiCIAiCdvDQu9OlJ9/72Cj/dyJybac6j5yGwPPPP39uEvzmm2/2va4oYd111x307znuuOPS5z//+bTddtulj3/842n99ddPm2yySTr55JP7fsZJETvssEMujJB2PeaYY7K4GxPtT4IgCIIgGDe8kSZOL70/xSh/tD2tWmVETuuP73//++m2224b7nWVpwTZYLnzzjuzcCMMNfnVemT33XdP5557bt/PHHnkkWnyySdPhx12WO47J4q34YYbRg+5IAiCIAhaQXVCbppppun3CC6Ca1RPdvjjH/+YP0aElK2PIAiCIAiCtlFdalWl6aqrrtr3dRFvesD9+c9/7uI7C4IgCIIgqIvqInLahZx99tnp05/+dJpgggny6Qv+rUkv31wQBEEQBEFQaUSOT2355ZfPIu6BBx5IK6ywQj4nVUHC3Xc7/DYIgiAIgiCoMiIHpyaoNg2CIAiCIAhaJuQw7bTT5g8nNDT5y1/+0rX3FARBEARBUBPVCbmFFlooHX300elTn/pUGm+88Yb7nsKHgc5BDYIgCIIgGGpUJ+T0dvvb3/6Wtt1223yM1qi2HAmCIAiCIBgqVCfk5pxzznywvTNWgyAIgiAIghZVrV577bX5iK4gCIIgCIKgZRE5KVUeuc985jP5WK533nlnuO//4Q9/6Np7C4IgCIIgqInqhJzGv4svvnhaeeWVP/C9KHYIgiAIgiCoWMg59/Scc85JhxxySL9nrgZBEARBEASVeuSGDRuWjj322BBxQRAEQRAEbRNyF198cVpmmWW6/TaCIAiCIAiqp7rUqh5ye+65Z1piiSXyKQ7vvvvucN8/4YQTuvbegiAIgiAIaqI6IffNb34z/ec//0lLLbVU/ugsdgghFwRBEARBUGlqdeGFFx7wY5FFFun22wuCoB++853v5B6Qf//73/OHNkErrbRS3/dVm/O+irI/8cQT6aqrrkprr732KLUleumll9J+++33gQbip59+enrooYfy//fkk09O00033RgdWxAEQc1UJ+SCIGgf//jHP9L//M//pBVXXDELuOuuuy796le/Sp/+9Kfz94855pj0iU98Ikfcl1122fT73/8+i64FFlhgpL/7c5/7XPrWt76V7rvvvuFen3zyydO5556bI/XrrrtuWmONNdLEE0+czjzzzA+c0xwEQdCrVJFa3WeffdIBBxyQXn/99fzvEcE/FwRBXVx22WXDfS1yJkr3+c9/PkfL9Ifcaaed0h133JG/f+ihh6Yf/OAHaaGFFkr33nvvgL93iimmSMcdd1zabrvt0vbbbz/c9xZbbLE0++yzpxVWWCG9+uqr+bUtt9wyPfroo2m55ZZL11xzzVgZaxAEQU1UIeTsyiec8P/eymB26EEQ1Mv444+fvvSlL+WI2W233ZZf+/Of/5yjZn/84x/Tv//97/zvSSaZJN1www0j/F0HHXRQuvzyy7Mo6xRy/nvRuLfeeqvvNf/+73//m5uKh5ALgmAoUIWQM6n39+8gCNrDPPPMk71xk046aS5Y2mSTTXI0Dt/97ndzKlVVumP33njjjfz9xx57bMDft95666UFF1yw31NeQCSK4u+1115p3333zenUn/zkJ3lTOMMMM4y1cQZBENREdR65I488Mk055ZQfeN3u3veCIKiTv/71r+kLX/hCWnXVVdOpp56az0wuHrnddtstffSjH83ijIeOZ+6UU07J4q8/Zp555rT//vunzTfffLiIWxPFD9K3q622Wi6gIAr9P+66664cqQuCIBgKjDds2LCqZrznn38+zTvvvOnFF1/8wIkPDzzwQFU77ammmipXyqmcKx6dIAj+j/POOy+Lq6OOOirdfvvtuZ1QidCV7/Oz7bjjjh/4b7/4xS+mM844Y7g+kiJt0qY+Zppppvy5OT/42VdeeSVXxhKKv/jFL8bBKIMgGFNMtenpqU28euImVWiMKlKr5Q1DekRErrkL57lZZZVVPiDugiCoF88tH9tkk02Wv+6Mkr333nv5Z/pDK5Oll156uNcIs0ceeSQdccQRw4k4/POf/8yfVcRqPyLFGwRBMBSoRsjZmZvofdx6660f+L7Xf/azn3XlvQVBkEZaTX7FFVekp556Km/ENthggyzEvvKVr2TxxRunUpWfjegScZOG/drXvtb3O84///zcluSkk05Kr732WnrwwQeH+3/w3flvm69//etfTw8//HDe5KmMlY7Vr06aNwiCYChQjZBT5SYad8EFF6Rvf/vb6eWXX+773ttvv50XiGeffbar7zEIgv6ZdtppczqT9aGkN4m4P/3pT/n7X/3qV3Mhwq9//evcUkTKdauttsriryB9IEU6KuhNt8cee6Spp546++QOO+ywLOSCIAiGCtV55GadddYs2tpAeOSCUYEx34feZxBZOvjgg9OVV16ZvxaxWn755dOMM86Yo09aduy99945ojUQ0o3NqBb8vg033LDva207WBPmn3/+XDE611xzjbUxBkEQfFjCI9dyj1yhLSIuCD7s6QdsBKLPolROP5BiVARw991355MKPAMiTD/+8Y/z10426PSENRHV2nrrrfu+7qzynGiiidLvfve7LAydrBAEQRD0DtUJuSAYqqcfODO08OSTT2a/l6OuRPDsygaC9UC190AUb2ln5C4IgiBoP9X1kQuCoYBqTT3VmqcfNPE6Iz8B9/TTT4/wdykqkKa95ZZb0iGHHJKjeUEQBMHQYMgIuW233TY3EBUFKWiN4AggHqTHH388/fKXv8ytC4JgbKEBrnvtmWeeyZ645ukH5QQE3xeRc6LB+uuvn31tA8EP53xRopCfTq+2s88+e8C2HkEQBEFvMSRmex6jb33rW+m+++4b7nWiTld4i+c666yTTeannXZa195nMLRPP8A555yTD4Ffa6218s861sqGYyC07NAzTbPsSy65JKdPF1544bTMMsuMoxEFQb2wLuhJKLLtw7PiZJGCjRT/qO/Z6H/kIx8Z7d+J6aefPldPq95WTX3VVVeltddee6yMMQiq88iJiDGEL7fccrmlAVN45wMyKmh1cNxxx6XttttuuEO3VYN84xvfSJtttln2IYFh/Oabb86epf7SXUEwuoiulfNFFTfYZLgHd9hhh/yayiQfCiLcg/qvrbnmmvkUhMEgmqen2sc//vG82NSK1LFnc1RRzet81SAYEwVGmlUTWT60xxkTvxNa8TguTnERgaivok0ZwXfvvfeO5VEHQ43qhJx2ClqQ8Po899xzo31motTp5Zdfnq655prhhNxnP/vZNPHEE+fXC1KsUloh5IJxffpBf1gkfIwoItffGaV6sXl2amaBBRZIiy+++Cj/d3yAPoJgTBQYHX/88fn1zlNERud3QnPqnXbaKd1xxx35azaKH/zgB2mhhRYKIRf0vpBbYoklcgSiMw36YeAbWnDBBbPXqBORPW0aNC9t8sILLwx4nivh11xUdbCvrReZ97fPPvvksXu/V199dZ5QjGtE7LLLLmnjjTfOu0gnazj/0o6zE7/zj3/8Y16I9TwbE9dpqDCi0w/mmGOOfM1cLxE1goyv880338wbkYKIsevrBAQRLdf24osvzsJNFM7JCa6bCENhlllmyQUQPk8wwQS5nxxEBkW4uoHFrL/7S2Nw0TpRNymvTrr1foPe2DSV+2tMbdQH+p1a/ay77rp5rvz3v/+d/21uvuGGG8bI/zcIqhZyKvQ606kfBguh9g3M4p19tT4sP/rRj9LOO++cusnIwvp2h5q/8v0RqVpP8P05Emkgttlmm5ze02lfam633XbLXi3G+c6/3U9/+tN8wgYhF4y50w/4M21iNt988/Sxj30sC+8bb7wxrbHGGsOdMfzJT36yz8fjrNL55psv3wMEuOtCCB5wwAG5JUlh1113Ha71SIlC84V2a2Eh1PpLkZZ+eT6PbPMRBIMtMOJjm3TSSfNGoLPAaGz8TvOvVCprBDvFG2+8kX+m2CqCoKdPdiBICAppUGnODwvhcsYZZ6R3332377UJJ5wwLxA+LKCM4qIYzajcXXfdlT11PgYTkROR6vbJDkzxIjEXXnhhPneSKLvooov6Fn5RHEUdA+1C77///iwwGO+Lf1Ck74c//GH+GxX4O/bdd998hBqRERG5YExjAfRcOWv1lFNO6fbbCXoADbHZdWyAbF741nxuCi+RcfNn53rwYX/ngQcemIuOzJc8ctajLbbYImebFCaNKQQXFEaZ54nFchpM86xh2Sevma89W77385//vG+N6A8/ZwPo/dqAiqDb4N955519P6Nh+Ze//OUcNCFWeX4FEm6//fYPPZ442eHDnexQXdWqXYyHys0gOuSma34MFkZvv8fNWz7chDrll3+LWvh389zG2WabbUDB4+eLGd2HxaamXmQj8/31h5SeaFDzvzE2f38+j2YRyuGHH54no3FpNjdRSUe6F4hL4tx1GpMVYv21pgmCoLcKjAgNtgQbV5vdsfU7LbqbbrppLp6zDvke+4sgwfe+9700JpE1sWaqgpd9EqywxlkTCjbp5kxic9lll822DP/NiLIq5npBFfO9/0akX8HVTDPN1Pczoo0yVL5PqJp7/b+nmWaaMTrGoIWp1d13332M/B4iy8LfRAj8n//8Z9/rDvD2EL788stZvNhF8YfVXugwUFif92lUfX+lCrgzjeXrZoWwIhR99kxGxO64okxUTMMmKQekmyy8XgTl6FSIDdSaJujO7nm8Se+2TKbxpph6jP/+sb17DtpfYDQmfqdKWHQW6rFCjOn+js0zlSGLIiujqOKmm276UIUX1hUbYfNp+R2KBmV1+LNZlvDb3/72Ax5gPmt2j5or5nuR6oTcWWedNU5FozQrgdIsDGhLL7IS1pcS9XlsYacp1C4cP64ZGxPVyFrTBEHQ+wVGsFn1IaWKeeedNwcB/Py//vWv/Bp7iSjWSSedNKjfKQsiWmUeYnkRPBCxMmeP7WPyin9WcOLDFl7YMPvo9EcrvBqo0lyqWUDB749N8binOiEHuxa5+U996lP5axG0Sy+9dIQHhw8G1UVN3Kjy/D56oRfZBRdckB9QD3MzKictOlA7inJGZ+fP+Lo8kELnxJLTCJqolBUd42kcV4yJiWpkrWmCIOj9AiPw+zYL2Ai2smH8zW9+05cq1dJnsL+TL1sBkr50sj42jOZr8yQBOLZQ/MYewhPdzEaNauEFISszpbelTbM1QtrWGtD530jpnnjiiTmVa/3wc4RrMMSFnJ2RqJxcfPHE8TCp1vRwjOjw8KFKCetLexbfXzGyjsz3x3um2lED5iLcGCwXWWSRfPJAaU3S9I/x1Amrf//73x8tY2u3JqqRtaYJgqA3sHaMbDPnY0TYKI/K74SuAkTiuIQPj+1GEKSJIgXWE3NeKbxQSDSiwgveuCOPPDL7+wjTe+65J3vkZDmaXH/99TnSyBcnrVr8es1K+2AICjmtE4g1+fgS2tYDSwrM98Z2aLp2RhTW5/MbjO+v2YsMmmLafZl8SvsR4s6RT+g8tL308iKUCOy2TVRjozVNEARBt9BmioBSwdqck0vhBU9xqaglzpZccslceKFfaH9Yg9l1RNps7EXbpJY7Ayl8ytYBH9YYaw1vnWKJYAgLOTdcU8SBKNE7rQiLoczIwvqD8f01e5HBzssDe9hhh2VBpHM+b1pNImdMTlSqe/li/G0KPCF+hyijaPDopvGDETNZejtNPt47H3h9/PR+3+dpxvtg89/X358ovZEmHifvcagwmBYWmjN3nt8rYj+QECiwx0gx2mxqRi1Vp7ioc3OI//3f/80RcpGdmOtHbW60aSW8VI42Gd3Ci9Lv0bqw4oor5j6iI8LvtO4EQ1zISQ32d2ICn4G02VBnZGH9wfj++isPF7nzMRi0MxmXJeZjeqIqrWmaqMplUj7iiCOqEXG9fB7ppyd8IX1uouE9l00mG+/dtM6kH4ym3vnOTOmud2cZy+9uaDGYynBoLN6cI4i+EWGTJeqvYblnWIbgM5/5TL8bRMVJo3sc41BElkJmQRSMt610GrDJV5ww2MKLzoKOFVZYIVtZiPm55porCzi/68wzz+ybm/iKdU+QvbEe2DjbBPd3IkswxIQcw7rqSIKl+K/0QHMjummCocXYmKgG05qmBnr5PNKH3p0uPfnex0b5vxORC8Z9ZXgRbqU4ajDIDrCBiO4V+vM4a5ukEEC7oDHZLHcowB+Mzua+pVhjsIUXnQUdMjZsPGwoMmKOAdTcuDTYt1EWwfW7/Xd+Rm9Wkd3RPTUj6AEhx1gvdUi0lQicXaKvdZoOhhZja6JqA718Hqn06BvvRwqmRvqrDAc/LhsHMefg+EMOOWTAqJxoDisE24bj/mxKRNN5p5ppUxH1E044IWcQRkUkBv/HYDIjgym86CzoMK+MKLImqipFHtRBdUJOpEX0RTiX4ofdYZxRNzQZWxPVyFrT1ECcRxqMawaqDFelzlIhjabhq+i3iviBFnPti1hkZFYUFonKibhJz3rWHPEHUR4Gee2lgiDoESHXXJz7i0YEQZuI0w+CNjFQZfjpp///95n0pypGfStFuvtLlxZ/KoFWzq3W3kgvsnJW8+qrr557VPJjBUHQciGnFYbWIqIP/j0i5O2DIAiCcVMZ3h/Fv6zvZ39CThsg1hjZlCY8rcX3ScT57zs37CruefO6ESXv5QKjoHepQsjxT/DBlX8HQRAEqYrK8P5QoICBTowh4pjfpV+bzD333DlFCxXiZ5xxxnDfdxqLqtluFbb1coFR0LtUIeQcqdTfv4NgKBO91oIaKsOlT31f8ZDKbh453jaiSx/LgRqNa+mjSlwa1QkAPHJ6hJZzoRU39FfgoNn5YMTk2KCXC4yC3qUKIddElZNO/SaUJh4iPYy22Wabrr23IBiXRK+1oIbK8HLsn15v5mHNfP2sBuIjajRO0DkxRsNh1hk9yfjjao5cRYFR0EbGGzZsWFVdGO3Q5p133g+c1aZ1BJOtEw1qwdEl/CF2rJpd1kh4PrrL6BQjDBSRGxmjE5EblWKHsVHIMTaJQo6hwdi4Lzec9O40xXjvpP+8P1E6+83hzxsdXeK+/P+JOeXDaYxqInLecCl/V7be7P6tAmqVVVaJg3g/BOH5aC/Ray0IgiAYGdUIOb4ER7T40FeoE68z5AajRng+giAIBkev+1IjQ9ObVCPkCAvROL2J+CiaXcV5NBhgNaMcioxuuPnNfl57///1Int/so+mN9c99APfn8D/t/JUQUxKQRCMSXrdlxoZmt6kGiFXOn3rwE+0BWOGXt5hxqQUBMGYpNfPAI4MTW9SjZArzDbbbPljIJqHOAdDe4cZk1IQBEPJlzomigF6NUMzlKlOyF144YX9+uMKpcdR0Bs7zEgbB0EQjBt6OUMzlKlOyM0111zDfT3RRBOlBRdcMO266675MOegt3aYo0NMSkEQBIOnlzM0Q5nqhFx/vVL+9Kc/5YIHXcN1Bw8CxKQUBEHQOxmaoEeE3EDopt15bl8wtIlJKQiCYPD0coZmKFOdkHOqQxMtSZzmsO2226b77ruva+8rqI+YlIJg3BNtf4KgLqoTctdcc00ubiDgmtx2221xzmoQBF1hySWXzGePfvazn00zzjhj2njjjdMll1zS930HxH/ta18b7r+58sor04YbbjjC3zvTTDOlvfbaK1tGJptssvTYY4+lrbfeOt11112j9XvHJtH2Jwjqojohp49cE4cUv/TSS8Md2RUEQTCuo1D3339/OvPMM9Ppp/dfaX3FFVdkEVYY2Zz10Y9+NIvB66+/Pm200Ub5CELFXv/6179G6/eO7WrxZ9J/0jVvvfGB1xef+Mk06XjvpTffnyDd8vYHW0i9vOA8aaoFt/pQ/8+oFg+CFgm5aAYcBEFtiIL5GBEKsp5//vlB/052kaeffno4kfbEE0+M9u8d28wx4b9GWGREzC0/yd/7LTJ6+d1RT8kGQdAyIXfAAQfk9MIJJ5ww3Ovf//7308c//vG0++67d+29BUEQDMTSSy+dHnzwwfTvf/87XXfddbldUvOowU5WX331dNVVV6VTTjklLbXUUumZZ57J/z7jjDNG6/eObaLIKAjqYvxUGWuvvXa/Popbb701rbPOOl15T0EQBCNCtG7LLbdM6623Xtp7772zMDv77LPT+OMPPMXOMccc6Tvf+U4+neQrX/lKOvXUU/NG9qtf/epo/d5xUWT00vtTjPJH9G4MgiESkZt66qnTK6+80m9/uWHDhnXlPQVBEIyI888/v+/fDzzwQPbT3XHHHWmZZZZJ1157bb//DTGmqGHfffftO3JunnnmSd/+9rfTWWed9aF/bxAEQ4vqInLSqv01/V155ZXT448/3pX3FARBMCqYqxQvsIMMxHPPPZceeuih4V57+OGH06yzzjpavzcIgqFFdRG5Y445Jv3sZz9L00wzTfaDYLnllsvphfDHBUHQBmaeeeacQSDWBoKFpLPJ+dxzz52efPLJ0fq9QRAMLaqLyCnv/8lPfpK++c1vpt/97nf5g39kp512+oAJeET86Ec/ymX7drCMwv7bzklzkkkmSQcddFB65JFH8s/98pe/TNNNN91YGFUQBG1GA9z5558/f2D22WfP/55lllny937605+mz3/+82m22WbLG0/zDe+bYoaCNKmircJxxx2X/5vtttsuR9jWX3/9tMkmm6STTz657/85mN8bBMHQprqIHJh+fYjKvfnmm7kj+KjCFGxC5CeZcMIJ0x577JHOPffc/HrpLq76a5VVVknf/e53sy9PJPC0005LX/ziF8fCqIIgaCsaAV944YV9X5s78Jvf/CbtuOOOab755stFCnrDPfvss+nqq6/OhQtahxTmnHPO4Xy+d955ZxZue+65Z/4dWo/IOpin8N577w3q9wZBMLSpUshNMMEE2cxr4vvtb3+bX9NNXcHDYEVdZ+dzXdn5TxZaaKF00003pammmip94xvfSJtttllfClc/p5tvvjnvgJ0kEQRBgBtuuCFvLAdC1mBUm53jj3/8Y/7oD5vYwfzeIAiGNtUJOUbfc845J6cspD7/9Kc/pddeey0fzzXxxBPnneuH4SMf+Uj+XPov2WH7fY4EK0ix8qeEkAuCIAiCoA1U55GTNlCSz/RrR1r4/e9/nz0iHwbntkqFiLbxy2H66afPR910tjp54YUX0gwzzNDv7yH8RPLKx5RTTvmh3k8QBEEQBEFPRuSWWGKJtMYaa6R33nlnuNf5Rxww/WE4+OCDc3+mNddcc7TemwKKnXfeebR+RxAEQRAEQc9G5DTJ5JHrr+xeinVUUcCw6qqrpi996UvpH//4R9/rzi6Uui0p14Kq1YFK+w8//PDs2ysfpYItCIIgCIKgG1Qn5FRlbb755n1fv//++7kMf5dddsntREZVxInCrbvuuh84jFr6VuXX8ssv3/ea9iTK/Afyx/l5BRfl48MIyyAIgiAIgp5Nreohp9jhxhtvzBGzE044Ic0111zpn//8Z9p0001HKZ2qL5N+dAQXTxx44njvCLFf//rXaZ999skFEL4+8MAD85muUegQBEEQBEEbqE7ISX8qanBItB5KCgp+9atf5d5KzeKHkaE3HC666KIPtCHR+wl6Nv33v//NjYAVMogGajwcBEEQBEHQBqoTcno1vfTSS1m4lcaYBQULDo4e7O8ZGapWf/zjH+ePIAiCIAiCtlGdR05zXqctdLLVVlulyy+/vCvvKQiCIAiCoEaqi8gde+yxOdUp/elYramnnjodc8wxORrXLIIIgiCokcknnzwXaI0qTq0pxwcGQRC0VsgdddRR+TQHgu7aa6/NQu7222/PvjktQ4IgCGpmgQUWSIsvvvgo/3e33HJL/giCIGi1kMNjjz2WvXBrr712/vqCCy4IERcEwThjqk1P/9D/7TPpP+mat974wOuLT/xkmnS899Kb70+Qbnl7tg98/+UF50lTLbjVh/7/vnriJh/6vw2CoL1UJ+QWW2yxdNxxx+WWIKJwvtYWZOWVV0477LBD+ve//93ttxgEQTAgc0z4r/S5iZ4Z8PvE3PKT/P0Dr9/5zkzp5XdHPSUbBMHQpjohJ/pGyO2///7p3XffTQ8//HC6/vrr82s+S1sEQRDUykPvTpeefO9jo/zfvf7+RGPl/QRB0NtUJ+Q22GCD3Ay4yd///vd8/ur222/ftfcVBEEwGN5IE6c33p+4228jCIIhQnXtRzpFXPOorkMPPXScv58gCIIgCIJaqUbInXXWWWmqqabq+3rbbbcd7kB71asDibwgCIIgCIKhSDVCbsUVV8xnqxa22267LN4KE044YT7UPgiCIAiCIKhMyI033ngj/DoIgiAIgiCoVMgFQRAEQRAELRVyihl8dL4WBEEQBEEQVN5+RCr1F7/4RXr77bfz1/xyqlTL2YMTTxzl/EEQBEEQBFUKOVWrTc4555wP/Mz//u//jsN3FARBEARBUDfVCLmtt966228hCIIgCIKgVVTjkQuCIAiCIAhGjRByQRAEQRAELSWEXBAEQRAEQUsJIRcEQRAEQdBSQsgFQRAEQRC0lBByQRAEQRAELSWEXBAEQRAEQUsJIRcEQRAEQdBSQsgFQRAEQRC0lBByQRAEQRAELSWEXBAEQRAEQUsJIRcEQRAEQdBSQsgFQRAEQRC0lBByQRAEQRAELSWEXBAEQRAEQUsJIZdS+t73vpfuvPPO9PTTT6c//vGPaeGFF+72WwqCIAiCIBgpQ17IrbvuummfffZJBx98cFpxxRXTfffdl84555w07bTTdvutBUEQBEEQjJAhL+S23HLLdMYZZ6QzzzwzPfTQQ2mHHXZIb7zxRvrGN77R7bcWBEEQBEEwQoa0kJtooonSQgstlK655pq+195///389aKLLtrV9xYEQRAEQTAyJkxDmGmmmSZNOOGE6fnnnx/udV9/8pOf/MDPTzzxxGmSSSbp+3rKKacc7vPYYspJWnaZpppq0D/ay2Pr9fHF2Cqjl8cXY2vn2Hp9fFON2nowqgxWW4w3bNiw99MQZcYZZ0z3339/Wm211dJtt93W9/pee+2Vll566bTqqqsO9/M//vGP084779yFdxoEQRAEwVBk/vnnT88888yA32+Z/B2zvPTSS+ndd99N008//XCv+7ozSofDDz88HXvsscO9NvXUU6eXX345tQ1KX2GHG+S1115LvUQvj63Xxxdjay+9PL5eHluvj2/Klo/N+x+RiEtDXci988476e67707LLbdcuuSSS/Jr4403Xv76pJNO+sDPv/322/mjyauvvprajBu77WMYimPr9fHF2NpLL4+vl8fW6+N7raVjG8x7HtJCDsccc0w6+uij01133ZXuuOOOtPnmm6fJJ588V7EGQRAEQRDUzJAXchdccEHuGbfLLrvklKoQ7IYbbpheeOGFbr+1IAiCIAiCETLkhRykUftLpfYyb731VvrZz36WP/cavTy2Xh9fjK299PL4enlsvT6+t3p4bIUhXbUaBEEQBEHQZoZ0Q+AgCIIgCII2E0IuCIIgCIKgpYSQC4IgCIIgaCkh5IIgCIIgCFpKCLkeQjPjoH3EdQuCIAg+LNF+pIfEwPvv/18B8korrZSeeuqp9Ne//jW99957qRdYe+2101xzzZUmmGCCdNFFF6VHHnkk9dp122STTdKLL76YrrrqqvTmm292+60Fo3j9eo1eHlvn+KaaaqpWdv0fiteul8f2YQkh1yOUG3uPPfZIX/nKV9L//M//pH/84x89MTn95Cc/yWNy+sYyyyyTFl100fTNb36zJ0RquW577bVXbkR9xBFHpEknnbRnhNz444+f/vvf/6ZeX1CWXHLJfCLMAw88kM9F7IWFpozhy1/+cpp55pnzfGIT5WjDXrp22223Xd4kHnTQQenJJ59MvTS2L33pS/naTTLJJOnqq6/OR1K2nTK2jTbaKH3qU59Kjz76aLriiivSc889l4YqIeR6iB122CF9/etfT9/+9rfTvffem954443UC2PywH7ta19L99xzT/rMZz6T/vjHP6YZZ5wxPf3006kX2GyzzfL41l9//XT//ff31K6ziLjdd989Rz3ck3vvvXfqBcr1MR7XzvgeeuihdO6556ZTTjklvfvuu6ntuG4/+MEPsgBYfPHF06qrrpoOO+yw9PDDD6de2kAdcMABPSFQ+xvbNddck+aee+603nrrpd/85jfpuOOOS23HSUxbbLFFuvXWW9MPf/jDdPHFF6eTTz453XjjjWkoEkKuR/joRz+all9++dzB2s1N6Cy44II5kmXSdRTZ888/n9rEvPPOm6NvO+20UxZx+Pe//53H40xc0Z4777wz/fa3v01tolOkzT///Om0007LIm6OOeZIn/vc57K4M06i9ZJLLkltP89YxOq2225Lyy67bFpiiSXS97///Z4Q4ksttVT++M53vpNefvnlvKhYMKeccsp05JFHtlrMWfwXXnjhbGsQDV9ooYXS//7v/6YJJ5wwHXzwwVm0tpnVV189Cx2b3xKpct0c2ehammvayjrrrJMjqWVsNhq/+MUvsuWm7cwzzzxpvvnmy2Mypyy44ILp8MMPzxsOc+sNN9yQhhoh5FpKpxjgHRs2bFj+MPH6EFKX7iEMpptuurT//vu3KspjoT/99NPTzTff3Ddmos0YiDjRuaWXXjp/ry1iToqjHBWzwgor5HSHhcNkJK2zwQYbpLfffjv97W9/y2mDj33sY+nKK69s1fEyzXSqRZ+YsbBYRGaaaaZ09tlnZ+H6rW99q9Vibs0110yrrLJKuv7669Of//znvggWe4PIlfv0qKOOaqWY+9GPfpTF9yuvvNIXfSMIRI7PPPPM/HXbxFznnGmu5LU1LsJgtdVWS1/96lfTRBNNlJ85m+K2nrk922yz5U2usUmvHnLIIWnXXXfNkavJJpsszT777K26doXvfe97+TqhvP977rkn7bjjjnmMNsCu8VCLzEXVagtpTkgrrrhiXhz/+c9/pvPPPz+nVe28iIIDDzwwf5+HgCBok4iDHfHll1+exwaTLB8EkWqxJHoskiKRbWCNNdZIv/zlL/O/99133zzxTDzxxGmbbbZJ//nPf3I0RxpEmmfrrbdOv/rVr/JiQxi1UcRJxRmzhUPayv3HZyVKzAd46qmnpllmmSW1ERskUThRgU9/+tN9r7uOru0dd9yRVl555bTbbru16voVHnzwwTx3LLbYYnl+KRAHxJyoqo0hwdAG5pxzzr75b8stt8ybWxsLG0GpxrPOOit98pOfzML72GOPzfetZ6+tVe9TTDFFHt/nP//5HBnmmS5zD2FHDLmH24b5Y4EFFsgfNvKFO+64I9twBC+kXX1/KBFnrbaYUthg4T/vvPNyJMeiYtEk3go8OzxzbfAmmWCnnnrqHKkpxRpFHNgpm4yJt/La0UcfnaMGdpu1Y3JhFjfBEjBf/OIXszm+TMbEtpROibCKfBCxvCBtgwiVlnO9jMsGQ5SjiLwZZpghnXPOOdkS8IUvfKFv3G1CJJVoc89KH4syNhdSESueQAtMzQzkx1xuueXy3OFa2hQ2rRksD6J2io5q3yCKtv3pT3/K6XzClOdWWlVVP1FDcF933XXp2muvTc8++2wWcMbN0nH77bentlw7KX4C3JwhmnrhhRf2RbHKv22q3Kci/rXPmQPdlzbuxKkUKuH9wP+bQ+H6uie33Xbb6u/LMUkIuZZikvnud7+bW1Z4eDurUy2QPC5CznbNFsvaqzyZc9ddd928U/zXv/6VJ9Xtt98+Tzr9PdR2X2eccUb+KLvN2mGCF1G0cIgodlZ08uhIy/me6yb92obUXPP6iJz6KBsHkUcROFFGEZ3yc66fe5gYasvYeE9F3WwqLJjTTz99TsERdaI6v/71r/v+O2OWEq95QWmOjSeV6H7iiSeysDZOkRvPF4vDQKnGWgtzRBJVEEPU25xpDrSB+stf/tL3vsum0GfWB3OJOYgdoMZx9YeUvjQ/kWYD6L7baqutckTYhp+Q/chHPpJ/js2GeK15PWjeU4ssskh+79YEa53NESFuc0F8H3PMMfn1Ef2OXic8ci1ExMquhPDhzbGY8FNZ/C2UHlqphP322y8vNsSAh7bmVhBSVHZSG2+8cXrsscfyzuob3/hGTq0y7TJbl/dfDMkWGLvqtog4iMgpXthnn33ypGuyFVEsWEilJEVXi/gWnat50kWZMBmORUD+8Ic/5HsRhKneeHbPTTEn4lpEXM2TbnlfhICx2CS5ZiJul112Wdp5552zyCFe/WzxkJUWMm0YmxY/NhieK9fl73//e44kGp9nkpBzD/785z/PG6z+fkdNiNh89rOfzdEoPjjvmbA2f0jJEXLlfXuNxcGmgu+RiCNgfb/ma1cQWeM3tak3ruKnNb8Qpj/96U/Ta6+9lkW4PpUEX+3rQbPy1n2pItxaZhxS++YXP0PM/fe//80b5FIQ1/k7hgIRkWsh0lLEmjYAolXSq/ogETgeTjf1iSeemP0RUgNu6NrFgB2z92syKohImYR4dSygJmQTk5+1IyP4pEtQ44Tb/JsTaCahEl2TjhPBUWHMs1Miqioe9UQqX9c82Xb+3V0bCz8hR8xIbxSMw7gsmATCLbfcktqEyLZKaWLOtZQmJ3BEjKUeRepsnES1LD6qjdvCpptumn784x9nISPtLy2nmtPiqeqRL9UzqGLV88jOUDuzzjprvhcZ4t2HPMM2vESAKJXecUVww33J92fTa3NR6wbK++MHKxW1si7mevecKP8000yTI92ijvy2CsU+/vGP59fNKQpX2rAegAfVtbKhF1nlYfS8saW4H0WNNb8/44wz8qbKJmOoEkKucgYSKKIAKnRUBRJuhJ0HV2qHv8zEPLLfUdtCyUelxUFzgvHQatQpHcDb4uFVcSVqxWNV4/hMLqJOpUiDcGGqJgCUyZtc+Y1EDIg50UbpAdE50dYSDWgTrpP7TjTjpJNOyosHYXPppZf2XU9ijlfTmEUka6WzIbO0jv5bPoi2cs8RA6Ihojil5Q8xVKIENeK5aYpo84fiKFE4hviCxtsWUe0dvG4DIsXlXq1dAJRKaalVkWBRe34+m94ydxIENoTEKdyrfHElilzjBsom13NDtKnSJ8yINpsGhSciUkS56wR+aYJcZXyT2uZLaEtEiDYhzlzHppePmHO/Pv7443kDXO7LO++8s7rrNS5pXznVEKL5wOk1Zsf4iU98In8tlSMdKUzOi0TElUXopZdeGu731PbQ9ofJRuhfas4YCsQBoSraKOoIHp5aRZz0sGpMkTU+KpOvMTH6l8XSYm8CtigyW0v1iAIQDHbSNY1nMBA0hx56aG6h8vrrr+fFRBTHQkmU2v3DRCtaV7OIs0B2FicQp66RdHfBNSK+baB4qYgH6TsLavFb1YaNAhHQrHS0EDLAs2Y00VJF6woWh4LofolU1Ypxlai3KI5NlTmTT5MIKHOn+5UgIBZsNkR4mqm5GkWB9LbWPYqf2Gik+G0ItRQhTkUgS9U0Ia4Fh8+d1Da/SH83NxEF4zOnNJGVMU6RyLJO3H777dU+c+OKoTvylh27dfzxx+domwnJg2rCIgSEyokc0R3flz7wM20rmS89j/jh1lprrZymK4ggiFSVibjmSUnExnUw2Yogal7p39JRRB7fCvEm+iiKJfUjlUX8EHEWoZoXyv4QeZSGM04Tr8XEWIk6Yk5avHNM/bVMqAGbIos7iDMQaDZKCnE8XwVRO2MVae0sSKlRCBCpni2ImJbr4LkTvRKta16nImwIvSY1R+TKfGAs0qs2T8QcIe66ljlElF/Wws+I2IkIFd9YjZT3JbUvckWUmytdP9FE84lrK4rKP+betZEsxR41I8XtGqG5obC5J9ZslJr3petVClNqf+bGFXXetcFw0Q4+FTsuaUe+MN4cZ3KWxdCkJcrB59EsbKgVk0yZcIlQ5f4eQpOUSI5Jinm3jMFCyRNSe3POMtlIBYjUuHaMuk34OOyqve46KkpRhUXQFXN1zQtlf/cVcargRMpbuoOY4wck5ogdGw+RuJoFOPztiReRNz39jMn9Cf4+9ymx6n6E580Goy1nPBKknjPC2uZISth1kAr3TO655565wIYoFx3mvRURb9t5zTZGouLmzXJGLKEg1UjMFbHgZ2ygFOCUDVStYqAZcWJDMb+4Rz1j7lsbYR9EN9Eqeuffxlgz3rv5z/gU8GkpIpsBkTfZJV45hUSeRRYb8yYvZ2fmaSgTHrmK0LdJOXXBxEOwSQXYnZhkLZp2XCJwbnppIJMxMaeC1QNRo5FVesqDKo3RrCwTsbJzNOEYm38r4pBKtuOy4EgPiDwyvdZKfyleaawSjVOxqXy+wIBtAREBYtZtGyZbpmtelQI/jsgAYznBqiUAUSB1whvYFiyYenLxxKkytmB6rghzUVMix6Ip1a9fnOe2tudtoNNEXA+470RwzB/GSJAar+fUYkn8EHcEUBva33QiiyGt72hC4zIeoo4gV9mpStfn2hmRdUR62JxqfhFtVUlNfIscEz2sN82em7VBaJbzwEtTe+1RFLB55vRGFQEnvqVSFb+V/qgsRcZWm7WmW4SQqwTpNjtjC3yzmsqukpmVz8OhwJr/St8RPSYqE5MdSrmZa72xecVMPGV8Hk6ePyLGQ8o3RsAZn4nH4mgRIUr5QIoQqHV8hZIeLVWLxuM6mWz5+pqtRggfBusaJ9kRoQcVoWaR1BW/ecyWSCq/C8HufmaWrx2irZzRKLJNiJ5wwgn5/iQCXEs+R/edFJzCFSk545aiq7mVgwVP1Fdlo+eP580YnOlrsbTYeyaJOaKUcdxco6jod7/7XbUbw/6wCWwefC8yLvJN5JhzpBmJOalk92abGuKaD4kaUVUbJG1E4Jr6Hr8mS4eosei3jX/N105Qwvs2V1gLdCwwT5aqdlkZzxwxZ/NB6Lk3jbs0Fq91bN0g+shVgknTBOrB9ACXxqJF1Lm5LY6lykoqTmTAotOkVpFjMjUREWSlh5ho1X333Ze/b3Il5Ir4kTrw0aRGEdd8T1KKonAMudJRN910U14sRDbK6QxNMSfFilpFQKHz/dk88GyWFIh/l8O4HRNnrCZm1bm1CzmtfEpxAxFq4S9+He9fuwpijmAlfPiTOqvral5QLI4+HDllgRetgUiqKDFE/d3DTPMyAs2sgGtf69iaiAQTcq6VtH6ZRzyfNollLjXvyAKUivKaafb447cl4vhqZWRUfrs/3bs80URPqRgndFCzTUOWxXMmDW4jL83P0uDDGgjPnL+BOaW0TmnbfTmuCCFXEW5gN2gRNM0u8cLKUiR2nB5Qos8NzgtRq8hpwvhuwrHoWTiYxJtCrQhWP+MBFenopMbxlffkfD/NVGGCsrO0sFgUef+MR7sYk60qXOMvtEXE2T0TbKJVKv7AcA3nU1ok7ZxVPIpitaGXGn8b64JFw+IifVpSbp6pIubcnzYhrnOnZ6zmBYWfSs87UTjPXfOgdNXfxJx7WITVhkOUtUnN92YT0R0eYvOMTXERc6qICTdeMpEdkfHita11AyVaWiwLIlPSpYQq64zrqZUKn6a5VBTZawSciFWzx1+N82WhHG3nusnKNAMSrl0Rc8Zj3SNcm9R43bpJCLku0ynAhJm91inm9EOSQjVJEQhKs0sz3JofWgu9SjEeHDtLD6aFUOTKeY2lb1NTzFlw7r///vT73/++i+988BBomsUy5PL9aQpbvB4mHMJGhRyxwNvYFHG1UyZMGwaVjsZgEeH3K2KOLYBYME6pOuKnDSKuuXBIk0q9qZCzqIi6leObjIfFQfpRsVEbqsJRNhN8RUSbsRGuovolKux111FKjge1U8i1BVE384YqadfMOIrgdkqFqI+muM2CqRrFgKiwe81nFg3PlcgiEce2IdpdqjxFiN2j2oyYa2qtBO/EPeneNMd7nghwYtTcInVqHEXMyToR4Z1CLhie8MhVIuLsuuyITbImGDe2SI7QOU8cISQt4iByu05l5jV7c6AKToWcBVCrlLK48+JIBYhudHoCIdwuLVkjJtnO9ytCZdJVsdn0gJQDnYk7Igc1X6+BIEqJAKdplMPt3Y/l3153b6paVfXpurZp81S+Fh2wUFpoRN/KNSsQ6CJaNUfgmmPrTPkSoO5LC6a0fhFzIlVM53621g1hf+OzmfU8qWgvzxRRaoPIMyYFSbgarzm083rW6iMm4hzj5/qxKEgpysjwRYt8m2/MNdYHG2G+zrIhrjUzM6L70jqh24JgRRFzMJ/YYNX8vNVCROS6SLmxHXvDbyRapTu8FFXZ9RfPnPCzys5mOXnN3hwpKjspUSr+t6Z4EZEy0RqXXTSa4qiIuNompdI1nQ+nWVyixUapBizvWdrYpEvUWGh4P3T/93eobVwjgqixiBgz4cYsrzjA38Ju2j3Lu2nRlDa2yUDNYyzvi/i047f7Z6qWBpfGEd0R7SASvEYEGF851aHm566MTaWwYg3RKBEb5nebQ/OKaycior1DmV9EVWu/bs2/uw2uVDhx7d7U588YXTfZDBEqm0UCVXVk2WTVOj5zJfsFMVcq+42Vh9h8SdwRdMVKY+NoXrWxsEku1Di2zrOYXTd+P8/WhRdemIWo79tkuC+tBaKQKD7cYMSEkOsy/DeqF6VNdahuUsQcD4/JyE6sSa2LCY+H1gbSp83UaRMTLDEH0Y9i1G1S26QkvK9y2PuySEq5+TeBZvHQCqCcsAGpHT8jrUM0+Lkax9Wkc6HjyXSfWSBFQEy2BJx7Und5CyRBQKAWEVf7GIvfz7Nn9+/es2B4Bi+//PL8fQuqSKoUMrHHo1T7c1cgckQWRcBFSwlv0Q0RHWKOb4wwIFiZ/hnNa75uUm9ES/m7y0Z4/1qMuO9YG0SuRPoVbDh+S4rfBqS0Myp92GqMhnumeBT54ZrtmXhpjccmwz2qpYgxKabieRRVLRvgWgVq8325Lu5L4o3H2xhUEYvC8cxpkeN+talgc+jswRkMTAi5LiNVasJtirjmzU/MWUDd1J1CrlYY3rU86BSmnXhwjc9CyfhaO8VzQ7DZPfPhlHYwFhK7ZROVHbK0lWpBVaoiCdKsJiyepFppLnR8cK4Pwc3fJwJgjCKoxDkztjESQxbQNjWN5QfTo9EzRcjwLVrsVVYTAMScZqMax6oStNGo9RD1ToyFF4woFdk2Tv5NwtS8oskxIcS+QORIN9bcysGiLyrljF7vUwpOmp+fT0W0DZVqcQUqhJDIt/nUtWxSq4gD0VIENeFmQ2RTS8DyFcNYbTa87rQD16p0MECNIg7Nin7WIQJchNjGwj3qmrkvZS/KcWnmk5p7otZICLkKFpVm76Ny85tk9asSfuYhaBN2jyM7WYKJVzqB/8purHmOZe0w6WrBURrBEnUqyaRYibViqHZdVRZbXBnOS1PWWikLHVEjhWwcWhmYZHkZm4fJEwuiO+7PNok40Rt+VIJaUYO0lTGKOEoT6+sn0qjZsY82tTsgBPimLIylEEXqzT1JzFk4XWMbjqYHtdaxuVYKbIhr79ucqGpaJIqw0c/QvSkCqbeaFKuoj8iVKFaTWkVcuUbEqfdss27+l9XwWunRSJy6RiJZnkPXt3aPdME5tt6vTaH5EJ4/mwpjtfk1Bm2MSjuqmu/LGqn3HKchgjSVCI+dfxNmcsZ6O+e2wUtlMpXSGQheK1EeHzWLuM5KMB4O6Ti7R6dOKOYgaMAPR5xK20lfGb/xSasSO0UE1UZTdHvvohwWe0ZxkZzSCsb75+HksRLx4L8S3WkLIgLGYPPEW1Wqhy0WqlSliVVYlz5cTWpfLCFCyl8rGt487J63yiIpkupeFSluw9j4TkV+bYj4qDxb5kvNjYkZ4pRIlV4kuok586ZNSJswxxBzBKv7T3rRvVhEXHk+3Zeuo6h4W0QcRBsJUT0bm9fG+Ig518+8Q7g2acPYaiGqVruMXaYKJR44O1ApnVIEYCLjNWvjDW2n7L0rdtDrqInGwLxmDOTNvke10UxxM487NozfjVdOGxjfFwEhtkXoOnvfmZRFerQN4Puo8Uig5mLgekmBuB+lh6W8+TftmKUbCVWeFmcfSnmYfNvizyl4piyUhLg0luvT/FuI8hCvzdNSamSgv7l0nFS41Lh0vmesoJ+a8Xnm2jCnSAurZFT5bVwi4P4N96Z7UgTLXOJrzx+/JstDzdeu0J8QM2Z2DJEp92YbGhcP5r40b4qW2mDY5JbIHPj+pMxZVNpwX9ZICLlxeGPbkfR3wLYb2aRrohWdEvGx47LgtPU8OTsvu2gpVKkPXhzeD2lGqVSpRgtmG1C0IR1HwImsMVmXI35EAKRVTVB8HcXTIr3sNZ4QoqEmEee9ibgRK+WsQyKOX9FE6r4rXj7+TGO3ybCrNnaRrXL+Zq33ZvN98fY5P1Sl3N/+9rccudIp33UlBqSN+/vv2jA2aWDi2hwiWvPXv/41i3HPHDGnoIi46aT2aE4Zo2iNY8b0lLSZKqk219NmV7ROmlj6ThZAetl/V+u16/z7mx+de2vDVJ4ph95L8fMFisyVNj+10/ybyya5J6XGzZXGYv3TzUDEX7FUfz0La78vayVSq2OZcmPzuWkzYufYCa+O9JtmlhYXC7+UnQdb5KPmCWkgFDoYi0VEBMDOmq9FFEe0p4i42ptYmnSE/IkeAtQ4UPxTJlkVZ1IjpQUJiFbpOtGsmkQcbBjs+IuIg0gHccdobBIuaJ0iQkAkEKXNBQe13pvN441EbXbeeecsaoxDYY3UsOdRY9Vyjm/zv+v8d61tizxj0sQ8VVJvrpFefjxJ7k3tHkprkSa1L5bGWBr4inqLJGqVQpzC61oyyWi4X43Hc9omEUew2RzaNDWfKSliaVbXVUFDc16pmfI3d0/yPtvkEteqpbfeeus8TmlxxQ5S/Aql2nZf1koUO4wD9M2xqyTUmoemF8rE07lzrt3sObIJU4TKBx8ED6CxKJ3XSmAw/30NSHkT2vxFxLYogNQVcWOClT4l6gj1Yvov4zLeGq8fkV0qikUV+YxEqky43rvqOF6yInCIOUZs0Z5me5Xa0TJE5E2bDX5Gi4vIIjFg4dSo2nUi8HixCPK2oOLWYm98Ngqijir+WDPguSPm3Je8mqwAtdM5HxiLCI7FnR/TKTd+xmbQ94yXbcN/U5692qsci4izmRKRItRsNrxuw2uNEGW0MVSZy85QjhtrAwIQ5g8bPkVhNsKeM/M+3Ks2U0SetisKVILRJ4TcWMYNrcWIXYhIVH+h44HETK27EztFE2uzb9iIGKijeu0iDkzV2qm4jgceeGCOgpSmzKqK7SoZ/osxuXZxSgBIc5Rji4gBqVSvG4Moh/fP2+j+00sNojtFxNU+xvL+PHdSc0Qcn6ImsRZNjWMJdCli7S1YGWoXqJ1/c+f6EjEWRtdQtMoGg+/PBsP4RMAJ9eIra8v4CHD3phYVhI6Nkgbb7snSjJuY4x9rboxrPiS+PxGn+tb96H3zMvq+CGPpYiBqrsCj5meu830pJHK/EXHN+9JGQnSODUDxjetXzpMNRp9IrY5l3MzFKK/isVZxNlj0/ZHCsRuWllIO36T2VOlgkKop/g2LPj+f3bKPIuKcAGCSFbkqIg41TrYFvhRezFI9a1wM1QS5XTM/nPQH07GJl0gVxeqk5jEW8Q1iRiRVVEDxDREu6ihqw/fHYK0ljGtcGsbWSvmbi2TA5sL1MjaLJZ9VuTfNOVJZ5htCr6Qb25KWkwYXhVJV7JpJw/F1siqIQIr4aJHTmXKs+b709y8iTnSbiBMt9bpCKRslEf+BNse1jq28L6K7CDli1DFp7kuCrdyXNlMsKq6bjWQb7su2UO/M1UL6uylNPKICdpgWRhNS28dnl2wy4v8SsTHRzjrrrFVPOKOCNI1ozRprrJFFj/GKbmgTI0Xumopc8SU1j/6pGf4+C6CiBqb/cq1Eq0y2xik6VcScNJYoiL9D7egQX2DyF7mBnmPSxtLgKuaIOFhI/C206WhS4ybLPafdC1Rllp6SPH7M5AQ48VMWSyLWPUrENtv6tOG5NFaRYdfPpsNzRyDIZhA4hLYopFS59HibUo7+/tYAEVPXrinipIlt9ts0Hpt4zxo0RS9tiFSjKnBQ+e41p1OUjS+h6tlr9p1sw33ZBqJqdSyEmOebb778b5NqMcUzeUpJ8liZfJtG8zZhp8UUb8KVkuL/E9UhBHiojM/ENNi0a01YHBzJRMwQqCI3JbVRRJAJTNpAFI6I47WqvdLKQq+4xPsvaTb3q6/dixDZEf1wzzLH88XZXdfe/kAlHAHqfYq+MfsTMiJRFg0+scUXXzzfp6Jvijnco661CEHNqTjvlaBxwoT7UhW0HnD8U9JUNlIWR2KAz2+uuebKFbh6/blPax4b4WJzVPyyMKcozlB5alw8miXSaAOswtPPN/sxtiXlWMbsnjQu31cx7b4lTNsk4mwSiDjzhHlQJ4JyX4rGCVhYEwhw8ygx7l4VRRYFr/m+bCsh5MYwdiEiOdIabnhl83wqUIatUslC4vU2iZ3mxEQY6AUn7WaBUQWoUOP555/PApWRnuejv/LyWhGxEWkrrVJ4OaRypOTKmbfwuoq54mOp3VzNLO6etDCWfn7esxMZROZEP8pYCB5iTqSReb4N9ycRzQunXYN/E6eqNkuLFBsPY7KJ0vrHgul6EQs1i/DyvGmzIQ3HmkEA7Lfffn0/4xmUquLftEgqWPEMMsnXPDZ9F0VKRXx9LpsLAkDKW9GJiLdIcYnoEHn+O98rJ6e0Ya4kcDRp5kttfl863zj0ZGyTiCtjsxESMfXslVZMBRtAa6BNhX8rFiP4eB9rvi/bTAi5MYiKIzsRE6mojbJ5X6vkKYfHi8xpbGmHUlpZ1IzFnTmVh6M8gMzxxmZcPDtEAeFGDBm7h1j43BjbgkqqL3/5y3nCkQon4iyUvEYWFGOsOQIwEK6RNKnIlBSIdBuPI1GjM77r1ByTAg4fnc2Na6P5njVRFSUm3qRT9VZrHnvnZ11bmysREJGQms9xbC50KvtcQ1Xf2nHYHFk4C8bsg9BzTY3f36XWsRVcI/MDQ7850WetmWw2RBR9jzgvaTmV764dj25bUMgg6iul7xn0rLk2hLcIsY1wm463cx3KMYPev02S9L5IsZQqT1znfVyiycXOUft92VZCyI0h3LT6VWmaagdtxy+sTAR4kKUGSoTD7kXKpPZdCe+RKACPkciUdFvBa8LoHlS7S5VJ5cgjKaHy77YgRafU32JPtEpT+bcxKwpwvZq9ntpAETuEtwiHDvgmXylx6ZzmNZKqkwJp9ryrVbSWY+s0ghWhkWojUkXd9GB0zUQgm9ercwGpNSqgFxrR5nkzdzjRQKRKul8RQGkW2xRzNlPNprG1Xjc0qzJFo4xN3zSpYZ9FsBQy8G6aT0V0RHKIuzal5UT2bZQUTkkHd56n3TZBI41qsyAizG/rOrkexJ2WPu5b92VTzPGgKmpow33ZdkLIjSGIFwuLSJVQuaiOFKSdpB2z131fOqH2xaSJxcTCSaDaOdtdwUNMGPBYGVvN56UOhAii9y2ayN9nt0/Qie6IDhBv/B/FiF1bY99RQZTUuPgXCbvmBEsk+BsoYCGEaobHSETRmZsEm0axFhERHYujzYd71n0qCkfMEQb6qrWhZ5VIlPcvIux0FNet3HeEtlS5zRPTvLRkOQFA+rhNOA2FOBOx8lkBgOuk35hTGpwK41pLP2pTQSzUnJZrihStYWzeiXHXiR3DxlDaWKaG569T2NUOr7BNk+fIZsJ1I7whrc+bKv1tPTCHaHRsA2zzEYx9Qsh9CAbaWZhMpXmkpviStHGAFJ22Dx5qkZE20Nwxehild7QcIeYsoASPhV+aqm2LSEHaVBEAky7DvOtDsEqDmIQtGhZOLQMsJDUuIKMC8S1aLNLBp8lPRbDya4rSKehoA1KMUt0+E+M2TYWmmBOpIvgIIKKoLREQQpWxX7sbZv8mxmLDoaDDHCTK77q2KVrs/at0F5GzsZCmE3UjEmQAbKpcR15NgrwU3LQhikW0eb+eKYVuBKq5QwrSWKTKRbQ8f23DpoEtyIbQmtC8FsSc6KqxivT7IMjbdF+2mRByoyHi3LwW+9JHzO6ZMd4O2QLD5Gp3RsRZMO1Y2iQGmp4Ik6sJSkpVJM6/RTyktDzApTq3bYi4SYNbSIzN7p/XUYXZzTffPNzPtmEhGWxkjkiwqRA5eOaZZ3K0oA3pD9FtKRsbClFw/k2iuxRywDOp1YO0luvlHvW51mhOofztzSGeO21H+KxE3lDevwIILR5EeQjzmv1+nXifNrgKM5zbW3CtZDCIWH7Ozuh3rfel6mCGf1Eo95lUsAyFIiJ+YX02bZzYT2w+/Jx51RzTFkrhkA27jYPxiZ5KhzftNiKobAE2vvpQtum+bDv1N4mqjDKZMKqKYFhMCDZ+ODdvOURdaNlNzmflQeApKE1Ha11MvG/js1v0Pi0m3r9wuUpUk6+0nEnV5KS608+brGoWctKi3nMzrV1w2oYUAbOuBZMniZ+xHH3U7BzfCxOSqKpKR2JOZEQE0oJT82LZfF8WFJsKUSjRD0JGZNX3tTuA50uKrhnNqvW541kUEXZvFc+iaBUULogsGptinPL+bSBvvfXW/NGGo/yaeJ88jaWfZrkuoqoLLrhgLoLwPeOWmivUeF/qSqBtDz+mqKK5wzxvziBWZSxUd7pfCzI2nRvEGmGnkdZWQFMKMkrmxXonzVqOtytzpLFpKVNSrm26L9tOCLkPsZhY5KXkiDnpKdEcuxQTbDm3ko9AON2CItLTht2J98fwb6K1cBizhV/0zQ7T+O2apVmNw66MobfW4428fyZ+0Sdpgf6EHIyXaDMJS/eIokrr9Hcubo0MJFIGep0frnhamg2Na1wsm+/LubYWRtfK/WdBcb20qCBKGendizYePjfbxtQo4qSppN60cbDZszlijC9zhEgjiBpRHKl/4tTPNg8cr3FsI4Kf0X1nfOUMThAOUuHEg8+1o9WSDTwR5zxbmQqiHDbBolcsCwSf3qLWCH5U3tua0XqI1cR9aQ2TCiaqyzm+RKrn0vzvmZNGloHideRZbet92WYitTqKMHla6CGqUSiVPMzKdiWd1BoR6FwsCTNGYykdEUe+js6u48ScEnoPr/5xnb+jNizy2sCovJKK649yfYxDekC6vNbxQONeC3rndZHa8b51jh+otUHntar52hV4Tl0/4xOpUrggimrxJ/BsoGxECB5CSMSudkN5Oa5JQZR7z1mwovoM8eUUCvAdqRYkeoxJOq/t3iORVNfNJlifMfcqIUQUEBBtuS9lYERQPY+ic+7JsoEoKUnWDZsm64YNcc1FG+W+NK/bNMg4ec+ibCqJXSPv24cCCOsEsUq0yta0/b5sKyHkRgELvLC4h1afLX6HZpSN8V81YDlSpw1Y8C2O2oeUha9UzplgpSWLIGiOVTqhLQ1/taWw+7eT5K0a7CRa80IiesPUr4eT6yMqpT2AFLcUjwmY761ECNqMVg7apfAV8VC5jq5p8WuKiisCcK+KfnjNfVpzBLzcW54/FgyRHdEMR90xkkv581QpvBEZ5oeTSpY+bkN0f2QoABPREckSgfP38OFr46r12RvofRmPDa/Nhvuy2YbDM2pMns029PgrzxzhqVWWa6KwyPUSDXdvGp/7UhbKh9d64b5sKyHkRgE3qZtaaFy60eHUQujl4WZ2Vc1p0WkDPA18biW6SMyVh9BOmVD1IDd7VnU+qLVOuJ0oODGhanDcC9g1W/xtKuyYRQXcf0SNCVg6WTrHPdpmMecetYAYqyiBqj8RLJ5NBQ0ic0RsZ7f/miMeTaS4eVPZFYzB86V6U4SDwFPUIEJljDZWtY+tOR+wJ0h/jygyKlIlXS6Sqi1HrUUpUqJNY7/NOm+w8ZonXTtCm+XGmKTBSxsOWYByFmlb5kstfcwp5hbXEO5L654xuLYa2peWMajxug0Vxu/2G6iV5iHobtAiYPR3Ing8xCZXoXWTkO9rcdCmTt0WeAuhSceDK8pjrLBYCpvvv//+ObVT6Nxt1TYpmWCa8HBAWwPXqC0ie2Q41kjK2PVw1qYIVbkWUh2iqlJ0UljEUFtRUcuv6bmTumKudl8SqEzkFhopfgttk7YsKFKoxqEARSpOxFHltPF5TerVPS2dXPvYmiKFH4w5nn+sOZc2fxb8jKqnbRZrFXG80DoR2KRDtW3xRBufimnV7wSPDTE/LoGuGEWkzv1a63yJ/q4Pj5x5RBTc93lO2U2kU206rH08gvzghdqu21AiInIjwY3sIZVWNeHwCdiBeIAJH5Vm0qk6q4uASO+0ySdAlBpLOYFC6oZPrjyUDrHmlTjwwANzpVLN+PsraGDm91mKrVka73q5NhbIttJcLFUUW+T5p1Q/SrVa8MvP2GTwjvGLSbcSRW1EwQovIDEuuiP16P4UDSDuRJXdxzXTXySmnHIguiOtanPo+vlaZHUwv6NGCBeV0CKNxEwxyaNGoTYyXBdzHzM/37AqaRtg6UQpR2lGvUMVwUmfajVF5Cl4I1TbknIU7RbpJtDMk1oVKSaySVTswMPZ5vuylwkhN4KbUmiZkOHJETZ3OLyKK32O3PAEEIEjGmAHXYz0bXhoC95r8R2J4PgswiOiUyZcfwcpnprPOZTOMHmKZkgLm3ws/tI1ejjZOarGEuFQMScK2TZ43txXxsAUTsBIp4q4iVRJs5p8m9W20qwWGKnWtmOjIeJdTuTgd7SgtuHM4oJrRcCZRwrEgDYwnjfWjZKKbOMCqRJX+yIRqXvuuSeP1fg8j+ZM6ck2ijm9C/lsS7rYulDaitgkSv0XMVfO1S60Ybw2eyLfGlGX3qHmDj5o84q5s9DG+7LXidRqB+UGJdwIA6k4KQLpRTtN0QE7Zje5I7e065ASaTa3rFXEGYeUqUa+ojXlvXpYea6MhwjSNZ4wKGlWVVi1ijiTirEQNEL/fFSulTFKh0gFWCSZdxV1GKvIFQHbJiyGxiKaqKjG/WdDUVLkhLcJ+JJLLskRgfK3kR4pIq6/FEqb0JJCrzGRVVHXEoGtdWwipY7TKpg/VDVKd0tVef/uQxEr4kfEVLuHQhsXS+9ZlsJmgmg1P7onRU8Jbs9g7aKm0LynZF1sAIlRRUXsNOVnbC5kbhSnmGtU4zZpw3hVpZo/FA0Zk7nf3MEPbtPkuWvzfdnrhJAbILqjn1NnObWeajwQyv9NuEQQfwRhJ1pnkq4VkyoxphSeyBF14y9SDacZp9eE1nmRiAVjZNStHZOKyJvJsjRUNbGKwNk1+5CS0y6F4Vj/LV3keVdqR2NUYoBQtdgTqNI8ohtEXNOPKRpsrCZj0ToG8s4Jt8YJeFQEmI0IEUskWHgI8tJku7ax2fBpVSS9L5rjeTKvWPBdRykqRQxS4rDp8HPNyEftNK+dja/om3tSRNH96T60AbERLN5UqfC2UO4pRVJlI6HFD9M/mw3PXPkZ47ZZlIJt+sbacg09UyJv5hdjKuJT1FGqVaQ4qJcQcv0gqqPs32JP6DTheeCHk0KAm16Ki2/CZOajRkRtLCKEKaO8tJQWItJVKq2MgZjTvqGI0yeeeCK1ZTIiqlX6NV+DBV/FqmiWBUW6h99Dy4PaUYCiWbH7DSZaniMtcFw76fwmxJzIHBHnfqwd0aiyEI4sQlqiw3ocuo/5r0qLkRojHjYXxJt7kjFcpEOa3wbKsyZN7l4k9FRSS8fx3zrZoA30V9jAh8k35hrph2fjqL2KjaJnjlhoPqNtEKgyFQRpKfgyDs/Ws88+myONpQDCfyNtrDiseOJqx8bP2GSTzPeCF+7Tkq2BtYLvT1AjqJch75EbKN8vdG5XyTtgNylS5ecskoQeccBP1oQIsnupGWPh67MQ8o6JAjCPSxfw7VhI2lCsIdrBD8fXp/eWFBtx0/QeDXR9y2tt8K4UCFELh/J/4yVKCTuRAacDlOIHY+PZ7M+UXBPS9xY+wtTiJ1XcrI4eiLb5c6QSRbZF7FVmaufTxIZRMRUBrtBBCq8t92RJF4tym0NsMDrvO1E69yMPGYEgI9CW8RFsbDOEKtynxc5g3mRZcN8qgCgtOtrEdtttl/19xJt0sM/WMHOqqKLUqiiktU8goE3P3VBjSAu55qIgpWEhlJ6zM4FdlR2zlKPJ2CQrneOG91qtXriRYfclZWfnTJAatworETgnOdQOkS3FrdhkxRVXzAugRpXK4gfbM612QdAsmJHWsBASPa4bL6BIsX9baPj+pP2JWYsL03LtY+SXcvi7xd9maa211uo7o3EwGL+oakmn10Lzb86rKApFzInKsWMQPZ2ni/BV8ccpEOj8HTVjDnRfqlCVGrYxKsfbmSv1VnOiiuyFDbDNV+2nGhSIN1Waor+aaysCEGH0zPEzwjj5HQmf2tsajeieMteYRwhVZ6xaF1xbm3uWDr7pcupNG+7LociQFnLNPkFSHaJpqjNFO0TbhM/d5HZhIlUiH/wRCgZq7xw/MnQhF5lztFiZmNCWh1UKu0w8UgQiAgzwjkfjTyp+HeMhUqV62rhrJlikc0rXeKK1KeZERBjqRT1sQPj/2oIFkMhRhar6dFQ2IgSRKGVN17T57IguEi8qjPmMjJMnTsSDlaF5IHznf9sWpI4VMxgP0SrVXyL67AB8qdKtPJ0KVGptw2Fj3rSREG56walsb1Z7l+ML+eS09XG9FMTZUNQsTJv3ludG9M0YWWj0iytIn5pP+vPDtfH+HEpMmIY4wssWPwul6ABPB1EgDWC36SEtTRFF4+ysS+PK2iakUXnYSo81osA4SsqgLQ+rBdwiQnTbFcM1s4sm4iwYhLm/iWtYolRtYtttt82Tq5Yirpd7TvrYxsN1Iwb8DQg6okHqteZJt7wvn4lt10Wq2DMoguP5K98v779zLKJWxqwlTk0iDuV9WujNKYpriifMOAkbm8HiS20eDN857jZAsOmtpphI6thGyvMoEmeTJaKjktMHapwzRfZFTUUOCzIU7AtNcebaeAatAfpqGgdxWnoz1hxlbN6X2qMQqSKn1jr+TPMJWB1EjUUa2Vb6+x1BnQy5iFznETIiUtKmTJ/8G6JTojcqNxUE2JFZMAgDHhcVTHbbdjM1ITRuxy895SH0XsvEMqJJRkpAibmdGiN2rRArdr/Scbwb5WgxExKzrvdP5BADogNFbBcTMmpfKDuvk+iwdKlKOIslCFWeHCLAYtkpZmodY/N9qd5koi59uKSFXVeeJIb/8jcoDXObIo6p3s/V2gfQQul+VBEu4liEAcEj6iNySswRCmwBtYnRkV07Alw7Ch+QElfp6Fp6JlkzjNEc6lqV9jC14r0S2+4zUVOCG+ZEfeGkFct9ChE5aVbf0yy31vuw87qxLxDZotmKFzyD+uLZRDkbtjxvilX8jMbwQXsYclWr5ca2WyR4+IuY/nnkLIweYGXkIjiidHb/HnDCwA1uAbKwMprXtjuW8uUVE8khTi14FpHSoqE/RBilRGoWcRZFpn69qHRR1+bFYshzQ9QR495/OTiecFM1KLXaFhGHImAIOAtmaXegmlgkAAS6sTNbO8ux82iqWsfYjApI3xDdpQWMiKMoDrFqnAzYrA1S/50iTnS85sXTCTAEnA+bD3MIMWOxFOl3PxJ7olesG7XTfG4UZIhgiYCXCL5r4d8+e+bcj9KOxFGJxNWKOdH1IOJszqUZpYFhjhExdq961oo3txQ5iKoqGCs9G2vCWGwUSpQXNsHsGEXE8UbbcLgvtTkSmSPkbKpshoN2MWQics0JyXFUfFUO3SaApOAsMMLKQuxaPjjyh7hzk7vxm20SlJzXvJOWYrTT8v7tkC0mxjiy8H+NYkc6ioBjPhYFJaj5buwuCTXXUjSVKPCaiCm/I/N1GyFWREkthiZZ95lNhSIOIrak6opI91pbsMBIiRIyqostoE3PlCgO8aOAwfdEETyf2rBoUO2ZrVXElWdH01j3rPGJ3ChssGF0r3r/5pJmhKfmlFwTaTgbKqKN+JGOs6mVuTC38P4ZO38VcUOct6WwASLCmjSr1iTQfHatROTMN7y31gdjsdng62R7UGBVE54ZGyCNi21wyzrlmfM9c4oNr/XOxh82xOZNc0npTdmW6xYMsYhcESjSAMQZ47ibtviovO7mNfn4WidraVapg+bOxqJTs4gzBkZjHipiwATl4RVBLJVHA1GbiLOrZDDWsoEZXmrKrpIXTETHdRShIVy1PSC+LZzNUzZqp3k97IhFGEU2RHZ4WeyURYxVBmrqXLCjbpOIIzo1v3VP6plWWtw0FwvPpPtWxFvVXPkZosj4axJxAz1HoqWaFmuEa8F04ogFVZEUQefaNqlxsTRnNCFWVltttRwVlY5TyShivMgii+QoVmm7pC+elFxppF5rj7/+rp2IsHOyRcNF3Gwo9AyVnZGpMffI3kiHl7lJ4VFtmRlzhfdPdBLfpa+plKkNkUyNLFMRcd4/sWoObTYYr/G6BQMzZCJysPjbiTC32jVb/It4UW1lktIzp6R8PNi1mXM7sTuU+uWRM/EU70oRdcbgwRWhktqpfTxN9NeSYmMct0gUym7RQiJFJYrKHwgTkihkbaJ0ZBR/jhSIyVaKw5FpBx10UE5lieZItYo2lnRxzXRGd92f+i9a6C0wTaSsbKSKp6xQhEBt17I5NgJTOp+wcZ3MH75PlJdnkdDht/U34OWsbTxNiGjPlyh4MbyL2Kj89trKK6+co6OiPgQ24VqO9ms2+601otO8djbpBJvor5QjfyYR6+xpG0abxEceeWS4/54nl3XFnOTvMth2R+NqLbCRlRLm32OZefLJJ7MQ9dlGSUSVPcMY/S2MxZgJ1DatDcEQjcjBrlF1HJ8DH44HunTgFv2QglQJaMEpIm4gb1kNiDyZeIX5iVApOItFcyK1sJhstagox//UeC5lfzCI2zE2w/0obQykD0zAUuQF0chmBLUN8B6Jmro+quBEAWw0ROcIBWP1usrA4pWrnbJYli7xInIWE60PvNa8PqIHFpTmuaTw/NUoesp74p8qFe7uSa1GpLB8n4jT4kE6kp9KBEe7lNrvTeKsNEEXnYIIuI2SCDjLhmpN0UZzpfnUz/NrNqlRxHV6NRUuaF9kwyjaK2IlMicabENFuDbPGBVlJVg9h0RRTSKOcHP/ed9wioh537OlelpkjnXB9StBCzYONiJtZGpf64IRMySunJ0JvwOBZkdi10L0mKiaN7A0AQ+PB7zm43+KR8quUAGGnaUUnAfSwo/yvqU4RLWMRTQANS6O/WE3LNIhkopmarjsHn3dXxPjtowRBI6IKa+f9LAxWSxNuNL40qgWEIU4NaUXR4bFTiWjaI5ojXEQojYgFhb3JBHE5+hzZ/SjZjxLilC0EREtlXaDgg0bQphXRHz4rTybJd1Y872pxYYIjrERc+WIQhEqGytCQTNnGIcoqlM62nAkXMFaILKtAtx11JAZhCpExl0vVgDXtyClbC71WucJMt1EypslwRwhhVog5hRt6JNX0qwCFqJvnk3+RpuLmtPgweDo+T5yIjrFkCv1KKQs7UEA6RNnArKr7K9RZa2hZl4pkyfvGL+R9y7tRqiKeDSxmFhE/SwRK+rR2Vm+ViweJiI+OdfIv5uLoMVfpIeINQmrXGXAdnB8myDOfEhREQEiBNKNrtt8882X/VWiH4o5ai1K6Q8LnwWPKHUNRVBtNCwwZYwKG3yWsqu1lxpjv7Hw90Gkzb3Ho2jh5CGzMRTtUAjFEyfS4fgt16ykWGvso1Zo/t2l9s2RNhVF3Hn+Ss80m11/C0UBxqQRdZuOvLOBJ0bdjzbBIm+yGsYtU0Ow2lSYKzs9jbVVGhOi7Bciwc1WL4pO2BhcO/cc4UrMEXy8fSKPnWdVB+2l5yJyzbSFNKMJ1YSj70/ZNfJV8az4noIG/pw23cgWFYu8nT7Ke5eKKzvoZhqyfI9hl/Cpkf7STa6PtiMEnTRA2R3zHPExEqb8HRZPaQ//bpuIayJ9ZUExAUvFMY1bMC2qTWoTOgNdP9E4YsfCYUERmbPYEG3EnAi4dhY1R6tEhKXSLPg2hMZJfCpoMBapK2k6RQ2iNV7z7InMiXo0Pau1ipymiFtiiSXyZ8+dMYmG21yYV2yGVY+bL0WHjVPUuAjwWsdXKHNis5+hwgDXz3hhg2yzocE2L/WIWjfVIEhdD4K0KeIUMkj5u3fL16wbInJS4Hx+TWp75oJRp2eLHbQ6sDAQbaJVvuY74mspzQ7tpBUCeBDKwchtwUNadotlJ8wLwS9WUjuiVPyAesuB90PD4Jp2lXaJwv0iaQNFY7xv5xz6LJpIoBOmBE5t5f8jYrDRptLihqmciDX2NtkYRBabld0ipjxwGnBL1/EWdf4tao7mKERh7ldJrKCB+CzvnceK4JHWErWaZ555shDQrkIGoE0bRPMH4Sa6WE5+KSdUSB27H11XWQ6ioBwzVuOxW50QnOZD146AM++IvLHR2NSXOVUhgDnGOlE73q/NhbHJzIiUunai+LyZNlDN50x7GOJPpDXEW2/Rk0LOIiiF6sEl4jysbmoPp1SPlKpoD/TPkbpq841dFkEPqLQrIWdHKdWobUetbSr02ZLWUDVmoZfOGEjs8OYYmyIUkQGCVDqy1vMbm2gyapFvVvUNhtrHJapmXI4sglSUNKpIho1Tc8NAhPPIqRRXZUy4144IsIialJtUqhQWASNyShCA38jXFlT94fwtRIXLIeq1X8MCEcBuYhwi981rJ31HzLE2iFw1vYw1psI7cQ0UnGhWTMTBtSS4Ra6IIHMocSdaJSrXhmtWxJzrYyzeu2IvRRs+j+gateG6BYOnzpjxaKI9g12WyIBdscVFHyQTLGNo6dSNW2+9tfpKspFRIhnSpj405GScNyHXKuLA4M9YrSq1+PcGuhb8OdIHFkqTsLRcSXvUPOmKptlUaCcihSgt1WRE913N4ypVwypuecMgkqGKWppUVVypoIPqaaLPa6wOtUPQeHZKqxcLo42S+5Afichz7XitCFoCh+Aj9IjYNlzDAluCDRIhYz4sIq5U9NsMijryORLkTWoUA81nynzoGtg82AiWTYdrKcpIvLqGUo4lwt+mCk5ZGdeHH9MGyga3iLjOVHLt1y348PRURI6h02LCfCts7kG1sOgPpLLM7sUkrNLKzqzZALEXsKBqBWDnKfUozVXr7kt6tDR8LRVUUjZ8jKKoNb7nUcUYpDMUoBiTik1RYguHRV+UuM1Y6AkaYpypv2waPFsqAi2IPqsCZCLnqxLVESmu+dra7NksiKrZEHWKHmlWgk2aVaSn6S0jhNoQJW4i5U1omyO1GmlSmv3CZpg3sNYUeCc2GeZ815C9RLqRcHNtFYbBpt5aIVLsGS0tqdpy7fqLzIkwls1VzZaFYMzRjm3HIGAOd5g4T5wdsZ2KickNbfLV4kA6xI7FxNRZjdQL2FHy7Ehb1SziUESclKrrpniBl0pkjvBpe5QUxmBhtwBaTIgaPiNmf+MkfpjlS9uDtlB2+hY7myYRKV5TCydEwXmNLIiikfynhCuPWRFxtV5baSnXxYavKeI0h7XoKzQSzeEV47ktBRDOp/TRhihxJyWSI2Klghjl+ojASauC+KnZ/N/EnE+Qi8TxjZljZGg0OSa6SyGAKLHrxu9X7ss2Xbv+InMqwsumKkTc0KCnInIiOnYlHl47MLtMi4mHWnVqicAVcVOryPmwmIiNvVTn1j4+gltrBxOuCVY00YQrWmcMPEe1j2Egmu9bVRyhaqx63qmCtCiKAthUSFHagJReZG2B55QolSLXc4uRWrSqLCJO3tCnijAXfXRvliPwarymooaqGFXXumbS4ZA2lRIm7gg58MwZq0VTRXX52bbimtlw8MoR266T+ZQg52HVcLZNmEO8Z3YG41ENbsMh+ugcWNE53uha78UmzfdoLSv3YH8QqMYmgEHA8oMHvU9PCbmCDvmOT7G7Zvp3ZAlh4BSAQhse4NGh9vGZaEWnpN1Ecwqum695k0qPvzYhqii9z6dS0hraiIhK8d8QANdee20WbhYXqRALi01GiWi1AWPhQ1UxZ0GUniq9qggcRSxNgVQ2UbWnrXTylw6XOuXzU8WpElXkrRxZVZ4ti6ooK39VWyMfzXlCmthxYwrCbDJUP7p2Nlglgl47NvKipddcc01+77y0UuDab4iqes3mQhNu9zALSluuD7+tzZJTNUongv4wRpFUEeW23pfBqNGTQq7sTPQ+0pxTutFxJVKtQT3YLZZIR3PCUWXsWkl3EAeKNtoAD5z+YRYNIqB5JqrXpL4VdDjYWnpOP7LSYLb8uy0QoMzvyy233HDPnMVSNIAYLy0s2gYxYxzmDcJTc1WR1Oai2uk9arMXqfneRckJVz0ZVaeaP8spNzULcJhLWGiIbz44ETiFX/qoiR7fcMMNOdrK0+lZtIGqebPbRIRYK5jSN05bosHQ5vsy6FEh92FSoiI/xIBdWe0TUa8y0PWS+iAGeHA0jy3NU4kEhnm9uER22jQRWUgIAMf+iFiV48NENQgb/jGTcbNRbBux4y89ufjkCvxHznS0gBBDfDttRMsYEVPHG/Eziuy0IdLdX4SR/w3uuYHef+eC3/y5Noi45ny/5ppr5jlF8YJosWiwCCt7TanobJO9xjNGUIsksjFA2ptns1zbNowjGHvU71r9f9hlqUAVWnYTDwaTk5SAxaTsKoNxS3OC4cGR+uCJU1lrxyzqZpKyO5aekxaQirTrZDpvi7m63Ft2/jw5xiDtZpyQCtG6wkLSJhE3UFGC8RDa0sFET0GqSl811aw2T23F+ERXpfZFqZw9ijYtlnrcKTYRgZLu5g8b6P13bpaaP9cWEQfzvY2EBs3mEEVfzvYlhhZaaKG+n6tZxGnqXooxSl9ULWGIOO2LeE2ljm0uRB5R4ziCcUcrInIWdz3E3NxuaF43pzNIVxUihFx/akBkVPRGUYa0IwEnzehoI5EPQs4ZgESRI9XatIBAxV85IkyhBv+fe1Qkzr+JAf24iNmmX7NWmgud9LcKW6ccsCl4/xqnSqO6lqpSpXuY5S2moqpti+YMlGbl1XRvEqhnnnlmagtSwt6vSJRUqTY/xLVrJzLc63OnDb9Kab3jbCK1VrGJrBn3mTnR0Xy8cKKJRKizsnk02YVcP50JPG9+TsFRMyoeDD0mTC2Af0hFn92xXQkvkp5UdpxuaKmPXpyIegUigIgjYFw//1boUFodSBkoUFHdaNEnFEpTzpqvq8a2hI6F0nsl4jQgtUiKBjgLV2SOINKUWvrYz9tVt0HIFRFnIXTteIwY4FUCWhRFekQXXV8VcsZr4ZHaKtQo4kYlEsP470QKGxHVxm0SctpqeL+uiWyGe45Q4E1VVGQzbBNV8zPWRPGaTgTNUwtGhNN73JPmFyK2KV5rRaCC9UKFO8yTghiKpNgWWE3MI0Qcv5+ecb3WDzXo0YgcVBhZLCyMzmrUe0sPMj4WuxGNRqURimcgqAfGd+03XCvtRbQ6UNAgtSrKStB1ltTXLuKwww475LFJ3bg3CQRpVdE3PcaIBQLAxkN7CpOw4gBpkbZgsyTFaDG85557+sZNzHneSqsRfRxF3xSm1NxUtSniHBEnwsjUrw+XfmoDIRJSGsbWTnOM5kgbJ9eR6OYhM1/ybhI65lHWE5Fjqf9a0VJDVIovk/d0RNdqRPNIrfdlJ2uttVaeLwjQcpxdGYvPCqRE43w2p7bhvgzGHtWaj0q0pvijmMdFako/I+dWutktkBo9MpPbrYkOBHVQrp30hp2mhZMoUBBAxFlwTNB22haYJjWLuOIbI2KIuFJlq6UIj5h7tBnNcl86JcBmpIi4WhvidvoR2RoIAC0dChYYp6UQq6WZsT5xUj+1N1Ut14WXUX84AtzcImKlMGAgmg1ja06loghpiBabK3kWQXzbCBN3WqoQ5yKNzbNVa0Tq3mZdJFGBVPGejowyj5TrVuN92d895RzpknFqjsVJG66dVjGqdLX/qf2+DIZoRE4EwyQjmmGXWHYiXrN4KMNmaNVMlXCzm1aVpFpQCrbGh3UoMFDKSqrNgkmcm4TPO++8/DoRYEKSvipnINaOPmmiONqHaJQKhn/iVG8qZ1b21zNNsU6bGv4Spk6lEImS5rFpks4pR6tZSBUE8ByJQrYJQlsk1XFNxsBjxIckOizqM6IeXbWiX2Y5oYDYQblWonLEmrS4+VQRjj5xndRq/mdXKAVCfLULL7xwFqTsCoNNK7Iz8K3WDCEuwka82ThZ8zqvie/zn0477bTZXtSW1jDBEIzIqYJTuWOy5ekouyo7aIu/ycoD7IYuR2258Yu3KqpTu0OZcKTdRNp4OFwvkSrXzuJB/JiM9FMTldNU1eTcBhRpaKkhzagKsNxnesbxtSgGaEaEm/diEXG17pyb78v4CFPpq3JMlUXDz5TGsK4bz+pg/Uq1YAyLLbZYju5ozCyCKtrjBAMbRmmqNiJVKuqmwtHYUK6V6kYigRgyviLiOqOvNYo4FBHHp2lMRJnNEyGuT9zI+N73vpezNtL/tWBzZFNbENUnTN2H5kVjI2A7o2384oog+FOLjzhEXFBlsYPojZuTP0AERLSmTD78ETpce7306Ookbuzu4VoVfxiRbVFRjMK0qwmnycriyUfm+kk3tqGwAVJS/ETSjeXUEBOu963pqLSHCdZYjLO/e7HWxbK8L/3h/NszViIY0sJM8SKpFhECT8TOosJs3SaMzfWyQWxGO1QKiqaac7R0KNHWNqHAhpjjI/OhBYex8vZJsUrVEXolTV7789bERsk9JxKuyKgUUJVCooEicyLGO++8c45CSv/XgPnD8XXmQ3Ok66OQwfUyL2ovQnCLECu06ez/1zxlo03XMBhCEbmyS7QzsVPWhoIPycQLlXOiAdKvQfdp7hZVnurVJKLjqCoLv8XDRKpFhdYUWlb4rG2FdKNJSdSqLROSxcD9Jzpg8rXpKPesyBzvld218bUNkQ6mdz7GZqSDWCNcCVXjE52zCEnh1dznb6Dop4i+hbTZVwz8YjYZg+1T2W2avcakUW0a7r///pzi15fRtSx/A+k619epDW1Dxabx7LfffjnrUtqIiKgSP0QacYTmvehnnIOrOIcVpxaITu+ZL9HGwYd1TV9G96b1jii3ydX6pkTmgmAgqpiBeTcsjmjesFJ0fFVSdCJwfHAmKREevg/puaB7/bWa14sok8JQ7m8SMllJP5p0iTo7adEAfjgHxmuFULsxvj8UOBA5Dks3GROqBFxZQFSSOXvTotk2FCtY/CwwyyyzTN/rxua6Em4WHZEQHzWL8GYEwzzCB1fG5Boaq+i+DSHTOCHAg0vItaGdgw2uSJR0fzNKI2JK+BA4mqeXNOtVV12VNyHG2DYUa5gjinAtdgUbRL5NG0ebQ9ew3IvGb81ghait7Yh7U+SNH1NETnSx2VTbeNlNnErh3vVzncVgQVCNkHNDE2f65Aida1FRJl+pKj45N7JeSI4jceyKxpb6H5mYtA0Ixj38UyZKlB2/hptaw6j8a3oUVQMScyIgJtZOT0vNO027efehRr4WR1hQ+N1ENvhu/B1EGaWOi5hzIoXUZM30F62STnStPGeeu9JaxOJYBJu0nM1U7SK8WTVMXLsmBLdoBxRvGIfUlWINERvXWBq5DTilweaXmOHNhHtVL0bRYt5GJ1JotF38mVJ2tY+vv/tSapG1xhxTIo/lWXv44YeziBVFLQJcitxmSlS8JhFXxubetO7ZNGjJpPOC66kIp/yMQj4RSBsohUXNdGoQVFm16hiV4qOStjHxmpDsHhmqIfohGmAnw5dUDLBt8Fb1GosuumhOt5lcLCIWRBOQtJvqPz6yTt+KBVS1pzRHzeKtINKh8SZEEAk3i4NKTrto7TdMvDYhoiMWUX8T/sA2wTQuIm4TpSBFNJVYcx09j04zEO1oI9re8IqJyrjnpMItjiJx7lUQ4QSce5ngKaK1VoHqOhW/sKiogi+noRB1PJs2Fnr5FWygiBmni9hI1TxnNqOoqmx97VqITBE+2sRIP0o36oFn4+FaijoSQ2VzUUSue7nGsZkDzRksGOYM8yJfZjk9xHNYkJGy1rVhzgyGoJBTQs40bcfhJpWa81Aqj2eCV/VoQWlOqiZkD6mFJW7s7sOQSwhYHPVHM1lJp7q2IgJ8jqWquA1tDjoR2dAzzSZDw2KFAMSB6A1/lYpNERG7Z98T5ald9DT/9t67yrlzzz03txnxbFk0eeREOog5pwCIWNk8tYktt9wy34eukbS+MfP42TQS5O7NImya1CpyYI4UVXN99BmDtBzxxn5SNhadz5dNiexFrePqr6KTJ5OAkfZWdeuaqTq1YbI+EK9SqdKt2k4Vr2btY7Sh1T7LGG0KpYZBeBJz7Cc2wr/+9a9bOWcG3aEriXcLBC+HnaJdiaodu2FHHNlBS5uWaE6zotGiUogbu/sQMIoYiDnXgvlYyxhRVb3jXDOl9J2eo7ZcNxOqxZ84VSknVSPFTwDxCPL7lepGC6iP2il/ewuGsYjoSBHD5skHcSetLM0qImDhadPz5pqJsvEv3nXXXX3v2/3KLO9r11RrHNGRJrUKAX3DCFIbCU1gzYkEjgiOaKJqVR82wqqrm5Sv2yB0zCXG4Z4TUbMx8rxZF2wy+G39jBZG1gZV4m0RcSLf1j4RRX3wCoIVNorsRe5L35d2lQkotOXZC4aQR07FGyz2DhEXCYDwOMO8xcVNXQogSmPEJnFjd9+7oj+cNHiJljp+ynUx8ZqERQhUm7UZGw67Z1EQCyjRI33KNycS0kbviigOgSPtxljd2T3fNSMcyrm3xtqm7vEEm4ibjZ8CB9G55veMyQaSfaMtWNhVNpb2Ka6hCDCMh49Yis5GaqAisNqFDpz+Ivpm/iB6iDYC1v1KoIvw+76NhmtYejXWOLbO50X00Ec56q5gDCpT2YbMNYIal19++Th+t0Gb6YqQU6xg4uFTUd3HcMyUC7tMfjgPsDSCBQUh3LpL+fszHPMqlsapdpbEnMnITlIVoJ9VaSVVLm3XdozDeNyvqqWlfEzGUjxtETdNbJhcN1WN5bkr43DShusnmtX53LXpGXzuueey10h0mBAwnxT4q6TopO/aQKlYtJlgYXCeNPFio2QzDJE5EWTGeCm6UgDRJhQsaGHk2vHhsjSUM5n9DWwQ+2s7VaufsTwv5kVpcSLUOIjVQinaMK/yzUkZi8rV3NYnqI+upFa1N3Cjeijt/kV27J5FdRh1eZA8BAy6PAR218G4R7TUJFkq/aQxRKMIGGkp6UbRjuLLUSVHfEvH8VUxy6PWtMeopAvdi+AH9DexyLRN3BR4Uwkbos1C6ZlzkDpsnETpRAfajnSVMUKE3z2o7x9KsVTNyEgYQ4n6asBsDOwMxqMSt5w9zZNKzIla8cvV0vx2VJ49AtvGj/CRhjRGG36IZBFA1g5nF7dlbHy2rApapJg39Ykzh4qw2gwWweY66vUn6lqocc4MhnCxgxQOnxRRZjICoyrBppUFIy4/AIM1cVCqrgg90btad1y9jDYh/CnaUEi3nX322VlQK5e3a7Sz9LV2MHabFg69ukQ/mHiL+KsV79/CJ7qhp5ixlIlzRMJT+wZRHhN0284Y7cQz6MQGUXHmas+djZUoneKNXnnuiFMV8NqqKNpow5m3nimeTH5hbVOIaxEd10VFuOskgqVgw/0qwsjT2KRWX2PzfSnEIFjNH0Qa76kCI5sNG3tdC8wxNvqijdLJbRE4oouuI49iqUTV5Fda2JzjbFzRR75UafEVVlihZ565oMeEnDScRdKOXwWZqI52FXYk+lQpcDDB8skpfiDmiAE7l0LN7QB6GYZ4C6AUlEXeBMrD2Dy+SDTOteQfK6K9NPutHR4cgtX9pyO+nb6IjWjNiMQcL6DCjl6AmJM6Jtil5lSRizb22mHc7mXpYhuS2sekDYX3KfXtOZIGd0+6N//yl7/k3njEAf8m8z/B47+xeSqFK22ACJVSJGIcB2eDKKLvuRShUqVK6BThp0+l6GStEf4mIorapXivmvseffTRfd/j2+Q7NXZC1RhlM9oytmAICjk7SEfFMKuqThUev/fee7OZ000sKkIEWPz5OlQmmaAsrkH3sUAQc9IBogKabUL6lAjn0RFV1dah9PyrORrQHyocRT/soKU/iFWm+JFNqrWOcVQXA2KWmLOZcrIDkdDLC0obBKqFvhxhR7y513iHCTyRb2lIQoDA0x9PhE6kp8b7sT+cmyr7QrARnwoYVKoatx6NInPEkPYj5hXe6dp7/HViLOwp1ra99torBymaqLxFyVK1aWzBEBJyZaETMjYBMXHyAWhcaTfmgSUEROkUPJi0NLwU4enVRaR2+hMnmnGqJOZd4RUTESiI5DBXW3REWttA8R6VFKv7jjC1MBojgWpzYbGsVawNRPP9ikLZ7Q82Mie96vkjZEUog+5ePw1/bZBEwFkaiBrRHNXSri1zfKcXrg33q2dNdFFU26adMDWviChKQepqQNR4/prUurloCrDO98iCYVzsKTJTZbNb61iCdjLOGgI7p5HxWIWjCI7diNcIAZ4IC0dzEoobfdzT/Ps7yYCgke7gb7SIMOzyc/AzEt4iOczyDNbSr7UvIOD7c06qtL6u6s17zWcRRy0cRI1VybVph+y9a45qw0RcE2VSNiMz9pfr7pnkW9UKwXPZTKHXMDYmf5H9NomWMRHVESXlGRPVYTnx3NkMszu09W+g1Q3vH9FGxBkbn5+NlTnG6RVSk22Cf1ZU3zwi+mZdg3nTXMKbaazNzEUQtO5kBx4HOy4PrKhOf13/g+4jWmrysXgQcVKrClWKmNOCw25ZGwvVq6qyRLVqX1QIGyl96VMiTluDUq1ZdtUWEhMyU7UKVVHj2scF4ktqbbHFFsspcGkpz9uonEdsESoRHsbzWvC+3GuEnMawTnxpVrKX69O8TiKMnY2o24pWP8Sc8RDoNhlow33Z33skdGzqpfJF+20GS3WxOYZHk+hpHlVVIwQn64m2MISo1HDxNiogsr45As74S29U7WNstDRuDoIxxThtVKPNCFEgNSDcXHrEBfWw1FJLZRGjuo9JV5pb5ZzqMpOPhfTnP/95jtbw7kjDEXGEUO2LirHwf4nq8ODw6SjOQIm8GYtKTuORFkHt44Komz53PovKaRJbRNxget3xKllMVQjWJOLgminEEMFxDd2bIoc+W/jL9Smfmf8trKo6ewFpOddGxNRJFKUPWZtE3IILLpgFDuEm+i3qLcXKjlFOUOFVNbe4bp1HVNUGYa2SlqjWgFlRHw9j2QSXNkzuUxiPn1fYUdvzFbSfMSLktAmRrmoy0OJBzLnRPQhSrErKg+7ReZ0IGhMr/4pJiCFZl3VmY2KO58qu0y669OQq/13t47SAiMYpsOHLNAHbRUvxl92/aIGIlgbAzuocqEt+bRCeniW9qVwfQlX1Nyymvj/QdfcsEoElpVwbpfO9XmJ6E/JUiaxKt0rze/8ikQVREgUAtTdrHpX3R8zZRBFD/KhtoIg4opqQ0ZVAtE2USoTf/abVjY2idcEGStScKKq5Ia4NnhZEAhIqiolT6W6VtwUFDkSdjZGCP/ADCmS06ZSUoB2M9pPCcMt3pOpNukPpON9Df4tHweQrGiK0Ln0XdH+ytYM84ogjcth/7rnn7rt20liu72233ZYXEyk7u2iNOmuebAcap2IbE6vFg5jTQV6kx065eRwcbyAPEgFRK83FgNhRwGFx9EF8WzCLmCtCW2W4a1b+HkSQlKwiDwttjRDWPJkWUMVRUowEnca3qoulHnlvbUAsnCrepWHLqQe1Uq4B0S19XE5wGAjpRuJAyr8tENiEmeipzR8Bp0LVvXn11Vfn77tuGgGzOhDpJcJfo0da9b7IWrNvn8i3+60INnjvfN+8jIReJ7VHU4Mh6JGz2NlJeVAtiPxTUjUm4P6KFjp9E23wevQazb+5RVzkTZTDDlmhg53j9ddf3/fzUlgmWr0AS8qxjdhFW/gtLnbRPHLSkaXxavMcRBOzhsE1pkI6qxtFDj1rmhRr5yA6p9LRQqlbPJEuPUeE8zhCWpzoce1rEnEibYSNe640bSbeCACLJsO462XxVAxgoVxooYWyZ8m843qKytV43Yhs/sxyIDqvsAibSmpRHILU9zoj3J1zZBuKwVwPGz9zRjH+E988tXr6ufecSNFJrWOz6RGJE4WThbLBFf3mx7SxEMAwh/DBwevEt01IG5pQB0NcyJVJhs/BJGwB4XdgthYlqPXBDFKac84501ZbbZU9VTqNK14w8WhzYOLyWsFi4+imNotuJmRCpkzIF198cRY+FheVchbatrRRKUKAkBNp5C0i3EQaeY1EA0RaeR5dV1FGzyR/o0ayBJFDuouPpwZsIKR5+eKk8s0dIoZS39LgNotM5BoXi+q7Zm2BuNZAW1d/wsb1MlZ+YSl//zaH2jB5Hmu3K4yIWWaZJY/RfWY8zZZFrqvnzUaJvaYNIkexgqIGc6JInMio4wltgmw2zCvSxjYRNod8uCxE5cSGWP+C1lWtelDLQmLn1dkPKKiD0hJG+tSiWLrCS/Hwv0mbm7hUbjZpcwRVt3gRKsLGbtpETNiIHkj1E3htwQIhEuC9l+pbEUdjINBYHUQFRFl9iPSUBYXXyt+gpn5xhJrF3wLoGkmbalMx77zz5o0FGwaf2FxzzZXFaxsr/0QKPXNEtWIhzWBFS1EiO9LDRPZ5553XajGncIrYYV8g0B3d11wjtOSQQjXH1AzBTcTZ8KieLhDgNkrmEPepZ8pYpIdtNviJSzFYBDOC6oQcI7Gbkw9noAWd70Ovrjb24xpKOHjb5MPcL+qhd1wRc9IE0j6irBadXkFEjnGeaCAW2oBqxXKEXUFaUYWmKJvr1vQ7SvvYRDWPuqu5e7zIjeioTvglDQf97IgbDZrNJTYcmuQSfcRQmzYV5b1KBXvWVHKK5rhehSLmRHJ8TwFAmwUAEWd8vJnWASf3FGwuRL9rvn4ju786xVx5xlQYF/93rc9c0DuMslOdv8iCwq9iIhoIqR4GVrtnYfaguwxUJWXBl8YxIdlJFnM/ob7FFlvkRZVHqZcgUAmGtog4ERopX2kou/6CxUFkw6JvsSlmeY1Uecr4VjupdUER9RVVJE5FcspYeP+MrZzEwWRe/h6oWQR0PnveK3uCCDghKkLF20esFlw3USw/63ttFnEg3Pj+FA6JFPM+FrxWewVnub9cL9W3aL5fLZqkVM2T5bxpz1iziK/WZy4YokKOUdXuQxTHRMtL1dl2pLONhaNkGJCDOnaVqoqdK6rpbTk3VZRDoUNpDdAUcwRPOeOwV+BjacsCWSpo9bvzrFkMP/nJT+bvMVUTQF6TMna9oMioFBrVTFkQi2izkZBqVBUoze1elSIm2ogfP8em4exmHty2PXuiNp4xfippN8+g8Sg2alY8EnNSxzZZvQDLBquGs7b55awjTdogxnlPl1tuuX7fbxFzNojN6xgEVaZW7aZE5IT+TayqGi0eUlXNo3OarLrqqtnD42d6pdN6W2EaV3EqRWWhJLZ5PooR2WQrHWfh5AcpwiDoHk1vjeibaJtrZjOlb1Xp+k9oszKAkVzkR8q1DYK10z+k8lYkvxQ6iMI1BVEbUnKdKGTYaKONcusQBUQl5c0zJ33KU8VXXCoeC7WmjlVoliPceKEVa4zsPRM5fLdlc9gGylg8T64NP6NWW/3hOXQtIwIXVC3kmD6la4TEoXO1NgCdYk7lVUlbMSoTclKxIeS6h0gbw67oqJSOBUQaS38nkVNH/8C/RT5EBIK6hIDrokCFCPfcqQ7Xl2u11VbLqR+bJh46aUj9rmo2WYtwOIGC2PQ+taEQuSlFG6JufsY9qi1H5xFcNYuc/nxi0osictddd13f68U7VQogFJ/wPJYzgGvE9VBlWu4p0X3XkBBVTGMc/Joju+9qvS9HtPapmOZhlMEYEeGJC1pTtVp2ZD4rqTcZSxFIGdhFa/aoKhDSPuUMx6A7EGwWe36cMoHaZYre8CT5fqkCbMsCOVRwjaTZXD9pYZ44UQEbJ+KgPFsaOdssScWWhtw1LigiU0Qo0eZ92hASA5pOS6uWw9J9Li1UfK8tC3/n87PGGmtkEaDKuHMzW+ZRc6Rr7O9S6zhtDhQsENkah9ugG5dNurSj+YSfVuGUlHHbxFqTzTbbLPfAk30SPXWNWFEUoBi3NS8IeqL9SFkoTEYiBMVw7XXioMZFZCjQXEjKv/mNFDRssskmuUdXswJZGtVC2owEhJirh6OPPjo/S6I1BWlW/ay06ZCua17Tmq+f9JP3K5LjWKYibER6vMYjJ9VfWuGI1KmAJ4baVjmtFYwIqQwFMzwhXtq9lOvjNYK8ObZaBZA+eDIv0qOO8PM+RUtdI3O+zaBUPzFH8LVJzCncU1kLGwyi2wZCytgHwcrKYFyK91SRR4YpqIXRckNbXDyodit22U4EcNN70Mv3gnFLcwF3eoFrYSExCRHcrpMClIKGqibeTj9cjSJgqMLYL6VTUIxCuCk2InAUO3QeA1Tj9dM2hLdPTzFRHaKtoGea7ykEkD52r8IxW6rf21A53axmJGp4TTXQ5if2Pf5Up1WgRExFuYifJjUKHxt0J2nwiPFG6+vHfmF8MN8rZHCMn00GH5x5p8axdEJMs5QoWuDH9N5tkKT+PWMEqbNipcc/97nPZcFXnseaK26DocNoKy0PqpA6b4Tdp8hPzWfl9TrNg6p1+C+NX7WDkQ5RKSeFs84666QFFlggiwAT1X333dfttx4MgEVGSrwcli69CkcfaR3j+tXeHFc6WBrYEWgvvvhifq1zfhAZdoYvwafPX0H0ow3n+jbPTuV7cwQVAerZE9EhYIk7woFnlZiVOvZc1gwRVzZ6xmVeIeb4xmwMi5jhjXMwPFHuCCuWgDac2CBa6rqICmshouCLTcg9p7ehKPJOO+2UI3UqbhX9lTOMa9wwBUOPMTIzmoyIOB4CO7NavTlDBROPCdYkpUll6cHFsyh9pTeXCjn+D/4kUY/a+zkNZaQZCRytOERBPF/lCDwpLp6d2q+fyI3NhbYofGCiHU1Kext9xwgEwq+TNmwMLfL8wXrBlagiiDZH4YnISR0TDgS4lis1Zy9szAk3lIiV+4yX0SkbRGvp6Vc2GTb1hKufqRkZCwVg5azhv//977ky1bhYg6xrBX5NcyaRp9WIDXJ/fRqDoBv8XwOn0cS5hyYphIjrPgsvvHD2TzVbwpTrIvWhvYOF0oJJgNdsjA9SjmCJdKgEtziKBoiS8OiUgqJaowPSbNJQToHhoyXGLPzM5CheuCLSnP3rvm3TebdNFGWI3igAUHWrP2NJP4ru+BuUaGM5J7bGZ69YNAgzle56GOpfaNMnOufek2YlQPnJILLovxGZK+f31uyRKx434xJpfPbZZ/PXni0Woc5r4m8iTa7Q6MYbb8ztVJrPXxC0Wsg1qW1CGmqIAkiZNg+7L9eFt0pqgF/Owd3NCSqu27hHNIbAkSIdGQS3IgGRHT4diyVRXnMEXIqUYVyEir/qkUce6av2I+b4yIqYIwBEGaXkFN2U9HHNDPR3F7XiD3MShyiPr4toKM2aa372RKREn1wHLUW0THFdpPGbRRnG5OegavUjH/lIrlhtUquI83cnqp3rq/cbca2QQZTbawpVOosZStSbmBM57i9qHAQ9IeSC7qLwRBSAiZpBt3koOpOuQ5ylVJtVjjVGcnodPin+RGk24ozQGRkWfAtpZ4VjbUKgjI9p3Pikq0TtC8ScBVFkkY9KhMfCKGVFzJVUXu2Uv7uxKvQyJj4q11OXf5sq/f88X9KN/VU51vjsiSA2PbOqi0XxpfZFqoyJ0CZki5jjw/XRFsrfnVAtYk77Hseiiah6vb9oov9OSlY0rlO0BkEr248EdSKlI+JhsuVrMSlPO+20ORWihQDfS40LyFDDtREBcKKGyszBROY6qbHNiIjhSSedlCNSJcVWEPlQreo98xspvBHhUK0qiqXKuuZGxlAoRLTwn+qZyYtK7Gh+znOq75g2PxCR1PaHF8vzV/P5vp1/c41vbRr4MKGaWFrxjDPOyGMqBRB8gVLKbY+OKypy5J3rOaKNlftUKtaRY0FQAyHkepS11lorm+ClPJzEYcFnrnYKgAm4RgEwVJDiLqlDviLXSOsGzUabh22PCCnyWltyqP4TadNuo/jD+KhEMRQ58Pzx1BKuXtd2xGvFf1VrqhhSbvxvojKlSpPfjwDgrSLy9PtzbcoJAMSqcRpfzZQ5oXwWSZ1uuulyCpxVwzXR7oaY4w2TghW9sjk037SdIuZsQhx3V6qrm9S8wQiGLiHkWkZ/AmwgUaZCTqrAkU6M1aIjJqGaF8qhhJSchdJiKEpF0AxGzBET0jpEOQ9WbXz/+9/PESlpfL44kUdROkj181u5/0TkCFqRLMKn9nvT9XKNiFRVjtrBGJueauWsUdEaGyitRgg53sa2QXAXLyMfppSjKlxeRtfG96WKFaQQs2VzWCPuNenfZuHXiDaxxsLTaNyescFYHoKg24SQaxHNg6pVWpk8TaajEmGLHWUdEG8Wej3SiBeRDovOyMSc1jLaeOiwT0zUCC8mj5EFVMWqSLBx8W46PowQEPUQseONa8O9qe0Lb6kIqmhNSSl6zTVsnqFq/CJ0BK3q8TahrYazmPkXRYnhbNW55porizmROfON1KKPcsxajQJcmt44NMv2Pm1kpcDNoSN6v6KtoqyijJG1CNpAnc2LguFQrcgEXkTcnnvumSdXjTctmCbUwU44tS6UQwn9qSwSigFcR9WAFn3tKTSRVagiXYVmbzgijierZhHn/dpcEKY64fOGSR3rg0fEwb3qfNjS37D2e9Pf3TFpfGBSwqUH3tNPP509byKkPH4FUUbFRA6Sr53O/nUi94pObCq0joHII9+f1x3pZ0OpVYcoV0nF1ibi4HQGAtzJGYSbZ0xRA3/jQL37jIXgi96aQZsIIVc5dpN8NyYX0Y1yNI4mliIzoh4iHWXSDeqnpKHK4scgD5Ed5nKeJL27XO8i0H1NwPNf1Sri4P1aILW3EdE54YQThhM0Uo/G5/ttMIv7u6suJtYUCV166aXZH6ZhrNM0iGr/Vp27xRZbZC8cwUOUOv2gdop4llIkWqT4nZ3Kg2lcBWJO5bGKXBW6TWqOWhHVNg2iiSqJbYh5/5xG1N9pIZ1jqXlsQVAIIVc5Kvr04xKNE7GRtnH+H/F24YUXZh+SxV9UJ8RcffS3oydsXFeeK/AZMcpDNIvYsViWdhVOTNGSw6kcNYu4EUXWiFKNqnmrShuc2iMeIjeePcJTipQAJ6Y9d9LfUneiUiKonk9jsrki0AmjNhwrBgJVpErl9KqrrprHRIzy/0mpFvwt+MdqP86Pp08DY2K0IHIqreroLZFhz5GG6LVGgYNgVAiPXMU0fW88cdI7TOP6NjV7bWlMyatj4lI63+wdF9Rx/RSd+Fr0jX/KYkN8O4eTV6z4w1QE8o/xKTX/W0JP8+Aaxya60Zkm7fxZwsCYpe5EuWpuZDwyv57nzRFUIuUKG6TwiD4pxymmmCKLdNQ6vk4/7ayzzpojjaqpCRyNfVWkisIZq6hjZw+8Wv2MniVijX3hueeey4Jbir+JY8X4HO+9997cBLjGaxQEo0IIuUoRtSjHFJlQeeFmn332nOaRbuVBai6eUgZSPrwrKuaCetBIVQ8uYky07corr8xeNxEqRQAWRNWNqowJAR6sEs2pcbFsCgGeMQZ5bTiajYo7mWGGGXJ1qmrIWs3x/VGeJb3Tmu+5iDnRLBG5zpNU2tDeZ5ZZZslVmSLEPJvG4foQpVqm2GTwakobm39qR5GCI+yc5ataWiTVeajOnW7iOn73u9/NcyiLivZMQdBm6o/7D0Es5HaR0hzSG6I0hBoDtSosu2OeOTvngp5c+neVRqRBHWgIyywvqsHf6LQNneQJdUdXrbLKKjkKwi+m8SpfUs0iDkWgSCPy7HnfI2rTQNSIjhhvzeb4/mCU91yh+Z71xytFR64fkdqkdhEnmuggePclIe7a2Bi650RP3bMEnkyA/mq1o9E077CNrkj3PffckwtstIVZfPHF0yKLLNL3s66jfnE2F6LDQdB2IiJXEXb5FgiRt4MOOiinSnmLVFA1m79+6lOfykJPKsf3OltVtCEa0IuIuHW2gnGdCB2LiqiH7v5OPOAV49HRmqOTNkSrRKJsMohSKSoYj0Pvy73a5vuwCGkCTTROBLU/f6ITU4ge1bm1X7NORK54yeabb74cmVJ5q0ceQSQbIGLn+9KutW4qmvDAsR+IgEOGgtfUtTSvKk4RdSzYKEuN95c6DoI2ERG5SpBi01fMpCPUzyNlkVD23zQcQxrOzzLJ+znpuCZtXTzbjP5ivG88cCXqRNjoNeaQdMZ4HkfpOCKO6LN49hftqFEQ8LeJehREM6TxiTgCQORRNaBCAJuQtt+HRbiIJHretN1AZ3GG7v/8VsXz1wZKAcZhhx2W06aiioodXFNpVe2OzCnaq6hgLY2aa8ZzpwjD88ZjakzuWaJU1Fv0mDBtRuBUs/oIgrYTQq4StCqwAJo0mY7tLhl3LSSaU5b0TsHiYvF0mHXN5zcOFZiqCWsp7yLmRNukeRSgSOWIFKj6AzO2aIfoa+3oU6hiWlWmCDHcl/5tXNLFojo+64ZvsVSg0UZYE/TyMzZiW7rRtdV+ZMEFFxyhOK1RgPdHM7qmpYjNhWtL+LhnecearUfaMDbPHmFKeN555535GfS8iQ4rPimFQqU/I3g6nXMc0big7fxfz4Og69hBQksKIX+LiYnGJCSFZYExmZZDyBl5VZYRc6jZUzUUsHgQ3KIBolI8SBYXHeVFBZxgoLoRDNhSrDyORdjVjMibkyhKykqFNFM836ZIlQXURkQEhx3A36Iti6OWPapuRdos+o6zI7wJGV+LttksSatKjasI95y1OdrYH8ZovhHRcu8qyGkb5krFDiX13xRtLA98xD6aaX/3bBC0nfDIdZlOHxExsMEGG+SIm87/JhqpVWJOaosgsFguuuii+XOIt7rQ2oCYI2T4FzUk5SNT3elaiZ6WVFU5o7ItIpyQIdpUB6poRHnvPkvH8QT6rEigdrEj4q14SPTGmbflJAoCXATOWbA8cmeddVZOjbt2PFVS5bWz2GKL5VYvPj7s+23LfdmJjIboMNHms75xNiEiy9KsbRxTEIyIEHKVoNmmCIAdvzSHVKru9/wqxBwTueib9IeJmcF6VM5YDcY8/f3tvUbMqTRW9SdNpVmsyjnRHtdRawSR1ZoPiR/ovtJzrNNXpKWKKI42D1LGIsq135vaihx88MG54z9jvwIiPlU9GovHr/ycqB2TvAik7/nvasYmTwNjApQvjD/MGFVwDhUWWGCB3BLH5lehg6iy+7NNG6cgGCwh5CrAQnjjjTdms7wihpI61T+uKeZEOiyMZYddqwgYCjRFCrO/BULEhnfM93jGROYceaSHnChPJ21YUKQY3XcicFJX3m+nQPN96UjFOdo/1N7sV0TRtbEZah5qL81NqPq+69a8TtpwsDsoYBGVq1Wggj/RuPgVRaHMI9Km0t/NVH4b7r/RQV9GbX48m9L9bepfGASjQgi5LtBcCMu/eVOUy++xxx65VQVE5qSo/v73v+eqyKiwqg/eMdFTCwRBI4XKP4Yi5vRYcx1rL0qRflKFyQAOJnjvm/Ffqt8RTs5PlS7uFHOl9UobBALRKYXq2qnWLO/bWZzEqFR4U3iXsYqGE0P++6uuuirVDBFng/iTn/wkH/FmXCKOTP8+RB77a33Ty9QcIQ6C0SGqVrtAmUxEBKTemN9vu+223JZC9KacEXjyySfnqkcir7M7edB9+KvKYfaiHnb9hE7pVSVN/v3vfz9H7JpHqtUIsaZpKh9cMfsrZOAVcxC8NiNEneOPeJA6z0ktYgg1izjwTbl2JbUKzx1BTsx1Rk+NlThV4XnHHXcMZ6KvFen7ZZddNgs4bWHMIzxjrjOfGK+tgpvO1ka9TIi4oFeJiFyXkKoxwTIj2yEfddRR2VN1wgknZG+HSEHB4ipVUvsCOZTQikLESmRDBG711VfPHfF1lCeCCJ5zzjkn/6zO+VLktV8/DamlRgkVJ02IIGqEC/3FROxsKpwI4H4VmWszIt4Kis4///xc2KCnmuduoMhNieTxoImS18IXvvCF3G+y86gprThsEHnkzDWEnGIq5n+ROp4/TYFrvy+DIBgxIeS6hJ2xCZYxnvHdIqnDuN2yidnCUg7fLtSesuplOhd3abaVVlopC29Hb0lHEnVSqYQBs7UTHLSIacP1K+MTwWHod/9pNt3shC9V5z51Riw/J+9mMxLXRkTFpRydJSqlOiKkznnoHJVXC6Kj1113Xb52qt3ZL8q11ILDmFTeEp6Eq41jJ5FyDIJ2E6nVcYyKPtE47Sn0PFLFqKJM1Z/KVQujvlYiI6IgTWoVAb1Oc6ETjYE0m0axJVIjYiqSCgKc10z/uNqvX0mPGt/MM8+c37cojWOZVNlKHZefEaEj3oxd1K7tIg7sDDvssENuBcPfOBA8kAogahJxEBVVnKEAylFizP3lXhXpN7/4HlFXRFzn6RQh4oKg3YSQG4c490/KTfNfk69UiEXTTlm6w4IiBeLfFso29KsaCpSFTtWiY7b4xqCIgdjmaVStWtqJlKIHi2dbBKp7T2r4c5/7XG5TIfLGF2dz0YxUEXM77rhj/vmaERElTJt0CpiCqOnOO++cC4122WWXfn+m5kpHrTXMJ+4/KW8CvGwo+AC9d3NPIYRbEPQWcbLDOEQLB+lTi6NoHDOyakA7Z2duMsrzVTkOqb92FUH3IF6k4Zyw0fQiEdsqGbfZZpvcQ02/uIkmmigXPtSetirvi4BxogjxVqI2em8RN9KsCm2IBEUCKPdmrWMT9eZfJLSdv+m50n6DoBkovS2aSoCLzNWOTZ6xNauFRfgJOmM3FpFU96lxu15LLrlkXxPnIAh6i/DIdQnCjaeF10rlGG+LFF2zxUjNnqqhhFS3FJyPUsCA0pNKVE4VpKiHaOqPfvSj1jQe1SLFwi/a2DyWqYxNAYTWN4o7eDp5ydrSQ0w1uJMoiJy//vWvWbBqudGG6zKiExt4MW0IFTIUiFVFNe493yeyRVLNJ3ycChs6U/1BEPQGIeS6iK7rmnfqZ6XowYRbzrMM6sECKeWtSXOnkGE2L9WbIjqlkWytjUc7o2giiIScAhsitL+xOb5K+l90rnYBxH+q9UZBZ3/RRlFwIk4zX+nhtoo512mLLbbIAptNw2kwmvzaEBonvy0BW/ybbABS5a+88kqV0dMgCEaf8MiNYYoPx0IxMpzWwCTPS+UsVS0Bgu7S9FGVa2ghZHLnhXMuZ/PnVBlLQaJ5GkCNIg5lMScC9L7T8kZ6jqesc9zSjM4YJfBE5cqZqrWizx1RY1ME4zI+QpVXTORUVJVAbZuIs+mDVje8jM8880z2w1100UW5wEE0n4iD9LhqY4KOl1EatrPvXxAEvUO9s3IL0VTUxKmFw2AXCgujxUZzznK0UdD9aNXmm2+em/lqE6P/Vmnuq0u+a+TnHNfk4HVncdZOcxH3no1PSwoiVQ8yC7/0KYpg47NyTzepVQDxL4poOzNVk22U8159dhKDHnAidMbeJghUaW/nvkK7Ec3CibnPfvaz6dBDD81+uOY1Jr6JcKnWQkTkgqA3idTqGMKZhnbLRJkJ1YHVusA3fUdtTecMNXjBCBviWo8/FanQLFZPrrvvvjtHPUSxCD0nH7SlFYeGviJxIozaVYBBXuNfTYtvvvnmPF4pSOk7Y6s1utgUcdK+PGH6vDmv2L+bKVaIpjqFwzUkZttQUOT+ElHUZFqz6fPOOy+deOKJ+XvLLbdc3lyI1rFnmG/6K0CJeScIepuIyI0hVC/ecMMNOUX6wx/+MFeWiRBI6dhRIybT+iEALPKM4a4fUaMRbvkecSeFavHUFJdniYhrQyRVYQNhyu/2kY98pO91JzUo1hDh0flf5EfVqqbApdKzVkQN9Vz0+fLLL8/ijQAt7TaaUSrCjeDjo/PzbUChBnHN16e4wTFi3/3ud/P3rr322hyZY9Ewz2gd01/ULeadIOhtIiI3BhHF0c2/nMogSifSwQOnHcVxxx2Xd9WdR+kE9aDYhBCQIndGqvSUqMdLL72UD40vR6c1Ix+1Fjb0ByHgWCrRG5FH7W+aKNhA7UUbJVp14YUX5tSilj2FY445JqccefwIoc7IlOtJzBVvY62U1iI2EmeeeWbu68fn50xcXj9+wBKZI+6cuKESvvOaBkHQ29S71W4BJlqUiIWDqaVXnY0KfZ1UpYoU2DXrNXbjjTfmo52COmGEF43jLRKR0ybmD3/4QxZyKgD1ikMz8lGj0GlGCJsRNak5mwt+OD3xdP5v/hwB14aiDRBpa665Zp+IK9E3YzR+Irz5eolM6afmOpfCldoojYxLut77vuuuu9I777yT26kQ4dLJpTG1yJwef1rjaLMSBMHQIiJyHxIpNb6VY489NpvhC/pxab4pCsdgLSWioSrvnJ20D+mQmhfIoY70qYiNaM/VV1+d/WRLLLFETptLrxLobUGkhi+OSBOpIQRgHCJSThlxP9Z0CPzoYqzaxPAxquYcqKXMY489lmqDf1GEUTWq3nCi9+YXG0LXylzCy8gTJ5XqVArRuSbhiQuCoUUIuQ+JRV0KVRTOQqj6DyIBFn8eHd4WO2d+o05qTlkNVZrp0mZPOJFXEQ8RkZEdrN5tFClI6avQlDrVW+zss8/OwkWq2IZCyxTjJHIIAj3ytBfhkeuVayjq7fQUbVZsqNqApr2OgHPii/59v//973PLG/43c4k+hry3rqtKaSli6WPHimljFATB0CSO6PqQ6BJvQtWewQ5YGk6/JguJCdjib+LtT8QhRFx9NNOlRBw/kjSra0wclZR4rUdT2TRY9BVraMPh/E2LvXYVEJnT9V/BwzrrrJPFqfSiytQ2RRlHRLkuoo82V0RRW4ScyJsIf6mI5qeVUrVpdNQYUWd8rqEosQ2k6JzUfxAEQ5fwyI2G/2jvvfdOV1xxRTYYE2121HwtUiCzzz577jkW1IMzUDtN/YX+mqUSOZqq6skl+lqqU2sUccSb6k2+KS1v+KxUpjY9U7xV2m84qYE1AFpbqFLttYaxmuNeeumladFFF01tguhWVKO3n+gvfy1BTnyXo8cU48CpDpoD196oOQiCsUs8/YPEeaiF5kLOSzXDDDNk0zUx51xOu+WTTjopNx4txuWgexDUFjqpUWy11VZZwLhGUlOip/0JGRESKUrtZEobjhojqaqlpRFVMZYUmzYcIsRFsMGCr7Gxgo3+7ssaBeroIE3Jq9o2rr/++nx/8sfxwGl1w6+p358CDiKv814NT1wQDF1CyA0C5xjqGUYAiMiUSZPJmMBT9CB9QxQwl4v26PnEc6QNSdA9XDORKhErSDVqLSI65dptt912uZpYtK4/MVfEX62LpXQqEacXHD8cUQdna/7lL3/J0ZxmZNh5o+5JfQ97HUK8rZHGm266KadZpU4POeSQXEAl3S8FXmtqPwiC7hDFDoNk2223zU1T9RkT+VBRxjwuLVUq/njmeHKkR6RdCzHxdg+p0f333z973LRncA4nD6M2MSJx++yzT67+k8IiiAi3tlwvxQoihsScSJy06ZZbbplbpzg03f0p9cY47zQKfivpunJiQ43CNBgeAk6kf4455shnMWs6HgRB0CSE3Eg64UtRWQhhkdSDS2pDWxEi7qmnnhquAlXrAN4q6bigu5Q2DNLdohrOwCXsRE2lGCF6SpwXMVeET+0455WI453iBWsW4bj3iDnHxKlWJfT0w1Ox6qQKJzvw+0Wbiu4wqhsFrW9UppprYl4JgqCTEHIDsP766+eTGKRPTaKlOaejfRzzQ7Bp2VCIRbHuxZLBX/RNBSoBVPqpQXWq/n9S417/zW9+k9osBDrFHGw2iFYp1/J1jX6/oQRLhmtiUyFlav4Y6NraVEqVtyFSHATBuCXajwxAqQzT/d5ky2tlopVS1RWeKNBaRNsRjGgSDsYtzeugotipGjxHu+66axbc+qhp8VCO2+IXc2yVSkcpydopY+OJU2wjjd8cs3YVIEptQFRBEm1FxCFE3LhF1PfFF19Mxx9/fP7a/OEMZseMaZWiH6UCB9Hg/uaREkGOOSYIgk5CyA2ABpwKGHippFRPPPHE7FUh2EzGBIHJ2KTqe4gJtg7KdeBZJOT023IsE/M7MSeiWoofiphjJC+LbFuiq4sttljuN9bfvUfMGQPDPAHhPg66A7HmRBcFNdLbTpSQLtUqxmZQ9NSJDjaMRx111IBiDjHHBEHQSaRWR4DSf5ELJnjpNmca/uAHP+hb5P2bmOM50h4gqAc+OEdQaeir31ZzceSZU8nKL+eczhJVbQvNcTiVwZFiZTPRCX8csRoRuO5H+N1zTmYg5Hhs+W1Lal/ETsNm1cdFzAVBEAyGaD/y/3CIuB2xtGlhv/32yxOwRZNYYxgX4SjNN3noNttss1wFGdSFsymJb93xi7+x8NJLL+UKZK87AaFtlKiMKKJCB9GegeDxJOJKE+ugO8Jb5E00WETOeanzzjtv3/el9kVQ//znP+fTQ/yciuogCILBEEIupdxrSzd8ETgFDPrGQUNO7ShMrsr+RTf8+5hjjukTc+eff34slBWh+rSYw0WsUCKoBBChTrxZWBWuOGu0Ldg0iL45Z1OaTk84EUVpuWbj3/6IiNy4p/Svc99pwCzFvf3222fxrZ2I+6/8jAidjePf/va3HLXr3HwEQRAMRAi5/5fagCO2LJAibAzkjvfhp9J7i7jTH07xg4rWHXfccbjfEQtl91GtqWjBosnf6Jp99rOfHe5n5pxzzvxzxJCTD2puGCtK7MQQH7POOmte7HmrpPqlS/XE06halFjhAy9WUAdNj5sG1Nra2GQ4/1Ua9d57783ziLml4PqaV/x8EATBYIn4fUp97SYskI5t0lzVIskkr4mqI7ikr+yWb7zxxnzuZqkiC+oRPa4RkebkgquvvjpHqkRR9fUjeDQF1lTVGaT6A9ZsICfMLPi8UkScg9EVbzjoXgsV3j//vvPOO/ORW8ZIyL366qtR2VgB5e/vfizXUqU0RIP5N20SpVlFjF1LvPXWW/lzXMMgCAZLFDs0UJUqvWHSZR4X2ZH+IBC8pvKxSfTiqgP+xeWWWy5HU/1bZAP6wklllRQrf5LFUfsRqataF0snNuhT6H6877770uyzz57OPPPMdPbZZ+cjxQrO3pRCdqavMRIDescFdeDaaCmiRyHrRue8wX/LymETQqRfdtllXX2/QRC0k4jINSDeLOzScwofNI71b8bj/qrIQsTVgevAI8b871gqaStYGJ3CMdNMM+W0lqPULrroohwBqVWE82u677beeuv8XolNVY78myLBom/Sc1Dh6EPvO6Jv4YUXzpW4JfITjFs6NwZTTjll/lBw08R9x6spMmeDaPPhVJEgCIIPQ3jkOpBadZKDCdZiatGPVgD10J+fzdm3IlUKUKRSHUtVkELVNkaRgOOsXE8/V6OIg9QoNPqVCi7CwGaCgOt83/4eUsk2ISp1R1b0EIw9yrUyb0jriwC7bqXXH0qRlGjx0ksvnV544YUclSv3ZRAEwagyZCJyJlNtJyx6hYFSa7xxXpdmVQih/1NQB+V68TBONtlk+bSChx56KJ133nn5WhHhUquuoQhcf9Ta7Nf9qEiDAV4xg2gOL9Xqq6+eX9NAtgi9QinWcF9rX1FOJAnGHc15RKNpqW7Xi/AWEd5www1zxarIXBFsLBusGqrha78vgyComyHhkeMl0rhXlSLPkWO2nFsoujGiLv521nbOa6211jh/z8HwiDbdfffd+d8KFlRySiM6fssH0zhUFav80xZGOlKBShtx3xFzGv4auypqXw90v0rJiiYvueSS6a9//WtX3vNQR0NfkTgbizPOOKNv7tH49/HHH8+nxTz33HPpq1/9ahbcK6ywQrWR4SAI2sOQEHKw6PNKOX9SVMNip6JML662HMk0VJEu1cBXkQJRrfeb1whznjhRK1E4Pf6gSvDnP/95vr4DnXjQBjSgVlGt4lYBhPEOhOikVCw/XdCdwgZ+RXOJ5r5HH3103/eWWWaZ9OUvfzmLc1FiYk5PQAU3MfcEQTC6DBkhV5CustDr4UTE2R0TATGh1okI2yGHHJJTUfr7acYsAiftXdJaIlZO2eCFI/iKCJKmbPs1LWJOtE0lqxRdJ3Hv1gGxpjjqjjvuyFWoDz/88HDfV0AFRTmoteAmCIJ20dPuWv3CROKaMCBrCXDwwQdnT5UjjFSQxUJYH9KFxAsxV45BE3VqHm/Em6TXn275TmyYdNJJ8+tXXHFFtQbyZZdd9gONigdqSmwcxR/3P//zP7nrfydx745bmqe4NO8vPk1pVO1E3LOaTzd/joArIg4h4oIgGBPUt8qNwd0xkSYqw68ialMWTCkNr2vzIELHnBzUhdSpKFQnGuNOO+202V/URMpKxEMvuZpFjkpFHj4pX+Nbe+2183smSAc65k0blR/84Af5WCfFHUF3KQLsu9/9bj6xQTRYv0KInorK2YRoK1LEXG33YRAEvUNPCjmVY7xwohnaiNghi2igVJeZWH1fGoQo0Bk/qAPXqhyNpjWD4pQNNtigT8hZSC2S/HKEuaPVCCL+sM6qztpQpaiKcb311svC7fvf/34uYhAdLsU3nRij1ikKPGo+UqzXYcMoDZelTnkzVcLbDLqm5hPXxvV037ontcXhzQ2CIBhb9JxHjrHY2ZN77rlnuuCCC/Jr/FW642tJYeItnf9L+tXiypxsZx10Fyc0iKBuueWWfelU19LX2267bT7dQAq1nKkq1fjss89mUaTYoebDxqV9+TKbBQrLL798juYQo9qMuD/D81ZnhJgdwybxySefTGeddVa+H52/XCpWFdi8/PLLaZ111umL2NkkSrPWeIJIEAS9QU8JOQugNhSOK+KDe/311/PrBJ1F3+t6OV1//fXZe1UQFdGA1Q476C5OLiC6XaemGZyY22qrrfLi6SSD6aabLp9Buvjii6dnnnmmFSc2aFTsqC0nLzR7j33605/OIsDYnd7QFHtB9yHeXB/CzDnMmi5Li/M6uvfK3GMTYoOx6667pj/96U/D/Y5aj4MLgqD99FRq1UJ+8cUX5zRUEXF6iVlAiTTpOT2e1lhjjRzVKWjMqeAh0qvdRxNVIs0B8E1Bpg+gqKkTGhwYryO+A+NFUWs/sUHrEF4qJ4S88847+bXmou6eVG0rLax1xUBeuWDcI2V65JFH5tNDiLhyWohWMM1TNNx/999/fxbjNo2dhIgLgmBs0VNCDhZDqQ8wkUvP8VJdffXVeeEvRxk1j3GSWjVZv/XWW1185wEWWWSR7C+ae+6589dNz1gRc6Ij/HOd1JiONB6nTWyzzTa5dYoNhsiwVGoTm4lzzz03zTXXXGmWWWbp2vsNhk+nmhf0h9OyiKiDghMNxUVZpcYLIqlO2CibyCAIgnFBzwm5JqIf0nBF2BWfkqOMnnjiieF+Nhqp1oFWIgS1Yob+xBkxJz1ZFtXaUWHrNBEnTWgaq3DD5sJ9qT9eQSRRxeMMM8yQPZ1B96Ooro90qn/bAIoGs27YLDppQ/Rthx12yPekvpSi/85WvfDCC7v99oMgGEL0tJDrRPqUf8WO+sEHH+z22xnydFZfWgQJGgujqOnCCy/c738nDVkM5bWj551UscIGaWAbBj4qabpFF100Vzg2exwSCNqMSC0H3cFmj/9NkUJJpzZT+6pXnQyzxRZb9FW9b7rppnleUXBTa//CIAh6kwnTEEBrB0bkjTfeOBvpTbyljUN4V7pH+dsvtthi6dZbb+2rOHU+Kp+YSkALZZtx2oTzNhVq6HWnrQp/lfEZp4pVveXK4elPPfVU/gi6gzlBilTfvk74F6H/JFSuagBM5OlhWHr81VpwEwRBbzL+UBFyDrPWdoRBmWAw2YaI617Eo0ScRKUUK/hw/qR2IqIdWsWoUOUZazMlra99ishcOS/VQn/TTTflkypU3xZ4r44//vjq++H1KmVO4InTK64zckzMKVzRp7L0NnQtm42aQ8QFQTAuGRJCzvmUqla1GSlNV2Oy7Q6apPIbaZ4qjSjdLfL26KOP5nQpccOXRMjceOONOVqHtqaqtBrRRFbFqsIHabkCUzzRqvdYUzA4SzboLu47UXx0bviKmNOvslm5GgRB0A16qo/cYIh0anerAIk31ZkEnGPUCDcGckJNekpK63Of+1zu6ycN7vtt8cONCL3ifv3rX2fxdsstt6Sbb745m+hFIFdZZZUqK26HImV+UFl8zTXXZE+cjcdA9zOPY2wKgyDoJkNOyAXdgWjhDxNtc3YotG4g6kRKpVYL+nAx/POVEXUiICo6245zNy3+mv7ql/fPf/4zm+Sl+uM0h/rS/7xvLAD9+eWahCcuCIJuEkIuGCctOPRJY+gXfdNeROTDIqkDvqOPCLXOaKn2DozlRE8547IXUJ0rIln6jYUQ6D78mdrD6PUnza91kY2GNjHS4Z0nNQRBENRCO41HQes8ilo58B1JreqVRrBZKDW/1TsOTREnQkXAnXPOOfnnpp9++tQriMA1m8aGiBv3LLjggmnNNdfMH4pNFEItscQSuQGwdOn888+fU+B8cAofoh1MEAS1MiTajwTd59JLL81NfjVNVbmpFYcTHJx4IFrXSUkzEn8KHyy0QTAmIMx23333XIBCxP3hD3/IFao8jF/84hfzEXD+7SQYUWFH9xFy7sPw2AZBUBuRWg3GKRbK0047Lf/7Jz/5SY54DISUozMuDz300L6oXRCMrlfT/cSb6MQNBTVOCjn77LPTdttt1/dzev9JtW6++ea58IGw66X0fhAEvUMIuWCco2WDlKmTDlQFSr0GwdjG2agnnXRS2nrrrXMz3xJdc9KGApTVVlstp/ObKLwh+pwy4rN2MkEQBDURHrlgnMM4zjMn2iHKwTMXBGOb0mRZaxuNmEuKVPEJAdfpVST0/vGPf+T2I46Mi55xQRDUSAi5YKydnTrQa8UzV8ScUzeCYGziPrzqqqvSN7/5zezLLGnU1VdfPb/mpIbO0zTKMX7E3J///Oc0bNiwLr37IAiCgYnUajBGmGiiiXLLhhLxUJnpeCqfR2QQX3zxxdNtt90WlZvBOEMKVWWqhr8ibSqpfT1QL7+Skl1yySXzSRxBEAQ1EUIuGC3222+/dMghh/QdM7XnnnvmvlsqAjW8ZS5/9tlnR/p7opdaMC5ZeeWVc+9CLUbco+UM3P6YbLLJcir2scceG6fvMQiCYDBEajX40DCCOz7LqQzaMyyzzDK5dQPfm3YOUlWXX355Pp5qZISIC8Ylzvr92te+liPCu+yyS25a3R+idFrfhIgLgqBWIiIXjBaf+tSncgsRhnFVqFNOOWXf2ZTaNuiUr43D+uuvnx566KFuv92gx1l22WXzBqLZrmZEqX1pVi1uzj///LTrrruOMDIXBEFQIxGRCz4UpYjh4YcfzmdROnZLV/zpppuu72deeumltMUWW+R+XY46IuiCYGyx9NJLpx133DFvJHja1l577ezdJOKk7vvDub/uX2f7vvLKK+P8PQdBEIwuEZELRpnZZpstFzJAxanFUGPVn/3sZzndusYaa2QRV5h66qlzw1VeuY033riL7zzodZxh6zg3B96rMn3zzTfTd77znXwkWn/FDJ3Ruji5IQiCthFCLhglVO7tscceuZHvcsstl9uHqPzToqGkWR1p5ASHZoSDh+61116LRTIYJyhQcEbv9ttvnzcS2ozYXAxUmRoEQdBWQsgFg0J0QxWqyNtBBx2UPvOZz2Rx5tDxBx98sO/niDleOSkt3+tMV0XEIxjTzD333PleFH1r3otQaPPzn/88n5nq9AY/EwRB0EuERy4YKdqL8BGJZjzxxBPp1ltvzVV+jz76aJprrrmG+9mmZ87PTTHFFMN9P0RcMCZReXrGGWfk81JFg917TRTY/PjHP84FEPvuu++AXrkgCIK2EkIuGCnXX399jsJJSfEg/eEPf8gL6HPPPZc222yz9OUvf/kDYu6HP/xhbvGgdUMQjA006j3wwAPToYcemnsXKqpZYYUVPvBzDzzwQDr33HPzpmOWWWbpynsNgiAYW4SQC0bKBRdckE9o+PrXv55OOOGEfC7lddddl3vFEWqO2rKoFhwuru8WMUf8ieQFwZhEmxs9CxXY/Pa3v0333HNPjsq5N/WGW2SRRYbrUaj5rzN9FT4EQRD0ErHCBgPSeU6qxVNV6m677ZYjG3/729/S7rvvnisCv/e97+VTHX7961+nnXbaqe+4LoS5PBjTKJyR3m9G2JyfutRSS6VTTjklHX744blSuvnzjuLSZoSfLgiCoFcIIRcMSPGzaearB5xonH5wH//4x7OAs4jyyRF20qkLL7xw/vl55503i7dOIRgEYwqV0VKpn//853PPOFFjRQ+idKusskqOFrs/mxG4p556Kn8EQRD0ElG1Goy0jcONN96Yz6QsRnKpU/3jHn/88XzW6tNPP52LGgg/0TnE2anB2EZ0eIMNNsj32VprrZVb4vBv4qMf/Wi65JJL0jnnnJOjcwXizv0aBEHQK0RELhiOZhTNv3ngCLdVV101e+Sgc/55552XW5E41mjWWWdN//nPf/pEHELEBWMbvQudJnL00Ufne5V4K/B0vvzyy/mjeV+HiAuCoNcIIRf0m0791re+lU9o0CX/tttuS6eddlpu8qt/HE4++eRsMpfa2mijjbr8roOhjEpq7UVWWmml3ARYap8NQDRZaxJE25sgCHqVSK0GH+CTn/xkuuaaa9Lzzz+fbr/99nTUUUdls7jFkZH8V7/6Vd/PSmlJYUVBQ9BNFlhggXxvKsjRuNpxcDYYInNxmkMQBL1MCLngA6jqYxaff/750+9+97tc2LDttttmE/kXvvCF3CFfWqtJLJZBt5lpppnyOcDE25133pmjcOHVDIKg14nUatAHH5xonDQV79Gcc86ZnnzyybTOOuvkylUL5DTTTJN7d00++eTD/bch4oJu88wzz+TTRO64444s4vjiQsQFQdDrhJALMvPMM0/aeuutcxsHzX0dxeXAcf3hXnjhhbTDDjvkdKt/M5U3CxuCoEbCFxcEwVAgUqtBH44wEnlzIoO2DXrDKXZQ6Xfqqafmn2Egd45qROCCIAiCoPuEkAs+wMorr5z7c2mwStxpovqNb3xjuGaq4YkLgiAIgu4TQi7oF41TF1pooXzclqIHFauKHoIgCIIgqIcQckMI5m++oVGJpmnnwCf3i1/8IozjQRAEQVAZIeSGCJr5apT6y1/+Mr344ouD+m86BV+0cgiCIAiCugghNwSYccYZ05/+9Kfc1FdU7qyzzsotGq688sq+nwnPWxAEQRC0jwm7/QaCsY9WITfccEO66KKL0nPPPZfWXHPN7HlzXuqNN96Yzj///BBxQRAEQdBCoo/cEOCVV15Jl112WTrwwAPT448/nvbYY4+09NJL5xMceN8uvvjifNTW7LPP3u23GgRBEATBKBBCrkeZcMIJ+1KmcMC99CrBBmdRqkq9/PLLc5+4bbbZJkfnHDweBEEQBEE7iNRqD+I81KWWWiode+yx6eWXX86vKVJwWsPaa6+d06pXXXVVPlxc81/euUUWWSR/EHtBEARBELSDiMj1aENfkbfvfve76WMf+1jf685IdbyWY7b+85//pI033jiLONx+++1Z4BF8qlODIAiCIKifEHI9CA8cT5yWI5tuumkWb1Cx+vvf/z498sgj+XURuf6IFiNBEARB0A5CyPUYJZq29957pyuuuCIftUW0TT311Ondd99NF1xwQS5qWH755bv9VoMgCIIgGE1CyPUAzkMtOLmh8MlPfjLNMMMMud0IMTfNNNOkhx56KJ100klp8803TzPPPHOX3nEQBEEQBGOCEHItx8H2t9xyS9pqq61yNK70gzvttNOywFP0oLBhtdVWy565KaaYIt12223pmWeeSf/4xz+6/faDIAiCIBgNomq15fztb39L++67b9ptt91yAYMjuE499dQs4hQzEGv77LNPbkNCzE0++eQ57ap3XPP81SAIgiAI2kcc0dVS5ptvvly08Pbbb+evt9xyy/TTn/40Pfroo+mNN97IIu6pp54a7nzUQw89NE0yySS55UgQBEEQBO0nUqstZP3118/93vbff/++xr/HHHNM2nnnnXOqVcUqEQcirjQF3mGHHULEBUEQBEEPEanVFjJs2LD8eZNNNsmeN/443jgp1YknnjinUrUW0RcOvhcp1CAIgiDoPULItZCbb745FzCIykmpnnjiibkqlWA7/vjjcwSOmCPcfA8h4oIgCIKg94jUagu5995701tvvZUWW2yxHJVbeuml03HHHdeXQnU011577ZVTr+uss063324QBEEQBGOJEHItYMEFF8wpVGnTwn777ZdTrCJt3/ve9/KxXARcEXOE3WabbZZPcgiCIAiCoDcJIVc5X/rSl9KVV16ZTj/99HTggQfmYgY88cQT6Z133kkrrbRSuuGGG9K3vvWt/G9FD0XMnX/++XF2ahAEQRD0MCHkKkffNzhia6KJJsoRNn3gFl100XTQQQelb37zm1ncXXfddTnNqqJ1xx13HO53xNmpQRAEQdCbRLFD5fzmN7/Jn4888sh8tNYll1yS5p9//nTyySenu+66Kx/Btcgii+TGwDfeeGNaccUV0/3339/ttx0EQRAEwTggInItEXNObjj88MPTrLPOmg4++OB86D0hp4JV8UPBv1WvRjo1CIIgCHqfiMi1BG1EFDYccMABufCBqPNvDYHL6Q5NIp0aBEEQBL1PCLkWIbVKzCl6INSOOuqofkVcEARBEARDgxByFbDAAgukl156KR9wXxjoJAbeOK9rP6IQ4mc/+9k4frdBEARBENTCeMOGDYuW/11k1VVXzacw/Pvf/0733XdfPmbrL3/5S98Zqfxu/bH11lun1VZbLa211lrj/D0HQRAEQVAHIeQqYPrpp08zzTRTOuyww9Krr76a/vrXv6Y99tgjvfnmmyMUc0EQBEEQDG1CyFXElFNOmb7+9a/nXnBE3Fe/+tX0xhtvhJgLgiAIgqBfQsh1iY022ii9/vrr6aKLLhrOE6cK9Qtf+ELaeeed08svv5wb/kZBQxAEQRAE/RF95LqAExh+8Ytf5GhbgYgTeXv33XfTVVddlduLiNBtvvnmXX2vQRAEQRDUSwi5cYwzUVWabrrppumKK64Y7nslfeqz791xxx1phRVWSJNMMkmX3m0QBEEQBDUTqdVxyMorr5xPaSDmHLX1iU98Iq233nrp05/+dHr88cfza7fffnvfz3/kIx9JN9xwQzr66KPTcccd19X3HgRBEARBfUREbhzhyKx55pknPfnkk/kzEXf66aenxRdfPE088cTpy1/+cvrpT3+a1l133b6ff+WVV9IRRxyRPv7xj3f77QdBEARBUCEh5MYR+sKddtppObK2wQYbpGuvvTZddtll6dvf/nb2zK2yyirZH7fxxhv3/TweeOCBLPQivRoEQRAEQSeRWh3HSJeqRJ1tttlyyvSpp57qq1hdeuml0wUXXJCWWWaZ9NBDD/X9NyJyjz32WFffdxAEQRAE9RFHdI1jpEvPOOOMNPPMM2cRh3IU17Bhw9Ldd9+dnn322eH+mxBxQRAEQRD0R6RWu4DTG5oRN0if6i1HtDmuKwiCIAiCYGRERK7LTDHFFGn55ZfP3rhZZ501NwNGSbcGQRAEQRAMRETkuszkk0+eNtxww1zooGecIgcVqyHigiAIgiAYGVHsUAFTTz11+te//pXFGxFXKlaDIAiCIAhGRAi5ioh0ahAEQRAEo0KkVisiRFwQBEEQBKNCCLkgCIIgCIKWEkIuCIIgCIKgpYSQC4IgCIIgaCkh5IIgCIIgCFpKCLkgCIIgCIKWEkIuCIIgCIKgpYSQC4IgCIIgaCkh5IIgCIIgCFpKCLkgCIIgCIKWEkIuCIIgCIIgtZP/D5SmvDnSqj+HAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execution_stats = [time_pytorch_function(fn, embeddings) for fn in functions.values()]\n",
    "execution_means = [stat[0] for stat in execution_stats]\n",
    "execution_stds = [stat[1] for stat in execution_stats]\n",
    "\n",
    "\n",
    "plot_execution_times(functions, execution_means, execution_stds, filename=\"1_forward-only.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VQaSerWCOnYB",
   "metadata": {
    "id": "VQaSerWCOnYB"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "## Speed comparison (Nvidia A100 GPU) with warmup (forward and backward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69e6377b",
   "metadata": {
    "id": "69e6377b"
   },
   "outputs": [],
   "source": [
    "def forward_backward(func, embeddings):\n",
    "    if embeddings.grad is not None:\n",
    "        embeddings.grad.zero_()\n",
    "\n",
    "    output = func(embeddings)\n",
    "    loss = output.sum()\n",
    "    loss.backward()\n",
    "\n",
    "\n",
    "def time_pytorch_function_forward_backward(func, *input, num_repeats = 1_000):\n",
    "    # CUDA IS ASYNC so can't use python time module\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(5):\n",
    "        forward_backward(func, *input)\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    times = []\n",
    "    for _ in range(num_repeats):\n",
    "        start.record()\n",
    "        forward_backward(func, *input)\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        times.append(start.elapsed_time(end))\n",
    "\n",
    "    return np.mean(times), np.std(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ReCmeRhCOpm8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "ReCmeRhCOpm8",
    "outputId": "2bcfa909-ba87-4d31-b926-bc66e63736cc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execution_stats = [time_pytorch_function_forward_backward(fn, embeddings) for fn in functions.values()]\n",
    "execution_means = [stat[0] for stat in execution_stats]\n",
    "execution_stds = [stat[1] for stat in execution_stats]\n",
    "\n",
    "\n",
    "plot_execution_times(functions, execution_means, execution_stds, filename=\"2_forward-and-backward.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1gWX-Ayqia1k",
   "metadata": {
    "id": "1gWX-Ayqia1k"
   },
   "source": [
    "<br>\n",
    "&nbsp;\n",
    "\n",
    "\n",
    "## Speed comparison (Nvidia A100 GPU) with warmup and compilation (forward and backward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "LQDiAPooiYAz",
   "metadata": {
    "id": "LQDiAPooiYAz"
   },
   "outputs": [],
   "source": [
    "import torch._dynamo\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "def prepare_function(fn):\n",
    "    fn = torch.compile(fn)\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aac06ffe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "aac06ffe",
    "outputId": "098c66b4-1201-4bdd-af23-e634f5ade806"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\26822\\AppData\\Local\\Temp\\ipykernel_25516\\3813504594.py line 54 \n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:00:41.605000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\26822\\AppData\\Local\\Temp\\ipykernel_25516\\3813504594.py line 14 \n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:00:41.812000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\26822\\AppData\\Local\\Temp\\ipykernel_25516\\2980611749.py line 17 \n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:02:21.400000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\26822\\AppData\\Local\\Temp\\ipykernel_25516\\1172096794.py line 25 \n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:04:02.439000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\26822\\AppData\\Local\\Temp\\ipykernel_25516\\4043859171.py line 47 \n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:05:47.734000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\26822\\AppData\\Local\\Temp\\ipykernel_25516\\4191513452.py line 16 \n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1784, in codegen\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler.codegen()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3383, in codegen\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._codegen()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3474, in _codegen\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     if device is not None and self.get_backend(device).ready_to_flush():\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1784, in codegen\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler.codegen()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3383, in codegen\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._codegen()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3474, in _codegen\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     if device is not None and self.get_backend(device).ready_to_flush():\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:07:37.454000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\26822\\AppData\\Local\\Temp\\ipykernel_25516\\3685552395.py line 17 \n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:12:33.279000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\26822\\AppData\\Local\\Temp\\ipykernel_25516\\3051348929.py line 22 \n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:21:36.599000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT forward C:\\Users\\26822\\AppData\\Local\\Temp\\ipykernel_25516\\2754101363.py line 37 \n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1370, in load\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 859, in fx_codegen_and_compile\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     graph.run(*example_inputs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 780, in run\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return super().run(*args)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\fx\\interpreter.py\", line 146, in run\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.env[node] = self.run_node(node)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1319, in run_node\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = super().run_node(n)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\fx\\interpreter.py\", line 203, in run_node\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1024, in call_function\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise LoweringException(e, target, args, kwargs).with_traceback(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1021, in call_function\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = lowerings[target](*args, **kwargs)  # type: ignore[index]\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\lowering.py\", line 361, in wrapped\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = decomp_fn(*args, **kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\kernel\\flex_attention.py\", line 849, in flex_attention\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     flex_attention_template.maybe_append_choice(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codegen\\common.py\", line 2158, in maybe_append_choice\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     choices.append(self.generate(**kwargs))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 678, in generate\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code = template.finalize_all()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 102, in finalize_all\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.code = self.code.replace(key, fn())\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 306, in hook\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code.splice(self.jit_lines())\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 232, in jit_lines\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     **TritonKernel.inductor_meta_common(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 2532, in inductor_meta_common\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\utils\\_triton.py\", line 51, in triton_hash_with_backend\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     from triton.compiler.compiler import triton_key\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._inductor.exc.LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=768),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_1])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=1536),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_4])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_6])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_8])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf3, i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf5, i3 + 8 * i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_1,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([clone_1, convert_element_type_1, sort])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf13', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf10, i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type_2,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf14', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf12, i3 + 8 * i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_3,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([sort_1, convert_element_type_3, clone_3])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=768),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_1])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=1536),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_4])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_6])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_8])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf3, i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf5, i3 + 8 * i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_1,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([clone_1, convert_element_type_1, sort])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf13', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf10, i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type_2,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf14', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf12, i3 + 8 * i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_3,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([sort_1, convert_element_type_3, clone_3])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1370, in load\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 859, in fx_codegen_and_compile\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     graph.run(*example_inputs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 780, in run\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return super().run(*args)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\fx\\interpreter.py\", line 146, in run\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.env[node] = self.run_node(node)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1319, in run_node\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = super().run_node(n)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\fx\\interpreter.py\", line 203, in run_node\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1024, in call_function\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise LoweringException(e, target, args, kwargs).with_traceback(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1021, in call_function\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = lowerings[target](*args, **kwargs)  # type: ignore[index]\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\lowering.py\", line 361, in wrapped\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = decomp_fn(*args, **kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\kernel\\flex_attention.py\", line 849, in flex_attention\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     flex_attention_template.maybe_append_choice(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codegen\\common.py\", line 2158, in maybe_append_choice\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     choices.append(self.generate(**kwargs))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 678, in generate\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code = template.finalize_all()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 102, in finalize_all\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.code = self.code.replace(key, fn())\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 306, in hook\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code.splice(self.jit_lines())\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 232, in jit_lines\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     **TritonKernel.inductor_meta_common(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 2532, in inductor_meta_common\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\utils\\_triton.py\", line 51, in triton_hash_with_backend\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     from triton.compiler.compiler import triton_key\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._inductor.exc.LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=768),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_1])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=1536),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_4])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_6])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_8])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf3, i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf5, i3 + 8 * i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_1,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([clone_1, convert_element_type_1, sort])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf13', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf10, i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type_2,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf14', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf12, i3 + 8 * i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_3,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([sort_1, convert_element_type_3, clone_3])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=768),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_1])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         ExternKernelOut(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name='extern_kernels.mm',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           name=buf0,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           layout=FixedLayout('cuda', torch.float32, size=[8192, 2304], stride=[2304, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           inputs=[ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 1024, 768], stride=[786432, 768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[8192, 768], stride=[768, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ), ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]               InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[2304, 768], stride=[768, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             FixedLayout('cuda', torch.float32, size=[768, 2304], stride=[1, 768]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]             origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           )],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           constant_args=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwargs={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           output_view=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           python_kernel_name=extern_kernels.mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           cpp_kernel_name=at::mm_out,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           ordered_kwargs_for_cpp_kernel=(),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           op_overload=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           arg_properties=[{}, {}],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           kwarg_properties=None,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           unbacked_bindings={},\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           mutation_outputs=[],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origin_node=mm,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           origins=OrderedSet([mm])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1], offset=1536),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([select_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_4])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_6])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ReinterpretView(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]         InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]),\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([slice_8])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     )\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf3, i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf5, i3 + 8 * i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_1,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([clone_1, convert_element_type_1, sort])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf13', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf10, i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp1\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=convert_element_type_2,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([convert_element_type_2])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ComputedBuffer(name='buf14', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]), data=Pointwise(\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       'cuda',\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       torch.int32,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       def inner_fn(index):\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           _, _, i2, i3 = index\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp0 = ops.load(buf12, i3 + 8 * i2)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp1 = ops.to_dtype(tmp0, torch.int64, src_dtype=torch.int16)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           tmp2 = ops.to_dtype(tmp1, torch.int32, src_dtype=torch.int64)\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]           return tmp2\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       ranges=[1, 1, 8, 8],\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origin_node=clone_3,\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]       origins=OrderedSet([sort_1, convert_element_type_3, clone_3])\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     ))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:31.479000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT from_kv_blocks c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\nn\\attention\\flex_attention.py line 299 \n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:31.872000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT _transpose_ordered c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\nn\\attention\\flex_attention.py line 186 \n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:32.071000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT _ordered_to_dense c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\nn\\attention\\flex_attention.py line 146 \n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:32.254000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT wrapped c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\apis.py line 202 \n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:32.437000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT _dense_to_ordered c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\nn\\attention\\flex_attention.py line 176 \n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 179, in aot_dispatch_base\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw = compiler(fw_module, updated_flat_args)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1334, in load\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 878, in fx_codegen_and_compile\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = graph.compile_to_fn()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1913, in compile_to_fn\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self.compile_to_module().call\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1839, in compile_to_module\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._compile_to_module()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1845, in _compile_to_module\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1780, in codegen\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.scheduler = Scheduler(self.operations)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1731, in __init__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._init(nodes)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in _init\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1749, in <listcomp>\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.nodes = [self.create_scheduler_node(n) for n in nodes]\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 1856, in create_scheduler_node\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return SchedulerNode(self, node)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 833, in __init__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._compute_attrs()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 846, in _compute_attrs\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3360, in get_backend\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.backends[device] = self.create_backend(device)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\scheduler.py\", line 3352, in create_backend\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise RuntimeError(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1142, in compile_subgraph\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] RuntimeError: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at https://github.com/openai/triton\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:32.488000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] WON'T CONVERT flex_attention c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\nn\\attention\\flex_attention.py line 916 \n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] due to: \n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1370, in load\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 859, in fx_codegen_and_compile\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     graph.run(*example_inputs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 780, in run\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return super().run(*args)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\fx\\interpreter.py\", line 146, in run\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.env[node] = self.run_node(node)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1319, in run_node\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = super().run_node(n)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\fx\\interpreter.py\", line 203, in run_node\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1024, in call_function\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise LoweringException(e, target, args, kwargs).with_traceback(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1021, in call_function\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = lowerings[target](*args, **kwargs)  # type: ignore[index]\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\lowering.py\", line 361, in wrapped\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = decomp_fn(*args, **kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\kernel\\flex_attention.py\", line 849, in flex_attention\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     flex_attention_template.maybe_append_choice(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codegen\\common.py\", line 2158, in maybe_append_choice\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     choices.append(self.generate(**kwargs))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 678, in generate\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code = template.finalize_all()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 102, in finalize_all\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.code = self.code.replace(key, fn())\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 306, in hook\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code.splice(self.jit_lines())\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 232, in jit_lines\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     **TritonKernel.inductor_meta_common(),\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 2532, in inductor_meta_common\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\utils\\_triton.py\", line 51, in triton_hash_with_backend\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     from triton.compiler.compiler import triton_key\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._inductor.exc.LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_8', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_9', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_10', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_11', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_8', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_9', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_10', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_11', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1446, in _call_user_compiler\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = compiler_fn(gm, self.example_inputs())\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_dynamo.py\", line 129, in __call__\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_gm = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\__init__.py\", line 2235, in __call__\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return compile_fx(model_, inputs_, config_patches=self.config)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1521, in compile_fx\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return aot_autograd(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\backends\\common.py\", line 72, in __call__\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1071, in aot_module_simplified\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = dispatch_and_compile()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 1056, in dispatch_and_compile\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, _ = create_aot_dispatcher_function(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 522, in create_aot_dispatcher_function\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _create_aot_dispatcher_function(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\aot_autograd.py\", line 759, in _create_aot_dispatcher_function\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn, fw_metadata = compiler_fn(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_functorch\\_aot_autograd\\jit_compile_runtime_wrappers.py\", line 586, in aot_dispatch_autograd\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1350, in fw_compiler_base\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _fw_compiler_base(model, example_inputs, is_inference)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 1421, in _fw_compiler_base\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return inner_compile(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 475, in compile_fx_inner\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return wrap_compiler_debug(_compile_fx_inner, compiler_name=\"inductor\")(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\repro\\after_aot.py\", line 85, in debug_wrapper\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     inner_compiled_fn = compiler_fn(gm, example_inputs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 661, in _compile_fx_inner\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = FxGraphCache.load(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codecache.py\", line 1370, in load\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = compile_fx_fn(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 570, in codegen_and_compile\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\compile_fx.py\", line 859, in fx_codegen_and_compile\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     graph.run(*example_inputs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 780, in run\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return super().run(*args)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\fx\\interpreter.py\", line 146, in run\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.env[node] = self.run_node(node)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1319, in run_node\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = super().run_node(n)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\fx\\interpreter.py\", line 203, in run_node\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return getattr(self, n.op)(n.target, args, kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1024, in call_function\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise LoweringException(e, target, args, kwargs).with_traceback(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\graph.py\", line 1021, in call_function\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = lowerings[target](*args, **kwargs)  # type: ignore[index]\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\lowering.py\", line 361, in wrapped\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out = decomp_fn(*args, **kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\kernel\\flex_attention.py\", line 849, in flex_attention\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     flex_attention_template.maybe_append_choice(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codegen\\common.py\", line 2158, in maybe_append_choice\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     choices.append(self.generate(**kwargs))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 678, in generate\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code = template.finalize_all()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 102, in finalize_all\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.code = self.code.replace(key, fn())\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 306, in hook\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     code.splice(self.jit_lines())\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\select_algorithm.py\", line 232, in jit_lines\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     **TritonKernel.inductor_meta_common(),\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_inductor\\codegen\\triton.py\", line 2532, in inductor_meta_common\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     \"backend_hash\": torch.utils._triton.triton_hash_with_backend(),\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\utils\\_triton.py\", line 51, in triton_hash_with_backend\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     from triton.compiler.compiler import triton_key\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._inductor.exc.LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_8', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_9', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_10', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_11', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] The above exception was the direct cause of the following exception:\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Traceback (most recent call last):\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 1064, in __call__\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     result = self._inner_convert(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 526, in __call__\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 924, in _compile\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     guarded_code = compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 666, in compile_inner\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return _compile_inner(code, one_graph, hooks, transform)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_utils_internal.py\", line 87, in wrapper_function\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return function(*args, **kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 699, in _compile_inner\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     out_code = transform_code_object(code, transform)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\bytecode_transformation.py\", line 1322, in transform_code_object\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     transformations(instructions, code_options)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 219, in _fn\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return fn(*args, **kwargs)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\convert_frame.py\", line 634, in transform\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     tracer.run()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2796, in run\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     super().run()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 983, in run\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     while self.step():\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 895, in step\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.dispatch_table[inst.opcode](self, inst)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2987, in RETURN_VALUE\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self._return(inst)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\symbolic_convert.py\", line 2972, in _return\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.output.compile_subgraph(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1117, in compile_subgraph\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1369, in compile_and_call_fx_graph\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     compiled_fn = self.call_user_compiler(gm)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1416, in call_user_compiler\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     return self._call_user_compiler(gm)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   File \"c:\\Users\\26822\\Desktop\\LLMs-from-scratch\\.venv\\lib\\site-packages\\torch\\_dynamo\\output_graph.py\", line 1465, in _call_user_compiler\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     raise BackendCompilerFailed(self.compiler_fn, e) from e\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] LoweringException: ModuleNotFoundError: No module named 'triton'\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   target: flex_attention\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[0]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_1', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[1]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_2', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[2]: TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_3', layout=FixedLayout('cuda', torch.float32, size=[8, 12, 1024, 64], stride=[2359296, 64, 2304, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   ))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[3]: Subgraph(name='sdpa_score0', graph_module=<lambda>(), graph=None)\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[4]: (TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_4', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_5', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_6', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_7', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_8', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_9', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_10', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8], stride=[8, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), TensorBox(StorageBox(\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]     InputBuffer(name='primals_11', layout=FixedLayout('cuda', torch.int32, size=[1, 1, 8, 8], stride=[64, 64, 8, 1]))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   )), 128, 128, Subgraph(name='sdpa_mask0', graph_module=<lambda>(), graph=None))\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[5]: 0.125\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[6]: {'ROWS_GUARANTEED_SAFE': False, 'PRESCALE_QK': False, 'OUTPUT_LOGSUMEXP': True}\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[7]: ()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125]   args[8]: ()\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n",
      "W0308 19:32:32.702000 25516 Lib\\site-packages\\torch\\_dynamo\\convert_frame.py:1125] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "execution_stats = [time_pytorch_function_forward_backward(prepare_function(fn), embeddings) for fn in functions.values()]\n",
    "execution_means = [stat[0] for stat in execution_stats]\n",
    "execution_stds = [stat[1] for stat in execution_stats]\n",
    "\n",
    "\n",
    "plot_execution_times(functions, execution_means, execution_stds, filename=\"3_forward-and-backward-compiled.pdf\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
