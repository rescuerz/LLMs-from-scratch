{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
   "metadata": {
    "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
   },
   "source": [
    "<table style=\"width:100%\">\n",
    "<tr>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<font size=\"2\">\n",
    "Supplementary code for the <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a> book by <a href=\"https://sebastianraschka.com\">Sebastian Raschka</a><br>\n",
    "<br>Code repository: <a href=\"https://github.com/rasbt/LLMs-from-scratch\">https://github.com/rasbt/LLMs-from-scratch</a>\n",
    "</font>\n",
    "</td>\n",
    "<td style=\"vertical-align:middle; text-align:left;\">\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff",
   "metadata": {
    "id": "58b8c870-fb72-490e-8916-d8129bd5d1ff"
   },
   "source": [
    "# Appendix E: Parameter-efficient Finetuning with LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
    "outputId": "316166b4-027a-4756-e9b4-fe88ae75dd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.0\n",
      "numpy version: 2.0.2\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.5.0+cu121\n",
      "tensorflow version: 2.18.0\n",
      "pandas version: 2.2.3\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"tiktoken\",\n",
    "        \"torch\",\n",
    "        \"tensorflow\", # For OpenAI's pretrained weights\n",
    "        \"pandas\"      # Dataset loading\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21532056-0ef4-4c98-82c7-e91f61c6485e",
   "metadata": {
    "id": "21532056-0ef4-4c98-82c7-e91f61c6485e"
   },
   "source": [
    "## E.1 Introduction to LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66edc999-3d91-4a1c-a157-9d056392e8d8",
   "metadata": {
    "id": "66edc999-3d91-4a1c-a157-9d056392e8d8"
   },
   "source": [
    "- No code in this section\n",
    "- Low-rank adaptation (LoRA) is a machine learning technique that modifies a pretrained model to better suit a specific, often smaller, dataset by adjusting only a small, low-rank subset of the model's parameters\n",
    "- This approach is important because it allows for efficient finetuning of large models on task-specific data, significantly reducing the computational cost and time required for finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1",
   "metadata": {
    "id": "5bb75b5d-d59c-4948-821a-1594a5883dc1"
   },
   "source": [
    "- Suppose we have a large weight matrix $W$ for a given layer\n",
    "- During backpropagation, we learn a $\\Delta W$ matrix, which contains information on how much we want to update the original weights to minimize the loss function during training\n",
    "- In regular training and finetuning, the weight update is defined as follows:\n",
    "\n",
    "$$W_{\\text{updated}} = W + \\Delta W$$\n",
    "\n",
    "- The LoRA method proposed by [Hu et al.](https://arxiv.org/abs/2106.09685) offers a more efficient alternative to computing the weight updates $\\Delta W$ by learning an approximation of it, $\\Delta W \\approx AB$.\n",
    "- In other words, in LoRA, we have the following, where $A$ and $B$ are two small weight matrices:\n",
    "\n",
    "$$W_{\\text{updated}} = W + AB$$\n",
    "\n",
    "- The figure below illustrates these formulas for full finetuning and LoRA side by side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b",
   "metadata": {
    "id": "a8a7419d-cae9-4525-bb44-1641f6ef4f3b"
   },
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-1.webp\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc",
   "metadata": {
    "id": "4edd43c9-8ec5-48e6-b3fc-5fb3c16037cc"
   },
   "source": [
    "- If you paid close attention, the full finetuning and LoRA depictions in the figure above look slightly different from the formulas I have shown earlier\n",
    "- That's due to the distributive law of matrix multiplication: we don't have to add the weights with the updated weights but can keep them separate\n",
    "- For instance, if $x$ is the input data, then we can write the following for regular finetuning:\n",
    "\n",
    "$$x (W+\\Delta W) = x W + x \\Delta W$$\n",
    "\n",
    "- Similarly, we can write the following for LoRA:\n",
    "\n",
    "$$x (W+A B) = x W + x A B$$\n",
    "\n",
    "- The fact that we can keep the LoRA weight matrices separate makes LoRA especially attractive\n",
    "- In practice, this means that we don't have to modify the weights of the pretrained model at all, as we can apply the LoRA matrices on the fly\n",
    "- After setting up the dataset and loading the model, we will implement LoRA in the code to make these concepts less abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
   "metadata": {
    "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
   },
   "source": [
    "## E.2 Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c64df-4431-4d27-834d-2bb38a01fc02",
   "metadata": {
    "id": "669c64df-4431-4d27-834d-2bb38a01fc02"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the dataset\n",
    "- Instead of repeating this code, one could open and run the chapter 6 notebook and then insert the LoRA code from section E.4 there\n",
    "- (The LoRA code was originally the last section of chapter 6 but was moved to the appendix due to the length of chapter 6)\n",
    "- In a similar fashion, we could also apply LoRA to the models in chapter 7 for instruction finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
    "outputId": "a67a7afe-b401-4463-c731-87025d20f72d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection\\SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from previous_chapters import (\n",
    "    download_and_unzip_spam_data,\n",
    "    create_balanced_dataset,\n",
    "    random_split\n",
    ")\n",
    "\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "try:\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
    "    print(f\"Primary URL failed: {e}. Trying backup URL...\")\n",
    "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
    "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
    "\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
   "metadata": {
    "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from previous_chapters import SpamDataset\n",
    "\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
   "metadata": {
    "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
   "metadata": {
    "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
   },
   "source": [
    "- As a verification step, we iterate through the data loaders and check that the batches contain 8 training examples each, where each training example consists of 120 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
    "outputId": "2ae34de1-dd01-4f99-d2c8-ba4dca400754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
   "metadata": {
    "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
   },
   "source": [
    "- Lastly, let's print the total number of batches in each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "IZfw-TYD2zTj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZfw-TYD2zTj",
    "outputId": "4d19ed61-cf7a-4ec4-b822-c847dd1c5d77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604",
   "metadata": {
    "id": "dec9aa4a-ffd2-4d9f-a835-cce1059fe604"
   },
   "source": [
    "## E.3 Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1",
   "metadata": {
    "id": "f36ebdaf-810e-46a2-9ad9-e017a04051b1"
   },
   "source": [
    "- This section repeats the code from chapter 6 to load and prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02b3a506-3879-4258-82b5-93a5b6bafa74",
    "outputId": "b8c9b125-bb52-45d3-8071-fa5054dbf5a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2\\124M\\checkpoint\n",
      "File already exists and is up-to-date: gpt2\\124M\\encoder.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\hparams.json\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2\\124M\\model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2\\124M\\vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "\n",
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252614cd-7ce6-4908-83e6-3761f519904e",
   "metadata": {
    "id": "252614cd-7ce6-4908-83e6-3761f519904e"
   },
   "source": [
    "- To ensure that the model was loaded corrected, let's double-check that it generates coherent text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b6ce20c-0700-4783-8be0-4cf17c200a7f",
    "outputId": "28ccbca5-8de9-41a0-c093-da00fcbaa91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8174b31b-1ab5-4115-b01c-245369da5af3",
   "metadata": {
    "id": "8174b31b-1ab5-4115-b01c-245369da5af3"
   },
   "source": [
    "- Then, we prepare the model for classification finetuning similar to chapter 6, where we replace the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e255ce91-d73a-4854-90a4-95804928eb16",
   "metadata": {
    "id": "e255ce91-d73a-4854-90a4-95804928eb16"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02e6f057-1383-4ece-8444-0a88e71ac75d",
   "metadata": {
    "id": "02e6f057-1383-4ece-8444-0a88e71ac75d"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 1.2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "model.to(device);  # no assignment model = model.to(device) necessary for nn.Module classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe",
   "metadata": {
    "id": "8e951cd6-5e42-44d2-b21f-895cb61004fe"
   },
   "source": [
    "- Lastly, let's calculate the initial classification accuracy of the non-finetuned model (we expect this to be around 50%, which means that the model is not able to distinguish between spam and non-spam messages yet reliably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fc7dd72c-73a2-4881-ade0-0a9605f1ab8c",
    "outputId": "74848515-5a49-4125-fecb-9f4bac23f812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import calc_accuracy_loader\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b",
   "metadata": {
    "id": "398a1ec9-e2a1-43d6-bf9f-12ee54b46a7b"
   },
   "source": [
    "## E.4 Parameter-efficient finetuning with LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a4a82-61ef-4d0a-9858-8988e844f12c",
   "metadata": {
    "id": "652a4a82-61ef-4d0a-9858-8988e844f12c"
   },
   "source": [
    "- We begin by initializing a LoRALayer that creates the matrices $A$ and $B$, along with the `alpha` scaling hyperparameter and the `rank` ($r$) hyperparameters\n",
    "- This layer can accept an input and compute the corresponding output, as illustrated in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-2.webp\" width=\"200px\">\n",
    "\n",
    "In code, this LoRA layer depicted in the figure above looks like as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ds9ywjMwvIW",
   "metadata": {
    "id": "2ds9ywjMwvIW"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LoRALayer(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.A = torch.nn.Parameter(torch.empty(in_dim, rank))\n",
    "        torch.nn.init.kaiming_uniform_(self.A, a=math.sqrt(5))  # similar to standard weight initialization\n",
    "        self.B = torch.nn.Parameter(torch.zeros(rank, out_dim))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.alpha * (x @ self.A @ self.B)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad21faa8-0614-4257-93cd-68952193e14a",
   "metadata": {
    "id": "ad21faa8-0614-4257-93cd-68952193e14a"
   },
   "source": [
    "- In the code above, `rank` is a hyperparameter that controls the inner dimension of the matrices $A$ and $B$\n",
    "- In other words, this parameter controls the number of additional parameters introduced by LoRA and is a key factor in determining the balance between model adaptability and parameter efficiency\n",
    "- The second hyperparameter, `alpha`, is a scaling hyperparameter applied to the output of the low-rank adaptation\n",
    "- It essentially controls the extent to which the adapted layer's output is allowed to influence the original output of the layer being adapted\n",
    "- This can be seen as a way to regulate the impact of the low-rank adaptation on the layer's output\n",
    "- So far, the `LoRALayer` class we implemented above allows us to transform the layer inputs $x$\n",
    "- However, in LoRA, we are usually interested in replacing existing `Linear` layers so that the weight update is applied to the existing pretrained weights, as shown in the figure below\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-3.webp\" width=\"200px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f",
   "metadata": {
    "id": "3e6d5da0-dfce-4808-b89b-29ff333f563f"
   },
   "source": [
    "- To incorporate the original `Linear` layer weights as shown in the figure above, we implement a `LinearWithLoRA` layer below that uses the previously implemented LoRALayer and can be used to replace existing `Linear` layers in a neural network, for example, the self-attention module or feed forward modules in an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "127d3a64-8359-4b21-b056-78d58cc75fe8",
   "metadata": {
    "id": "127d3a64-8359-4b21-b056-78d58cc75fe8"
   },
   "outputs": [],
   "source": [
    "class LinearWithLoRA(torch.nn.Module):\n",
    "    def __init__(self, linear, rank, alpha):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.lora = LoRALayer(\n",
    "            linear.in_features, linear.out_features, rank, alpha\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x) + self.lora(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1145a90-35ff-462c-820b-15483fa5b051",
   "metadata": {
    "id": "e1145a90-35ff-462c-820b-15483fa5b051"
   },
   "source": [
    "- Note that since we initialize the weight matrix $B$ (`self.B` in `LoRALayer`) with zero values in the LoRA layer, the matrix multiplication between $A$ and $B$ results in a matrix consisting of 0's and doesn't affect the original weights (since adding 0 to the original weights does not modify them)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d",
   "metadata": {
    "id": "e98a6d36-7bc9-434c-a7f1-533f26aff06d"
   },
   "source": [
    "- To try LoRA on the GPT model we defined earlier, we define a `replace_linear_with_lora` function to replace all `Linear` layers in the model with the new `LinearWithLoRA` layers\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/appendix-e_compressed/lora-4.webp\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "WlQZ8ygqzN_g",
   "metadata": {
    "id": "WlQZ8ygqzN_g"
   },
   "outputs": [],
   "source": [
    "def replace_linear_with_lora(model, rank, alpha):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            # Replace the Linear layer with LinearWithLoRA\n",
    "            setattr(model, name, LinearWithLoRA(module, rank, alpha))\n",
    "        else:\n",
    "            # Recursively apply the same function to child modules\n",
    "            replace_linear_with_lora(module, rank, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2",
   "metadata": {
    "id": "8c172164-cdde-4489-b7d7-aaed9cc2f5f2"
   },
   "source": [
    "- We then freeze the original model parameter and use the `replace_linear_with_lora` to replace the said `Linear` layers using the code below\n",
    "- This will replace the `Linear` layers in the LLM with `LinearWithLoRA` layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbe15350-4da9-4829-9d23-98bbd3d0b1a1",
    "outputId": "fd4c208f-854a-4701-d9d3-9d73af733364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters before: 124,441,346\n",
      "Total trainable parameters after: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters before: {total_params:,}\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable parameters after: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "mLk_fPq0yz_u",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLk_fPq0yz_u",
    "outputId": "0a93b8fc-05d7-4ace-ee47-e2fc6bdd7d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable LoRA parameters: 2,666,528\n"
     ]
    }
   ],
   "source": [
    "replace_linear_with_lora(model, rank=16, alpha=16)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total trainable LoRA parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9",
   "metadata": {
    "id": "b8b6819e-ef7a-4f0d-841a-1b467496bef9"
   },
   "source": [
    "- As we can see, we reduced the number of trainable parameters by almost 50x when using LoRA\n",
    "- Let's now double-check whether the layers have been modified as intended by printing the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1711be61-bb2c-466f-9b5b-24f4aa5ccd9c",
    "outputId": "acff8eca-3775-45a2-b62d-032a986ef037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_query): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_key): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (W_value): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (out_proj): LinearWithLoRA(\n",
      "          (linear): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (lora): LoRALayer()\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "      )\n",
      "      (ff): FeedForward(\n",
      "        (layers): Sequential(\n",
      "          (0): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "          (1): GELU()\n",
      "          (2): LinearWithLoRA(\n",
      "            (linear): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (lora): LoRALayer()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): LinearWithLoRA(\n",
      "    (linear): Linear(in_features=768, out_features=2, bias=True)\n",
      "    (lora): LoRALayer()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55",
   "metadata": {
    "id": "c4bbc9d7-65ec-4675-bab8-2e56eb0cfb55"
   },
   "source": [
    "- Based on the model architecture above, we can see that the model now contains our new `LinearWithLoRA` layers\n",
    "- Also, since we initialized matrix $B$ with 0's, we expect the initial model performance to be unchanged compared to before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "DAlrb_I00VEU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DAlrb_I00VEU",
    "outputId": "3da44ac4-230b-4358-d996-30b63f0d962a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101",
   "metadata": {
    "id": "13735b3e-f0c3-4dba-ae3d-4141b2878101"
   },
   "source": [
    "- Let's now get to the interesting part and finetune the model by reusing the training function from chapter 6\n",
    "- The training takes about 15 minutes on a M3 MacBook Air laptop computer and less than half a minute on a V100 or A100 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wCParRvr0eff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCParRvr0eff",
    "outputId": "ce910a9c-ee89-48bb-bfa6-49c6aee1e450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.820, Val loss 3.462\n",
      "Ep 1 (Step 000050): Train loss 0.396, Val loss 0.364\n",
      "Ep 1 (Step 000100): Train loss 0.111, Val loss 0.229\n",
      "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
      "Ep 2 (Step 000150): Train loss 0.135, Val loss 0.073\n",
      "Ep 2 (Step 000200): Train loss 0.008, Val loss 0.051\n",
      "Ep 2 (Step 000250): Train loss 0.022, Val loss 0.179\n",
      "Training accuracy: 97.50% | Validation accuracy: 97.50%\n",
      "Ep 3 (Step 000300): Train loss 0.076, Val loss 0.064\n",
      "Ep 3 (Step 000350): Train loss 0.057, Val loss 0.209\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 4 (Step 000400): Train loss 0.051, Val loss 0.145\n",
      "Ep 4 (Step 000450): Train loss 0.007, Val loss 0.154\n",
      "Ep 4 (Step 000500): Train loss 0.167, Val loss 0.143\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 5 (Step 000550): Train loss 0.108, Val loss 0.132\n",
      "Ep 5 (Step 000600): Train loss 0.010, Val loss 0.153\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 2.87 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from previous_chapters import train_classifier_simple\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c",
   "metadata": {
    "id": "d0c89e82-3aa8-44c6-b046-0b16200b8e6c"
   },
   "source": [
    "- Finally, let's evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bawWGijA0iF3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "bawWGijA0iF3",
    "outputId": "af70782a-d605-4376-fa6c-d33b38979cfa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from previous_chapters import plot_values\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses, label=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa074723-e3f7-4f7e-a267-855531a037dc",
   "metadata": {
    "id": "aa074723-e3f7-4f7e-a267-855531a037dc"
   },
   "source": [
    "- Note that we previously calculated the accuracy values on 5 batches only via the `eval_iter=5` setting; below, we calculate the accuracies on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1D2awlEq0gZi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1D2awlEq0gZi",
    "outputId": "d603eda1-d912-43eb-ec9c-af6a622510a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 99.42%\n",
      "Validation accuracy: 98.66%\n",
      "Test accuracy: 97.33%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d",
   "metadata": {
    "id": "1f87f5e6-339e-4fcf-900b-6d845d3c713d"
   },
   "source": [
    "- As we can see based on the relatively high accuracy values above, the LoRA finetuning was successful"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
